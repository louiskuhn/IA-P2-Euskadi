{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Langage Processing : Matrice de termes\n",
    "\n",
    "On voit dans ce notebook comment créer une matrice de termes à partir de notre corpus de termes, de manière à pouvoir faire tourner les modèles que l'on connaît par ailleurs sur des variables numériques. \n",
    "\n",
    "On charge les données nettoyées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "cr_df_clean = pd.read_pickle('cr_df_clean.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va créer la matrice de termes, en indiquant au logiciel d'enlever les mots-balise comme \"le\", \"et\",... Ces mots n'apportent en effet pas grand chose à l'analyse en général.\n",
    "\n",
    "Problème : la fonction propose automatiquement d'enlever les mots balise anglais mais pas les français. On va donc récupérer une liste dans un module python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'ai',\n",
       " 'aie',\n",
       " 'aient',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'alors',\n",
       " 'as',\n",
       " 'au',\n",
       " 'aucun',\n",
       " 'aura',\n",
       " 'aurai',\n",
       " 'auraient',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'auras',\n",
       " 'aurez',\n",
       " 'auriez',\n",
       " 'aurions',\n",
       " 'aurons',\n",
       " 'auront',\n",
       " 'aussi',\n",
       " 'autre',\n",
       " 'aux',\n",
       " 'avaient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avant',\n",
       " 'avec',\n",
       " 'avez',\n",
       " 'aviez',\n",
       " 'avions',\n",
       " 'avoir',\n",
       " 'avons',\n",
       " 'ayant',\n",
       " 'ayez',\n",
       " 'ayons',\n",
       " 'bon',\n",
       " 'car',\n",
       " 'ce',\n",
       " 'ceci',\n",
       " 'cela',\n",
       " 'ces',\n",
       " 'cet',\n",
       " 'cette',\n",
       " 'ceux',\n",
       " 'chaque',\n",
       " 'ci',\n",
       " 'comme',\n",
       " 'comment',\n",
       " 'd',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'dedans',\n",
       " 'dehors',\n",
       " 'depuis',\n",
       " 'des',\n",
       " 'deux',\n",
       " 'devoir',\n",
       " 'devrait',\n",
       " 'devrez',\n",
       " 'devriez',\n",
       " 'devrions',\n",
       " 'devrons',\n",
       " 'devront',\n",
       " 'dois',\n",
       " 'doit',\n",
       " 'donc',\n",
       " 'dos',\n",
       " 'droite',\n",
       " 'du',\n",
       " 'dès',\n",
       " 'début',\n",
       " 'dù',\n",
       " 'elle',\n",
       " 'elles',\n",
       " 'en',\n",
       " 'encore',\n",
       " 'es',\n",
       " 'est',\n",
       " 'et',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eurent',\n",
       " 'eus',\n",
       " 'eusse',\n",
       " 'eussent',\n",
       " 'eusses',\n",
       " 'eussiez',\n",
       " 'eussions',\n",
       " 'eut',\n",
       " 'eux',\n",
       " 'eûmes',\n",
       " 'eût',\n",
       " 'eûtes',\n",
       " 'faire',\n",
       " 'fais',\n",
       " 'faisez',\n",
       " 'fait',\n",
       " 'faites',\n",
       " 'fois',\n",
       " 'font',\n",
       " 'force',\n",
       " 'furent',\n",
       " 'fus',\n",
       " 'fusse',\n",
       " 'fussent',\n",
       " 'fusses',\n",
       " 'fussiez',\n",
       " 'fussions',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fût',\n",
       " 'fûtes',\n",
       " 'haut',\n",
       " 'hors',\n",
       " 'ici',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'j',\n",
       " 'je',\n",
       " 'juste',\n",
       " 'l',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'leurs',\n",
       " 'lui',\n",
       " 'là',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'maintenant',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'moins',\n",
       " 'mon',\n",
       " 'mot',\n",
       " 'même',\n",
       " 'n',\n",
       " 'ne',\n",
       " 'ni',\n",
       " 'nom',\n",
       " 'nommé',\n",
       " 'nommée',\n",
       " 'nommés',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'nouveau',\n",
       " 'nouveaux',\n",
       " 'on',\n",
       " 'ont',\n",
       " 'ou',\n",
       " 'où',\n",
       " 'par',\n",
       " 'parce',\n",
       " 'parole',\n",
       " 'pas',\n",
       " 'personne',\n",
       " 'personnes',\n",
       " 'peu',\n",
       " 'peut',\n",
       " 'plupart',\n",
       " 'pour',\n",
       " 'pourquoi',\n",
       " 'qu',\n",
       " 'quand',\n",
       " 'que',\n",
       " 'quel',\n",
       " 'quelle',\n",
       " 'quelles',\n",
       " 'quels',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'sans',\n",
       " 'se',\n",
       " 'sera',\n",
       " 'serai',\n",
       " 'seraient',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'seras',\n",
       " 'serez',\n",
       " 'seriez',\n",
       " 'serions',\n",
       " 'serons',\n",
       " 'seront',\n",
       " 'ses',\n",
       " 'seulement',\n",
       " 'si',\n",
       " 'sien',\n",
       " 'soi',\n",
       " 'soient',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'sommes',\n",
       " 'son',\n",
       " 'sont',\n",
       " 'sous',\n",
       " 'soyez',\n",
       " 'soyons',\n",
       " 'suis',\n",
       " 'sujet',\n",
       " 'sur',\n",
       " 't',\n",
       " 'ta',\n",
       " 'tandis',\n",
       " 'te',\n",
       " 'tellement',\n",
       " 'tels',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tous',\n",
       " 'tout',\n",
       " 'trop',\n",
       " 'très',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'valeur',\n",
       " 'voient',\n",
       " 'vois',\n",
       " 'voit',\n",
       " 'vont',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'vu',\n",
       " 'y',\n",
       " 'à',\n",
       " 'ça',\n",
       " 'étaient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étant',\n",
       " 'état',\n",
       " 'étiez',\n",
       " 'étions',\n",
       " 'été',\n",
       " 'étés',\n",
       " 'êtes',\n",
       " 'être']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stop_words import get_stop_words\n",
    "french_stop_words = get_stop_words('french')\n",
    "french_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant utiliser `CountVectorizer` pour faire notre matrice de termes avec nos mots balise français : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abattait</th>\n",
       "      <th>accentué</th>\n",
       "      <th>acclamé</th>\n",
       "      <th>accordé</th>\n",
       "      <th>acte</th>\n",
       "      <th>adversaire</th>\n",
       "      <th>alex</th>\n",
       "      <th>allemand</th>\n",
       "      <th>aller</th>\n",
       "      <th>américain</th>\n",
       "      <th>...</th>\n",
       "      <th>voir</th>\n",
       "      <th>wiegman</th>\n",
       "      <th>zagallo</th>\n",
       "      <th>échoué</th>\n",
       "      <th>écrit</th>\n",
       "      <th>égalisé</th>\n",
       "      <th>énergie</th>\n",
       "      <th>équipe</th>\n",
       "      <th>états</th>\n",
       "      <th>éternité</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CR hommes</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR femmes</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           abattait  accentué  acclamé  accordé  acte  adversaire  alex  \\\n",
       "CR hommes         1         1        0        1     1           2     0   \n",
       "CR femmes         0         0        1        1     0           0     4   \n",
       "\n",
       "           allemand  aller  américain  ...  voir  wiegman  zagallo  échoué  \\\n",
       "CR hommes         1      1          0  ...     0        0        1       1   \n",
       "CR femmes         0      0          1  ...     1        1        0       0   \n",
       "\n",
       "           écrit  égalisé  énergie  équipe  états  éternité  \n",
       "CR hommes      1        1        1       3      0         1  \n",
       "CR femmes      0        0        0       0      1         0  \n",
       "\n",
       "[2 rows x 464 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words = french_stop_words)\n",
    "\n",
    "# On fit_transform \n",
    "cr_cv = cv.fit_transform(cr_df_clean.texte)\n",
    "cr_dtm = pd.DataFrame(cr_cv.toarray(), columns = cv.get_feature_names())\n",
    "cr_dtm.index = cr_df_clean.index\n",
    "cr_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant regarder quels sont les mots les plus utilisés pour chacun des compte-rendus : c'est aussi l'occasion de vérifier que notre nettoyage a bien été réalisé ou s'il nécessite quelques retouches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CR hommes</th>\n",
       "      <th>CR femmes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abattait</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accentué</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acclamé</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accordé</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acte</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adversaire</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alex</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allemand</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aller</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>américain</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>américaine</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>américaines</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>américains</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>année</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anouk</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ans</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antoine</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appartient</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appel</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>après</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CR hommes  CR femmes\n",
       "abattait             1          0\n",
       "accentué             1          0\n",
       "acclamé              0          1\n",
       "accordé              1          1\n",
       "acte                 1          0\n",
       "adversaire           2          0\n",
       "alex                 0          4\n",
       "allemand             1          0\n",
       "aller                1          0\n",
       "américain            0          1\n",
       "américaine           0          2\n",
       "américaines          0          4\n",
       "américains           0          1\n",
       "année                0          1\n",
       "anouk                0          1\n",
       "ans                  1          0\n",
       "antoine              2          0\n",
       "appartient           1          0\n",
       "appel                1          0\n",
       "après                7          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on transpose le df pour trier par mots les plus utilisés\n",
    "dtm_analyse = cr_dtm.transpose()\n",
    "dtm_analyse.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "morgan         6\n",
       "van            6\n",
       "rapinoe        4\n",
       "américaines    4\n",
       "alex           4\n",
       "gardienne      3\n",
       "coup           3\n",
       "match          3\n",
       "but            3\n",
       "gauche         3\n",
       "pu             3\n",
       "veenendaal     3\n",
       "frappart       3\n",
       "centres        3\n",
       "stéphanie      3\n",
       "penalty        3\n",
       "compétition    3\n",
       "face           3\n",
       "plus           3\n",
       "megan          3\n",
       "Name: CR femmes, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pour les femmes\n",
    "dtm_analyse[\"CR femmes\"].sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la librairie `wordcloud`, on peut faire une représentation graphique intéressante de ces résultats : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice : nuage de mots\n",
    "\n",
    "Utilisez la fonction `WordCloud` pour faire un nuage de mots pour le compte-rendu de match femmes et un autre pour celui des hommes. Voyez-vous d'autres nettoyages de mots à faire?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
