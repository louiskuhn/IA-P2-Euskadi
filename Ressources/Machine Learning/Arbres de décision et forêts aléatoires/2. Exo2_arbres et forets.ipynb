{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réduction d'une forêt aléatoire avec une régression Lasso\n",
    "\n",
    "Le modèle Lasso permet de sélectionner des variables, une forêt aléatoire produit une prédiction comme étant la moyenne d'arbres de régression. Et si on mélangeait les deux ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données\n",
    "\n",
    "On va partir sur ce jeu de données [Boston](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html). Le but est de prédire le prix des appartements (variable *MEDV* pour Median Value). Importer les données puis afficher l'objet dataset importé, notamment l'attribut `DESCR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse exploratoire et visualisation\n",
    "\n",
    "Créer un dataframe à partir des données du jeu Boston puis procéder à l'étape de visualisation et d'analyse exploratoire. Regarder notamment les corrélations et afficher des graphiques des variables indépendantes fortement corrélées avec la variable dépendante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des différents datasets\n",
    "\n",
    "Créer les différents jeux de données pour la modélisation : X, y puis X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Une forêt aléatoire\n",
    "\n",
    "Caler une forêt aléatoire sur l'échantillon d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment récupérer le nombre d'arbres ? Comment récupérer les arbres eux-mêmes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer le score du modèle. Choisir bien sûr une mesure adaptée à notre problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moyenne des prédictions des arbres\n",
    "\n",
    "Vérifier que la forêt retourne bien la moyenne des prédictions des différents arbres en calculant cette moyenne \"à la main\". On pourra vérifier que le score du modèle est le même pour s'assurer qu'on obtient bien les mêmes prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pondération des arbres à l'aide d'une régression linéaire\n",
    "\n",
    "La forêt aléatoire est une façon de créer de nouvelles variables, autant de variables que d'arbres dans la forêt. On peut donc utiliser ces nouveaux features pour caler une régression linéaire. À vous de jouer !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer le score de ce nouveau modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répeter plusieurs fois les opérations précédentes afin de voir l'effet de l'aléatoire (notamment présent dans le découpage `train_test_split` et dans le `RandomForestRegressor`). Idéalement vous pouvez définir une fonction qui refait tout et l'exécuter directement.  \n",
    "Qu'en conclure sur ce nouveau modèle ? Que dire du risque d'*overfitting* ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuer un diagrammes en barres des valeurs des coefficients de la régresion linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caler une régression linéaire sur les variables initiales et mesurer son score pour comparer avec celui obtenu sur les features issus de la forêt aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin : sélection de variables\n",
    "\n",
    "Une idée pour sélectionner les variables est d'utiliser la régularisation. On a vu que la régularisation $l_1$ ou encore [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) permet de sélectionner des variables en fixant certains coefficients à 0. On peut donc tenter d'améliorer la régression précédente en utilisant une régression Lasso pour réduire la forêt aléatoire sans perdre en performance. C'est quasiment le même code. À vous !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarder les coefficients pour savoir quels arbres ont finalement été conservés ou non (ou plutôt combien d'arbres ont été conservés)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire varier le paramètre `alpha` de la régression Lasso :\n",
    "- avec un pas de 0.01 entre 0 et 1\n",
    "- avec un pas de 0.1 entre 1 et 10\n",
    "\n",
    "Puis tracer l'évolution de la performance et du nombre d'arbres conservés en fonction de alpha. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
