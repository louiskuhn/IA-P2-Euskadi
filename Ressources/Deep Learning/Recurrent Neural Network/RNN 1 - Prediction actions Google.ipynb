{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Recurrent Neural Network - Stock Prediction**\n",
    "\n",
    "Le but de cet exercice est de prédire le cours de l'action Google. Rien que ça. Plus exactement : on veut prédire le prix de l'action Google à j+1 en utilisant un certain nombre de jours précédents. Allez en route !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import et preprocessing des données**\n",
    "\n",
    "1. Récupérer les données de Google sur Yahoo!Finance (c'est la colonne \"close\" qui nous intéressera). Prendre tout l'historique (depuis le 19 août 2004)\n",
    "2. Pour vous rafraîchir un peu la mémoire :\n",
    ">- les charger en un objet série temporelle avec pandas,\n",
    ">- modifier la fréquence pour être en \"jours ouvrables\"\n",
    ">- afficher la série\n",
    "3. Créer vos échantillons d'entraînement et de test en précisant la stratégie utilisée\n",
    "4. Scaler vos données. Pour les réseaux récurrents et plus généralement lorsqu'on utilise des fonctions d'activation sigmoïde, on suggère d'utiliser la normalisation (min-max)\n",
    "5. Transformer vos données de sorte qu'elles puissent servir pour entraîner un réseau, c'est-à-dire qu'on veut une matrice X d'inputs et un vecteur y de targets. Pour ça, vous devez vous demander, qu'est-ce que je veux prédire et avec quoi ?\n",
    "6. Quelle est la dimension des inputs pour un [réseau récurrent de keras](https://keras.io/api/layers/recurrent_layers/) (simple, LSTM, GRU, peu importe) ? Agissez en conséquence...c'est niquel ça fera même la transition avec la suite : lisez la doc, vous allez faire un RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Construction du réseau**\n",
    "\n",
    "1. Continuer de regarder un peu la doc `keras` sur les RNN pour savoir quelles couches utiliser\n",
    "2. En reprenant toujours les mêmes étapes (initialisation, ajout de couches cachées, couche de sortie, paramètres d'entraînement, entraînement), construire un RNN comprenant plusieurs couches LSTM empilées.  \n",
    "Ne pas oublier de gérer le sur-apprentissage s'il y en a..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Prédiction, évaluation et visualisation**\n",
    "\n",
    "**Première approche :** une première méthode est de prédire chaque jour à partir des dernières vraies valeurs. Cela a du sens puisque notre modèle est construit pour ça : prédire la valeur de l'action à j+1 à partir d'un nombre de jours précédents fixés. En revanche cela veut dire qu'on utilise à chaque fois les vraies valeurs de l'échantillon test pour prédire la suivante. Pour essayer d'être plus clair :  \n",
    ">- on a un modèle entraîné avec les données jusqu'au 31/08/2020 et on veut prédire les valeurs du 01/09/2020 au 13/11/2020\n",
    ">- notre modèle est fait pour prédire un jour à partir des précédents, le 31/08 on va donc prédire le 01/09 à partir des données des jours précédents\n",
    ">- ensuite, le lendemain, le 01/09, on va prédire le 02/09 en utilisant la vraie valeur du 01/09 qu'on aura observée depuis ainsi que les précédentes\n",
    ">- ensuite, le lendemain, le 02/09, on va prédire le 03/09 en utilisant les vraies valeurs des 01/09 et 02/09 et les précédentes\n",
    ">- etc...\n",
    ">\n",
    "> Ce qu'on peut reprocher à cette méthode c'est de ne pas utiliser les nouvelles infos dans la construction du modèle mais uniquement pour la prédiction. Ça a un petit côté paradoxal mais en même temps on a pas forcément envie de réentraîner notre modèle tous les jours avec juste une seule valeur en plus.\n",
    ">\n",
    ">1. Le premier travail va être de formater les inputs de test pour qu'ils soient au même format que ceux de l'entraînement du modèle. Il faut donc répéter les opérations qu'on a faites pour le train. Avec quelques modifications quand même. hésitez pas à prendre un papier un crayon si ça chauffe trop...\n",
    ">>- définir un objet `inputs` qui contient toutes les valeurs dont vous aurez besoin (donc les données du test + les n dernières valeurs du train nécessaires à la prédiction des n premières valeurs du test). Vous pouvez pour ça utiliser certaines méthodes des objets datetime de pandas.\n",
    ">>- une fois que c'est fait, il vous reste plus qu'à normaliser et reconstruire votre `X_test` de la même manière que votre `X_train`\n",
    ">2. Évaluer les prédictions avec une ou plusieurs métriques adaptées\n",
    ">3. Afficher les prédictions sur un beau graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deuxième approche :** la deuxième possibilité consiste à prédire toutes la période de test à partir des infos au 31/08/2020. Cela pourrait avoir du sens si on veut savoir comment va évoluer la tendance à moyen terme (ou en tout cas à plus que j+1).\n",
    ">- on a un modèle entraîné avec les données jusqu'au 31/08/2020 et on veut prédire les valeurs du 01/09/2020 au 13/11/2020\n",
    ">- notre modèle est fait pour prédire un jour à partir des précédents, le 31/08 on va donc prédire le 01/09 à partir des données des jours précédents\n",
    ">- puis, toujours le 31/08, on va prédire le 02/09 en utilisant la valeur prédite du 01/09 ainsi que les précédentes\n",
    ">- puis, toujours le 31/08, on va prédire le 03/09 en utilisant les valeurs prédites des 01/09 et 02/09 ainsi que les précédentes\n",
    ">- etc...\n",
    ">\n",
    "> Le modèle qu'on a construit est prévu pour ne prédire qu'à un jour donc on réutilise la prédiction comme input pour la prédiction du jour suivant. Le problème est qu'on multiplie ainsi les erreurs qui s'accumule un jour après l'autre. Cette méthode ne sera donc a priori pas très convaincante ou en tout cas pas sur une longue période...mais on va le faire quand même !\n",
    ">\n",
    "> Une autre approche, à tester pour en comparer l'efficacité mais certainement meilleure, serait de construire un modèle qui prédit plusieurs jours à partir des précédents.\n",
    ">\n",
    ">1. On va de nouveau formater les inputs mais différement bien sûr.\n",
    ">>- définir un objet `inputs` qui contient toutes les valeurs les n dernières valeurs du train nécessaires à la prédiction\n",
    ">>- faire la prédiction pour le 1er jour\n",
    ">>- ajouter cette prédiction dans votre objet `inputs` et supprimer la 1ère valeur dont on aura plus besoin\n",
    ">>- faire la prédiciton du second jour puis l'insérer dans votre `inputs`\n",
    ">>- etc jusqu'à avoir prédit toutes les valeurs jusqu'au 13/11\n",
    ">2. Évaluer et afficher les prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Amélioration du modèle**\n",
    "\n",
    "En revenant sur la première approche, essayer d'amélorier le modèle.\n",
    "\n",
    "Quelques pistes qui peuvent évidemment être combinées mais tout ça étant coûteux en temps, vous ne pourrez pas tout tester :\n",
    "- Plus de données, quand c'est possible\n",
    "- Augmenter le nombre de \"timesteps\" pour regarder plus loin dans le passé\n",
    "- Ajouter d'autres variables : par exemple on pourrait ajouter des actions d'autres entreprises dont l'action pourrait être corrélée à celle de Google\n",
    "- Compléxifier le réseau : plus de couches/neurones\n",
    "- Ajustement des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Ajout de variables supplémentaires**\n",
    "\n",
    "Comme évoqué, on pourrait vouloir ajouter d'autres variables pour améliorer les performances de notre modéle. Dans cette partie, il s'agit de mettre en oeuvre un RNN avec plusieurs variables. Sans aller chercher l'action d'une autre entreprise des GAFA par exemple, on va se contenter pour simplifier ici d'uitiliser les autres variables disponibles dans le dataset (Open, High et Low).\n",
    "\n",
    "1. À vous de modifier votre code pour prendre en compte dans votre modèle les 4 informations Open, High, Low et Close.\n",
    "2. Comparer les prédictions obtenues (et les temps d'exécution !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
