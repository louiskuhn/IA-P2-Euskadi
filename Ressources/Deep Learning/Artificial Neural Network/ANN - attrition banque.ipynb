{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de neurones et attrition des clients bancaires\n",
    "\n",
    "Réseau de neurones avec Python (Keras)\n",
    "\n",
    "## La problématique\n",
    "\n",
    "On s'intéresse ici à une problème classique du domaine bancaire (mais pas que !) qui est l'attrition ou *churn* en anglais et correspond à la perte de client. \n",
    "Récemment de nombreux clients ont quitté la banque Crédit Friqué. La question est de comprendre pourquoi ces départs ? Ou plutôt de prédire s'ils vont partir...\n",
    "\n",
    "## Les données\n",
    "\n",
    "Pour répondre à cette question, la banque a sélectionné 6 mois plus tôt un sous ensemble de ses clients pour lesquels elle a stocké un certain nombre d’information puis, dans les 6 mois qui ont suivis, elle a observé si les clients avaient quitté ou non la banque. Vous voilà donc, 6 mois plus tard, contacté par la banque qui vous propose un beau dataset (pour une fois!) et vous demande de déterminer les profils des clients les plus à même de partir.\n",
    "Vous disposez du fichier banque_abandon.csv qui est la base de données de la banque virtuelle Crédit Friqué.\n",
    "\n",
    "## Quelques questions préliminaires\n",
    "\n",
    "C'est juste pour vous échauffer donc ça doit être fait en moins d'une heure ça !\n",
    "1. À quoi correspondent les différentes variables du datasets ?\n",
    "2. Pour pas perdre les bonnes habitudes, faites quelques visualisations pour voir ce qu'il y a dans vos données.\n",
    "3. À quelle type de problème avez-vous à faire ici : classification ou régression ?\n",
    ">- Lister un certain nombre de modèles vous permettant de le résoudre\n",
    ">- Lister les métriques associées à ce type de problème\n",
    ">- Choisir un modèle, l'entraîner et l'évaluer avec la métrique de votre choix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flemme de tout refaire et vous commencez à être au point là dessus normalement\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "df = pd.read_csv('data/banque_abandon.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.000500e+03</td>\n",
       "      <td>2886.895680</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2500.75</td>\n",
       "      <td>5.000500e+03</td>\n",
       "      <td>7.500250e+03</td>\n",
       "      <td>10000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>71936.186123</td>\n",
       "      <td>15565701.00</td>\n",
       "      <td>15628528.25</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>15815690.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>6.505288e+02</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>350.00</td>\n",
       "      <td>584.00</td>\n",
       "      <td>6.520000e+02</td>\n",
       "      <td>7.180000e+02</td>\n",
       "      <td>850.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.892180e+01</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>18.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.012800e+00</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.648589e+04</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.719854e+04</td>\n",
       "      <td>1.276442e+05</td>\n",
       "      <td>250898.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.530200e+00</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.055000e-01</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.151000e-01</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.000902e+05</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>11.58</td>\n",
       "      <td>51002.11</td>\n",
       "      <td>1.001939e+05</td>\n",
       "      <td>1.493882e+05</td>\n",
       "      <td>199992.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.037000e-01</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count          mean           std          min  \\\n",
       "RowNumber        10000.0  5.000500e+03   2886.895680         1.00   \n",
       "CustomerId       10000.0  1.569094e+07  71936.186123  15565701.00   \n",
       "CreditScore      10000.0  6.505288e+02     96.653299       350.00   \n",
       "Age              10000.0  3.892180e+01     10.487806        18.00   \n",
       "Tenure           10000.0  5.012800e+00      2.892174         0.00   \n",
       "Balance          10000.0  7.648589e+04  62397.405202         0.00   \n",
       "NumOfProducts    10000.0  1.530200e+00      0.581654         1.00   \n",
       "HasCrCard        10000.0  7.055000e-01      0.455840         0.00   \n",
       "IsActiveMember   10000.0  5.151000e-01      0.499797         0.00   \n",
       "EstimatedSalary  10000.0  1.000902e+05  57510.492818        11.58   \n",
       "Exited           10000.0  2.037000e-01      0.402769         0.00   \n",
       "\n",
       "                         25%           50%           75%          max  \n",
       "RowNumber            2500.75  5.000500e+03  7.500250e+03     10000.00  \n",
       "CustomerId       15628528.25  1.569074e+07  1.575323e+07  15815690.00  \n",
       "CreditScore           584.00  6.520000e+02  7.180000e+02       850.00  \n",
       "Age                    32.00  3.700000e+01  4.400000e+01        92.00  \n",
       "Tenure                  3.00  5.000000e+00  7.000000e+00        10.00  \n",
       "Balance                 0.00  9.719854e+04  1.276442e+05    250898.09  \n",
       "NumOfProducts           1.00  1.000000e+00  2.000000e+00         4.00  \n",
       "HasCrCard               0.00  1.000000e+00  1.000000e+00         1.00  \n",
       "IsActiveMember          0.00  1.000000e+00  1.000000e+00         1.00  \n",
       "EstimatedSalary     51002.11  1.001939e+05  1.493882e+05    199992.48  \n",
       "Exited                  0.00  0.000000e+00  0.000000e+00         1.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df==0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dans le vif du sujet\n",
    "\n",
    "Vous l'aurez compris, il s'agit ici de résoudre le problème à l'aide d'un réseau de neurones.   \n",
    "Vous aurez bien sûr besoin du package `keras` et il vous faudra aussi certainement installer `tensorflow`(et peut-être `theano` si besoin).  \n",
    "À vous de jouer !\n",
    "N'oubliez pas le preprocessing !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# création des tables X et y\n",
    "X = df.iloc[:, 3:13] # pour virer row, id et nom\n",
    "y = df.iloc[:, 13]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography\n",
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.value_counts('Geography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (2000, 10), (8000,), (2000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# échantillons train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 11), (2000, 11))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot-encoding sur les variables catégoriques\n",
    "# feature scaling sur les numériques\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "\n",
    "preprocessing = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), ['Geography', 'Gender']),\n",
    "    (StandardScaler(), make_column_selector(dtype_exclude='object')))\n",
    "\n",
    "X_train_pp =  preprocessing.fit_transform(X_train)\n",
    "X_test_pp =  preprocessing.transform(X_test)\n",
    "X_train_pp.shape, X_test_pp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 08:49:31.483609: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 08:49:31.510261: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 08:49:31.511696: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f71bf68bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 08:49:31.511756: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "400/400 [==============================] - 0s 834us/step - loss: 0.5185 - accuracy: 0.7617 - val_loss: 0.4498 - val_accuracy: 0.7980\n",
      "Epoch 2/100\n",
      "400/400 [==============================] - 0s 657us/step - loss: 0.4359 - accuracy: 0.8043 - val_loss: 0.4302 - val_accuracy: 0.8085\n",
      "Epoch 3/100\n",
      "400/400 [==============================] - 0s 643us/step - loss: 0.4230 - accuracy: 0.8159 - val_loss: 0.4201 - val_accuracy: 0.8160\n",
      "Epoch 4/100\n",
      "400/400 [==============================] - 0s 644us/step - loss: 0.4144 - accuracy: 0.8257 - val_loss: 0.4126 - val_accuracy: 0.8245\n",
      "Epoch 5/100\n",
      "400/400 [==============================] - 0s 679us/step - loss: 0.4063 - accuracy: 0.8274 - val_loss: 0.4043 - val_accuracy: 0.8315\n",
      "Epoch 6/100\n",
      "400/400 [==============================] - 0s 738us/step - loss: 0.3995 - accuracy: 0.8296 - val_loss: 0.3976 - val_accuracy: 0.8320\n",
      "Epoch 7/100\n",
      "400/400 [==============================] - 0s 696us/step - loss: 0.3938 - accuracy: 0.8300 - val_loss: 0.3932 - val_accuracy: 0.8335\n",
      "Epoch 8/100\n",
      "400/400 [==============================] - 0s 714us/step - loss: 0.3883 - accuracy: 0.8313 - val_loss: 0.3873 - val_accuracy: 0.8335\n",
      "Epoch 9/100\n",
      "400/400 [==============================] - 0s 761us/step - loss: 0.3847 - accuracy: 0.8310 - val_loss: 0.3844 - val_accuracy: 0.8330\n",
      "Epoch 10/100\n",
      "400/400 [==============================] - 0s 755us/step - loss: 0.3808 - accuracy: 0.8328 - val_loss: 0.3787 - val_accuracy: 0.8320\n",
      "Epoch 11/100\n",
      "400/400 [==============================] - 0s 745us/step - loss: 0.3769 - accuracy: 0.8329 - val_loss: 0.3751 - val_accuracy: 0.8300\n",
      "Epoch 12/100\n",
      "400/400 [==============================] - 0s 737us/step - loss: 0.3741 - accuracy: 0.8346 - val_loss: 0.3736 - val_accuracy: 0.8345\n",
      "Epoch 13/100\n",
      "400/400 [==============================] - 0s 697us/step - loss: 0.3702 - accuracy: 0.8420 - val_loss: 0.3694 - val_accuracy: 0.8480\n",
      "Epoch 14/100\n",
      "400/400 [==============================] - 0s 735us/step - loss: 0.3666 - accuracy: 0.8480 - val_loss: 0.3642 - val_accuracy: 0.8490\n",
      "Epoch 15/100\n",
      "400/400 [==============================] - 0s 772us/step - loss: 0.3625 - accuracy: 0.8501 - val_loss: 0.3638 - val_accuracy: 0.8515\n",
      "Epoch 16/100\n",
      "400/400 [==============================] - 0s 806us/step - loss: 0.3591 - accuracy: 0.8528 - val_loss: 0.3580 - val_accuracy: 0.8515\n",
      "Epoch 17/100\n",
      "400/400 [==============================] - 0s 695us/step - loss: 0.3550 - accuracy: 0.8522 - val_loss: 0.3564 - val_accuracy: 0.8555\n",
      "Epoch 18/100\n",
      "400/400 [==============================] - 0s 808us/step - loss: 0.3521 - accuracy: 0.8559 - val_loss: 0.3544 - val_accuracy: 0.8555\n",
      "Epoch 19/100\n",
      "400/400 [==============================] - 0s 701us/step - loss: 0.3495 - accuracy: 0.8590 - val_loss: 0.3509 - val_accuracy: 0.8605\n",
      "Epoch 20/100\n",
      "400/400 [==============================] - 0s 772us/step - loss: 0.3466 - accuracy: 0.8574 - val_loss: 0.3525 - val_accuracy: 0.8555\n",
      "Epoch 21/100\n",
      "400/400 [==============================] - 0s 719us/step - loss: 0.3446 - accuracy: 0.8599 - val_loss: 0.3465 - val_accuracy: 0.8585\n",
      "Epoch 22/100\n",
      "400/400 [==============================] - 0s 700us/step - loss: 0.3429 - accuracy: 0.8618 - val_loss: 0.3445 - val_accuracy: 0.8560\n",
      "Epoch 23/100\n",
      "400/400 [==============================] - 0s 709us/step - loss: 0.3413 - accuracy: 0.8596 - val_loss: 0.3482 - val_accuracy: 0.8610\n",
      "Epoch 24/100\n",
      "400/400 [==============================] - 0s 735us/step - loss: 0.3401 - accuracy: 0.8630 - val_loss: 0.3455 - val_accuracy: 0.8590\n",
      "Epoch 25/100\n",
      "400/400 [==============================] - 0s 759us/step - loss: 0.3394 - accuracy: 0.8612 - val_loss: 0.3454 - val_accuracy: 0.8615\n",
      "Epoch 26/100\n",
      "400/400 [==============================] - 0s 696us/step - loss: 0.3381 - accuracy: 0.8608 - val_loss: 0.3437 - val_accuracy: 0.8560\n",
      "Epoch 27/100\n",
      "400/400 [==============================] - 0s 612us/step - loss: 0.3375 - accuracy: 0.8610 - val_loss: 0.3462 - val_accuracy: 0.8570\n",
      "Epoch 28/100\n",
      "400/400 [==============================] - 0s 681us/step - loss: 0.3372 - accuracy: 0.8605 - val_loss: 0.3445 - val_accuracy: 0.8585\n",
      "Epoch 29/100\n",
      "400/400 [==============================] - 0s 809us/step - loss: 0.3369 - accuracy: 0.8621 - val_loss: 0.3452 - val_accuracy: 0.8590\n",
      "Epoch 30/100\n",
      "400/400 [==============================] - 0s 742us/step - loss: 0.3362 - accuracy: 0.8620 - val_loss: 0.3430 - val_accuracy: 0.8595\n",
      "Epoch 31/100\n",
      "400/400 [==============================] - 0s 704us/step - loss: 0.3356 - accuracy: 0.8637 - val_loss: 0.3439 - val_accuracy: 0.8605\n",
      "Epoch 32/100\n",
      "400/400 [==============================] - 0s 734us/step - loss: 0.3359 - accuracy: 0.8618 - val_loss: 0.3450 - val_accuracy: 0.8600\n",
      "Epoch 33/100\n",
      "400/400 [==============================] - 0s 664us/step - loss: 0.3349 - accuracy: 0.8633 - val_loss: 0.3439 - val_accuracy: 0.8580\n",
      "Epoch 34/100\n",
      "400/400 [==============================] - 0s 619us/step - loss: 0.3348 - accuracy: 0.8631 - val_loss: 0.3447 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "400/400 [==============================] - 0s 763us/step - loss: 0.3344 - accuracy: 0.8639 - val_loss: 0.3443 - val_accuracy: 0.8570\n",
      "Epoch 36/100\n",
      "400/400 [==============================] - 0s 629us/step - loss: 0.3343 - accuracy: 0.8635 - val_loss: 0.3456 - val_accuracy: 0.8605\n",
      "Epoch 37/100\n",
      "400/400 [==============================] - 0s 719us/step - loss: 0.3345 - accuracy: 0.8635 - val_loss: 0.3452 - val_accuracy: 0.8580\n",
      "Epoch 38/100\n",
      "400/400 [==============================] - 0s 718us/step - loss: 0.3339 - accuracy: 0.8629 - val_loss: 0.3441 - val_accuracy: 0.8595\n",
      "Epoch 39/100\n",
      "400/400 [==============================] - 0s 785us/step - loss: 0.3336 - accuracy: 0.8631 - val_loss: 0.3438 - val_accuracy: 0.8595\n",
      "Epoch 40/100\n",
      "400/400 [==============================] - 0s 745us/step - loss: 0.3329 - accuracy: 0.8664 - val_loss: 0.3451 - val_accuracy: 0.8565\n",
      "Epoch 41/100\n",
      "400/400 [==============================] - 0s 848us/step - loss: 0.3331 - accuracy: 0.8615 - val_loss: 0.3420 - val_accuracy: 0.8580\n",
      "Epoch 42/100\n",
      "400/400 [==============================] - 0s 756us/step - loss: 0.3329 - accuracy: 0.8630 - val_loss: 0.3435 - val_accuracy: 0.8595\n",
      "Epoch 43/100\n",
      "400/400 [==============================] - 0s 682us/step - loss: 0.3319 - accuracy: 0.8639 - val_loss: 0.3460 - val_accuracy: 0.8585\n",
      "Epoch 44/100\n",
      "400/400 [==============================] - 0s 735us/step - loss: 0.3324 - accuracy: 0.8652 - val_loss: 0.3445 - val_accuracy: 0.8570\n",
      "Epoch 45/100\n",
      "400/400 [==============================] - 0s 829us/step - loss: 0.3323 - accuracy: 0.8630 - val_loss: 0.3444 - val_accuracy: 0.8585\n",
      "Epoch 46/100\n",
      "400/400 [==============================] - 0s 780us/step - loss: 0.3326 - accuracy: 0.8634 - val_loss: 0.3420 - val_accuracy: 0.8580\n",
      "Epoch 47/100\n",
      "400/400 [==============================] - 0s 608us/step - loss: 0.3316 - accuracy: 0.8633 - val_loss: 0.3446 - val_accuracy: 0.8580\n",
      "Epoch 48/100\n",
      "400/400 [==============================] - 0s 615us/step - loss: 0.3325 - accuracy: 0.8637 - val_loss: 0.3424 - val_accuracy: 0.8590\n",
      "Epoch 49/100\n",
      "400/400 [==============================] - 0s 727us/step - loss: 0.3319 - accuracy: 0.8656 - val_loss: 0.3449 - val_accuracy: 0.8585\n",
      "Epoch 50/100\n",
      "400/400 [==============================] - 0s 738us/step - loss: 0.3318 - accuracy: 0.8640 - val_loss: 0.3424 - val_accuracy: 0.8585\n",
      "Epoch 51/100\n",
      "400/400 [==============================] - 0s 740us/step - loss: 0.3317 - accuracy: 0.8634 - val_loss: 0.3438 - val_accuracy: 0.8595\n",
      "Epoch 52/100\n",
      "400/400 [==============================] - 0s 658us/step - loss: 0.3312 - accuracy: 0.8665 - val_loss: 0.3418 - val_accuracy: 0.8565\n",
      "Epoch 53/100\n",
      "400/400 [==============================] - 0s 703us/step - loss: 0.3309 - accuracy: 0.8658 - val_loss: 0.3433 - val_accuracy: 0.8560\n",
      "Epoch 54/100\n",
      "400/400 [==============================] - 0s 699us/step - loss: 0.3309 - accuracy: 0.8662 - val_loss: 0.3406 - val_accuracy: 0.8580\n",
      "Epoch 55/100\n",
      "400/400 [==============================] - 0s 814us/step - loss: 0.3300 - accuracy: 0.8655 - val_loss: 0.3447 - val_accuracy: 0.8560\n",
      "Epoch 56/100\n",
      "400/400 [==============================] - 0s 646us/step - loss: 0.3294 - accuracy: 0.8656 - val_loss: 0.3422 - val_accuracy: 0.8575\n",
      "Epoch 57/100\n",
      "400/400 [==============================] - 0s 676us/step - loss: 0.3308 - accuracy: 0.8660 - val_loss: 0.3415 - val_accuracy: 0.8545\n",
      "Epoch 58/100\n",
      "400/400 [==============================] - 0s 682us/step - loss: 0.3305 - accuracy: 0.8644 - val_loss: 0.3411 - val_accuracy: 0.8560\n",
      "Epoch 59/100\n",
      "400/400 [==============================] - 0s 818us/step - loss: 0.3301 - accuracy: 0.8659 - val_loss: 0.3426 - val_accuracy: 0.8605\n",
      "Epoch 60/100\n",
      "400/400 [==============================] - 0s 861us/step - loss: 0.3299 - accuracy: 0.8645 - val_loss: 0.3421 - val_accuracy: 0.8580\n",
      "Epoch 61/100\n",
      "400/400 [==============================] - 0s 864us/step - loss: 0.3302 - accuracy: 0.8644 - val_loss: 0.3424 - val_accuracy: 0.8590\n",
      "Epoch 62/100\n",
      "400/400 [==============================] - 0s 652us/step - loss: 0.3294 - accuracy: 0.8662 - val_loss: 0.3419 - val_accuracy: 0.8590\n",
      "Epoch 63/100\n",
      "400/400 [==============================] - 0s 687us/step - loss: 0.3296 - accuracy: 0.8664 - val_loss: 0.3416 - val_accuracy: 0.8575\n",
      "Epoch 64/100\n",
      "400/400 [==============================] - 0s 640us/step - loss: 0.3294 - accuracy: 0.8665 - val_loss: 0.3423 - val_accuracy: 0.8565\n",
      "Epoch 65/100\n",
      "400/400 [==============================] - 0s 767us/step - loss: 0.3294 - accuracy: 0.8659 - val_loss: 0.3445 - val_accuracy: 0.8615\n",
      "Epoch 66/100\n",
      "400/400 [==============================] - 0s 682us/step - loss: 0.3298 - accuracy: 0.8655 - val_loss: 0.3411 - val_accuracy: 0.8585\n",
      "Epoch 67/100\n",
      "400/400 [==============================] - 0s 776us/step - loss: 0.3288 - accuracy: 0.8668 - val_loss: 0.3435 - val_accuracy: 0.8550\n",
      "Epoch 68/100\n",
      "400/400 [==============================] - 0s 626us/step - loss: 0.3290 - accuracy: 0.8662 - val_loss: 0.3449 - val_accuracy: 0.8585\n",
      "Epoch 69/100\n",
      "400/400 [==============================] - 0s 626us/step - loss: 0.3289 - accuracy: 0.8673 - val_loss: 0.3433 - val_accuracy: 0.8600\n",
      "Epoch 70/100\n",
      "400/400 [==============================] - 0s 633us/step - loss: 0.3284 - accuracy: 0.8662 - val_loss: 0.3424 - val_accuracy: 0.8585\n",
      "Epoch 71/100\n",
      "400/400 [==============================] - 0s 614us/step - loss: 0.3285 - accuracy: 0.8664 - val_loss: 0.3421 - val_accuracy: 0.8565\n",
      "Epoch 72/100\n",
      "400/400 [==============================] - 0s 781us/step - loss: 0.3286 - accuracy: 0.8658 - val_loss: 0.3410 - val_accuracy: 0.8585\n",
      "Epoch 73/100\n",
      "400/400 [==============================] - 0s 660us/step - loss: 0.3284 - accuracy: 0.8654 - val_loss: 0.3424 - val_accuracy: 0.8560\n",
      "Epoch 74/100\n",
      "400/400 [==============================] - 0s 774us/step - loss: 0.3280 - accuracy: 0.8655 - val_loss: 0.3427 - val_accuracy: 0.8580\n",
      "Epoch 75/100\n",
      "400/400 [==============================] - 0s 688us/step - loss: 0.3283 - accuracy: 0.8634 - val_loss: 0.3435 - val_accuracy: 0.8585\n",
      "Epoch 76/100\n",
      "400/400 [==============================] - 0s 772us/step - loss: 0.3285 - accuracy: 0.8661 - val_loss: 0.3440 - val_accuracy: 0.8585\n",
      "Epoch 77/100\n",
      "400/400 [==============================] - 0s 687us/step - loss: 0.3286 - accuracy: 0.8662 - val_loss: 0.3412 - val_accuracy: 0.8545\n",
      "Epoch 78/100\n",
      "400/400 [==============================] - 0s 800us/step - loss: 0.3281 - accuracy: 0.8668 - val_loss: 0.3433 - val_accuracy: 0.8580\n",
      "Epoch 79/100\n",
      "400/400 [==============================] - 0s 641us/step - loss: 0.3288 - accuracy: 0.8648 - val_loss: 0.3414 - val_accuracy: 0.8570\n",
      "Epoch 80/100\n",
      "400/400 [==============================] - 0s 634us/step - loss: 0.3276 - accuracy: 0.8661 - val_loss: 0.3435 - val_accuracy: 0.8585\n",
      "Epoch 81/100\n",
      "400/400 [==============================] - 0s 674us/step - loss: 0.3285 - accuracy: 0.8658 - val_loss: 0.3428 - val_accuracy: 0.8600\n",
      "Epoch 82/100\n",
      "400/400 [==============================] - 0s 716us/step - loss: 0.3268 - accuracy: 0.8677 - val_loss: 0.3500 - val_accuracy: 0.8555\n",
      "Epoch 83/100\n",
      "400/400 [==============================] - 0s 637us/step - loss: 0.3281 - accuracy: 0.8652 - val_loss: 0.3425 - val_accuracy: 0.8585\n",
      "Epoch 84/100\n",
      "400/400 [==============================] - 0s 636us/step - loss: 0.3278 - accuracy: 0.8666 - val_loss: 0.3427 - val_accuracy: 0.8590\n",
      "Epoch 85/100\n",
      "400/400 [==============================] - 0s 647us/step - loss: 0.3277 - accuracy: 0.8658 - val_loss: 0.3425 - val_accuracy: 0.8590\n",
      "Epoch 86/100\n",
      "400/400 [==============================] - 0s 647us/step - loss: 0.3278 - accuracy: 0.8658 - val_loss: 0.3417 - val_accuracy: 0.8565\n",
      "Epoch 87/100\n",
      "400/400 [==============================] - 0s 667us/step - loss: 0.3278 - accuracy: 0.8659 - val_loss: 0.3422 - val_accuracy: 0.8565\n",
      "Epoch 88/100\n",
      "400/400 [==============================] - 0s 722us/step - loss: 0.3277 - accuracy: 0.8676 - val_loss: 0.3416 - val_accuracy: 0.8575\n",
      "Epoch 89/100\n",
      "400/400 [==============================] - 0s 647us/step - loss: 0.3277 - accuracy: 0.8673 - val_loss: 0.3414 - val_accuracy: 0.8565\n",
      "Epoch 90/100\n",
      "400/400 [==============================] - 0s 630us/step - loss: 0.3278 - accuracy: 0.8674 - val_loss: 0.3413 - val_accuracy: 0.8575\n",
      "Epoch 91/100\n",
      "400/400 [==============================] - 0s 612us/step - loss: 0.3274 - accuracy: 0.8654 - val_loss: 0.3435 - val_accuracy: 0.8575\n",
      "Epoch 92/100\n",
      "400/400 [==============================] - 0s 627us/step - loss: 0.3279 - accuracy: 0.8670 - val_loss: 0.3416 - val_accuracy: 0.8555\n",
      "Epoch 93/100\n",
      "400/400 [==============================] - 0s 645us/step - loss: 0.3274 - accuracy: 0.8677 - val_loss: 0.3416 - val_accuracy: 0.8575\n",
      "Epoch 94/100\n",
      "400/400 [==============================] - 0s 695us/step - loss: 0.3274 - accuracy: 0.8679 - val_loss: 0.3450 - val_accuracy: 0.8580\n",
      "Epoch 95/100\n",
      "400/400 [==============================] - 0s 627us/step - loss: 0.3273 - accuracy: 0.8660 - val_loss: 0.3424 - val_accuracy: 0.8560\n",
      "Epoch 96/100\n",
      "400/400 [==============================] - 0s 644us/step - loss: 0.3271 - accuracy: 0.8674 - val_loss: 0.3461 - val_accuracy: 0.8555\n",
      "Epoch 97/100\n",
      "400/400 [==============================] - 0s 689us/step - loss: 0.3269 - accuracy: 0.8676 - val_loss: 0.3424 - val_accuracy: 0.8575\n",
      "Epoch 98/100\n",
      "400/400 [==============================] - 0s 634us/step - loss: 0.3273 - accuracy: 0.8680 - val_loss: 0.3423 - val_accuracy: 0.8565\n",
      "Epoch 99/100\n",
      "400/400 [==============================] - 0s 673us/step - loss: 0.3269 - accuracy: 0.8655 - val_loss: 0.3431 - val_accuracy: 0.8560\n",
      "Epoch 100/100\n",
      "400/400 [==============================] - 0s 679us/step - loss: 0.3269 - accuracy: 0.8671 - val_loss: 0.3401 - val_accuracy: 0.8555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf54551460>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on passe à l'ANN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# architecture\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=8, activation='relu', input_dim=11))\n",
    "mlp.add(Dense(units=6, activation='relu'))\n",
    "mlp.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# paramètres d'apprentissage\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# entrainement\n",
    "mlp.fit(X_train_pp, y_train, epochs=100, batch_size=20, validation_data=(X_test_pp, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD4CAYAAADM6gxlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAM7klEQVR4nO3beXBV5RnH8d+bmwCh7GCIYRcNgiBYCWAVxaWIC6WKOO5LmUat4AKtQkQhUQRUHBcoi4GCoKAWFQG3uoAiKKGKoEYQKWiKWUVZNdvbP4KpUZIImJw8ud/PTGaSc86d89yZy5eTc944770AAHZEBD0AAODgEG4AMIZwA4AxhBsAjCHcAGBMZFWf4HrXiGUrqLGm7/ky6BGAA6vf2JW3iytuADCGcAOAMYQbAIwh3ABgDOEGAGMINwAYQ7gBwBjCDQDGEG4AMIZwA4AxhBsAjCHcAGAM4QYAYwg3ABhDuAHAGMINAMYQbgAwhnADgDGEGwCMIdwAYAzhBgBjCDcAGEO4AcAYwg0AxhBuADCGcAOAMYQbAIwh3ABgDOEGAGMINwAYQ7gBwBjCDQDGEG4AMIZwA4AxhBsAjCHcAGAM4QYAYwg3ABhDuAHAGMINAMYQbgAwhnADgDGEGwCMIdwAYAzhBgBjCDcAGEO4AcAYwg0AxhBuADCGcAOAMZFBDxDurpw1Vd3OH6Bd2Tm6u1sfSdL5Y0frlD9frV05uZKkxUkp+uilV9U+4URdPvNhSZJzTkvHTdC655dKkgbdc6d6X3Wp6jdtolsaxgXzZhBWdu7apTHJ47Xp88/lnNO9Y8fo1TeW68233lZUVJTatm6lCcl3qVHDhkGPWus4732VnuB616hqT2Dc0X1/p+9379E1j88oE+7vd+/WvyY/WubYqOhoFeXnq7ioSI1iW2rMh6s0Ki5exUVF6tA7QXnbvlDKZx8Q7oMwfc+XQY9g1u13jlPPE3poyIV/VH5Bgb777jut/+hj9UnoqcjISN3/cMnn9283Dw94UqPqN3bl7eJWScA2v71Ke7/e8YuOLdi3T8VFRZKkqHr1pB/9p/uf99K0MzOrSmYEfmr37t1Ke/8DXXTBIElSnagoNWrYUKec1EeRkSW/yPfo1lWZWdlBjllrVXqrxDl3rKRBklpJ8pK2S3rBe59exbOFtX7DEtX7qku1be0HWjTyDu395htJUvtePXXV7Klq1q6N5lyZWBpyoDp9+d/tata0qUaPTdGnmz7TcZ2P1R23jVT96OjSYxYtXqJz+v8+wClrrwqvuJ1zt0taKMlJWiMpbf/3C5xzoyp4XaJzbq1zbu0nyv815w0LK6alakzH7hrf42Tt/CpTgyePL923dc1apXTtrYkJ/TRg9EhF1q0b4KQIV4WFhfrk0426dMhgPb9wvqKjozVz9tzS/dNSZysUCukP5w4IcMraq7JbJUMlJXjvJ3rv5+//miip1/59B+S9n+m97+m979lFdX7NecPCruwc+eJiee+18rG5at/rxJ8dk/npJn2/Z4/iunYJYEKEu9iWMYqNiVH3bl0lSQPOOkOffLpRkvTcC0u1/K2VemD83XKu3Nu0OAyVhbtY0oGedB25fx+qQKPYlqXf97hgoLZ/VHJXqnn7dooIhSRJzdq2UctOxyhv67ZAZkR4O6JFC8XGxmjL/s/f6jVp6nhUB731zmo9Nmeepj00WdHR9QKesvaqcFWJc26ApCmSPpP0w+P3tpKOljTMe/9yZSdgVUnFhj45W/H9TlGDFs21MytbS8beq/h+fdWmRzd575W39Qs9cd3N2pmZpd5XXKKzR92qooIC+eJiLUuZpA8XL5MkXTgpRQmXDVHjuCP17fav9E7q41qaPCHgd1fzsark0KVv3KQ7ku9RQWGh2rSK04Tku3TRFdcoPz9fTRo3liR179ZVKWNGBzypURWsKql0OaBzLkIlt0ZaqeT+doakNO/9L3oqRrhRkxFu1FgVhLvSVSXe+2JJ7/6qAwEADhnruAHAGMINAMYQbgAwhnADgDGEGwCMIdwAYAzhBgBjCDcAGEO4AcAYwg0AxhBuADCGcAOAMYQbAIwh3ABgDOEGAGMINwAYQ7gBwBjCDQDGEG4AMIZwA4AxhBsAjCHcAGAM4QYAYwg3ABhDuAHAGMINAMYQbgAwhnADgDGEGwCMIdwAYAzhBgBjCDcAGEO4AcAYwg0AxhBuADCGcAOAMYQbAIwh3ABgDOEGAGMINwAYQ7gBwBjCDQDGEG4AMIZwA4AxhBsAjCHcAGAM4QYAYwg3ABjjvPdVegKfkV61JwAOR1TdoCcADsi1PMqVt48rbgAwhnADgDGEGwCMIdwAYAzhBgBjCDcAGEO4AcAYwg0AxhBuADCGcAOAMYQbAIwh3ABgDOEGAGMINwAYQ7gBwBjCDQDGEG4AMIZwA4AxhBsAjCHcAGAM4QYAYwg3ABhDuAHAGMINAMYQbgAwhnADgDGEGwCMIdwAYAzhBgBjCDcAGEO4AcAYwg0AxhBuADCGcAOAMYQbAIwh3ABgDOEGAGMINwAYQ7gBwBjCDQDGEG4AMIZwA4AxhBsAjCHcAGAM4QYAYwg3ABhDuAHAGMINAMYQbgAwJjLoAfB/X2Xn6PaJDyt3xzeKcE4Xn9dfVw0eqPtmzNGbq9MUFRmptnGxuve24WrUoIGWvLZCs55+rvT1G7ds07PTJ6vz0UcF+C5QWyVNfFDLV61R86ZNtGTudElS+mefa9zkR/V9foFCoZDG3nqjju/SSZI0Y/5TWrTsFUVEROiOm29Q314nBjl+reK891V6Ap+RXrUnqEWy875WTt4OHRffUbv37tPg60dqaspoZebmqs8JxysyFNIDM+dKkv6aeHWZ127cslU33jVBr82fEcTodkXVDXoCM9LWbVD96GiNuveB0nD/aUSSrrn4Ap3aJ0ErVq9R6oJ/at4j92nz1m0amTxJz8x4SNm5X+vaEaP18hOpCoVCAb8LO1zLo1x5+7hVUoPENG+m4+I7SpIa1I9Wx3atlZWbp1N6nqDI/R/47l06KTM372evXfbG2zrv9L7VOi/CS0KPbmrcqGGZbc457d6zV5K0a89exbRoLkl6feW7OvfM01SnTh21jotV21ZxWp++qdpnrq0Idw2VkZml9M1b1L1zfJnti156Tacm/PZnx7+0fKXOO4Nwo3olDb9O90+bpX6Dr9R9f0/ViMRrJElZOXk6MuaI0uNij2ihrNzcgKasfQ453M65ayvYl+icW+ucWzvziacP9RRha8++fbpp3CSN/stQNfhN/dLt0594RpGhkAaedVqZ4z9M36R69eoqvkO76h4VYW7B4mUaNSxRyxfN0+hhiRoz6aGSHQe4BetU7m/+OEiHc8WdXN4O7/1M731P733PxMsvPoxThJ+CwkLdNG6SBp55mvr3Pal0+3OvvKE3V6/V/Ukj5FzZfwAvvsltEgTj+ZdfU//TTpYkDTi9r9anb5QktYxpoa+yc0qPy8zJLb2NgsNXYbidc+vL+dogqWU1zRg2vPca88AUdWzbWtcOGVS6/e017yt14bOadk+SouuVfZhWXFysl1esItwIREzz5lqzboMk6d3316ld61aSpDNO7qMXX1+h/Px8ZWzP1LaM7Tr+J7f9cOgqXFXinMuSdLakHT/dJWmV9z6ushOwquSX+/eGT3T5LUmK79BOERElV9W3Dr1C46ekKr+gQE32Pxjq3rmTkm+9QZL03roNejB1np6acl9gc5vGqpJfbETyRKV9sF47vt2p5s2aaPi1V6pD21Ya/8gMFRUVqW6dOrprxI3q2ukYSdL0xxdo0YuvKhQKKWn4dTq1T0LA78CWilaVVBbuWZL+4b1feYB9T3rvL6vs5IQbNRrhRg11yOH+NRBu1GiEGzUU67gBoBYh3ABgDOEGAGMINwAYQ7gBwBjCDQDGEG4AMIZwA4AxhBsAjCHcAGAM4QYAYwg3ABhDuAHAGMINAMYQbgAwhnADgDGEGwCMIdwAYAzhBgBjCDcAGEO4AcAYwg0AxhBuADCGcAOAMYQbAIwh3ABgDOEGAGMINwAYQ7gBwBjCDQDGEG4AMIZwA4AxhBsAjCHcAGAM4QYAYwg3ABhDuAHAGMINAMYQbgAwhnADgDGEGwCMIdwAYAzhBgBjCDcAGEO4AcAYwg0AxhBuADCGcAOAMYQbAIxx3vugZ8BBcM4leu9nBj0H8FN8NqsPV9z2JAY9AFAOPpvVhHADgDGEGwCMIdz2cA8RNRWfzWrCw0kAMIYrbgAwhnADgDGE2wjn3ADn3Ebn3Gbn3Kig5wF+4Jyb7ZzLds59FPQs4YJwG+CcC0maKukcSV0kXeqc6xLsVECpOZIGBD1EOCHcNvSStNl7v8V7ny9poaRBAc8ESJK8929J+jroOcIJ4bahlaQvf/Rzxv5tAMIQ4bbBHWAb6ziBMEW4bciQ1OZHP7eWtD2gWQAEjHDbkCbpGOdcB+dcHUmXSHoh4JkABIRwG+C9L5Q0TNIrktIlPe29/zjYqYASzrkFklZL6uScy3DODQ16ptqOP3kHAGO44gYAYwg3ABhDuAHAGMINAMYQbgAwhnADgDGEGwCM+R+XbPZWFmFVawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions sur le testset\n",
    "y_pred = mlp.predict(X_test_pp)\n",
    "classes_pred = 1 * (y_pred > 0.5)\n",
    "\n",
    "# matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "sns.heatmap(confusion_matrix(y_test, classes_pred),\n",
    "            annot=True, cbar=False, fmt='d', cmap='Reds');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      1593\n",
      "           1       0.74      0.44      0.55       407\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.81      0.70      0.73      2000\n",
      "weighted avg       0.85      0.86      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, classes_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rappel : 180/(180+227) = 0.44226044226044225\n",
      "Précision : 180/(180+62) = 0.743801652892562\n"
     ]
    }
   ],
   "source": [
    "print(f'Rappel : {180/(180+227) = }')\n",
    "print(f'Précision : {180/(180+62) = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation du réseau et affinage des hyper-paramètres\n",
    "\n",
    "Jusqu'à maintenant, on a évalué les réseaux qu'on a vu en regardant uniquement l'accuracy mais cette valeur n'est pas déterministe puisqu'elle dépend de certains paramètres aléatoires comme le train_test_split, l'intialisation des paramètres etc...\n",
    "\n",
    "Une solution par rapport à ce problème est de répéter l'entraînement plusieurs fois et de regarder les résultats en moyenne. On l'a déjà utilisé et ça s'appelle la validation croisée.\n",
    "\n",
    "Mettez en place la validation croisée en utilisant `cross_val_score` puis affiner les paramètres avec `GridSearchCV`.\n",
    "\n",
    "__/!\\\\__ Vous aurez besoin de ce qu'on appelle un wrapper pour pouvoir relier `keras` à `sklearn` et utiliser un modèle de l'un dans l'autre. Ça tombe bien, ça existe : regarder la librairie `keras.wrappers.scikit_learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition d'une fonction pour instancier le modèle\n",
    "def build_ann_clf(optimizer='adam'):\n",
    "    clf = Sequential()\n",
    "    clf.add(Dense(units=8, activation='relu', input_dim=11))\n",
    "    clf.add(Dense(units=6, activation='relu'))\n",
    "    clf.add(Dense(units=1, activation='sigmoid'))\n",
    "    clf.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 09:23:54.682204: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 09:23:54.689540: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 09:23:54.693383: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 09:23:54.698295: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 09:23:54.699018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631d20ed630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 09:23:54.699044: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 09:23:54.702935: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 09:23:54.703569: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560647bae630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 09:23:54.703603: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 09:23:54.706133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 09:23:54.706538: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5622005e2630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 09:23:54.706562: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 09:23:54.714359: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 09:23:54.715223: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 09:23:54.721775: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 09:23:54.722309: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fae5eae630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 09:23:54.722332: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 09:23:54.723277: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 09:23:54.723656: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8b68ad630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 09:23:54.723680: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 09:23:54.758892: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 09:23:54.766438: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 09:23:54.766984: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d99ea92630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 09:23:54.767005: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 09:23:54.774495: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 09:23:54.782019: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 09:23:54.782567: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f52f49630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 09:23:54.782651: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 09:23:54.788262: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 09:23:54.795575: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 09:23:54.796251: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c5f4b23630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 09:23:54.796280: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.5627 - accuracy: 0.8000Epoch 1/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.7692 - accuracy: 0.4000Epoch 1/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.6876 - accuracy: 0.5000Epoch 1/100\n",
      " 53/720 [=>............................] - ETA: 0s - loss: 0.5581 - accuracy: 0.7849Epoch 1/100\n",
      " 40/720 [>.............................] - ETA: 0s - loss: 0.6306 - accuracy: 0.6800Epoch 1/100\n",
      " 79/720 [==>...........................] - ETA: 0s - loss: 0.6132 - accuracy: 0.7456Epoch 1/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.6364 - accuracy: 0.6000Epoch 1/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4747 - accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.5086 - accuracy: 0.7757\n",
      "629/720 [=========================>....] - ETA: 0s - loss: 0.5098 - accuracy: 0.7814Epoch 2/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.5034 - accuracy: 0.7808\n",
      "670/720 [==========================>...] - ETA: 0s - loss: 0.5056 - accuracy: 0.7894Epoch 2/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.5219 - accuracy: 0.7858\n",
      " 43/720 [>.............................] - ETA: 0s - loss: 0.4694 - accuracy: 0.7814Epoch 2/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.7897\n",
      "709/720 [============================>.] - ETA: 0s - loss: 0.4852 - accuracy: 0.7937Epoch 2/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4849 - accuracy: 0.7935\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7851\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7453\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4317 - accuracy: 0.8126\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4339 - accuracy: 0.8069\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4238 - accuracy: 0.8018\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4290 - accuracy: 0.7971\n",
      "595/720 [=======================>......] - ETA: 0s - loss: 0.4252 - accuracy: 0.8153Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4259 - accuracy: 0.8199\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4151 - accuracy: 0.8251\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4313 - accuracy: 0.8164\n",
      " 71/720 [=>............................] - ETA: 0s - loss: 0.4282 - accuracy: 0.7873Epoch 3/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4252 - accuracy: 0.8146\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4160 - accuracy: 0.8260\n",
      "626/720 [=========================>....] - ETA: 0s - loss: 0.4016 - accuracy: 0.8294Epoch 4/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4068 - accuracy: 0.8110\n",
      "715/720 [============================>.] - ETA: 0s - loss: 0.3998 - accuracy: 0.8320Epoch 4/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3996 - accuracy: 0.8325\n",
      "Epoch 4/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4020 - accuracy: 0.8296\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4169 - accuracy: 0.8200\n",
      "Epoch 4/100\n",
      "674/720 [===========================>..] - ETA: 0s - loss: 0.4071 - accuracy: 0.8283Epoch 4/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4152 - accuracy: 0.8242\n",
      "Epoch 4/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3907 - accuracy: 0.8349\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4062 - accuracy: 0.8289\n",
      "Epoch 4/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.3328 - accuracy: 0.9000Epoch 4/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3736 - accuracy: 0.8487\n",
      "Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3885 - accuracy: 0.8258\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8308\n",
      "Epoch 5/100\n",
      "670/720 [==========================>...] - ETA: 0s - loss: 0.3833 - accuracy: 0.8410Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3807 - accuracy: 0.8417\n",
      "711/720 [============================>.] - ETA: 0s - loss: 0.3722 - accuracy: 0.8463Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3997 - accuracy: 0.8296\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4063 - accuracy: 0.8313\n",
      "Epoch 5/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.1962 - accuracy: 1.0000Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3727 - accuracy: 0.8464\n",
      "Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3936 - accuracy: 0.8307\n",
      " 66/720 [=>............................] - ETA: 1s - loss: 0.3863 - accuracy: 0.8348Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3600 - accuracy: 0.8562\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3760 - accuracy: 0.8379\n",
      "649/720 [==========================>...] - ETA: 0s - loss: 0.3842 - accuracy: 0.8302Epoch 6/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3937 - accuracy: 0.8319\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8522\n",
      "710/720 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8311Epoch 6/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3831 - accuracy: 0.8308\n",
      "700/720 [============================>.] - ETA: 0s - loss: 0.3975 - accuracy: 0.8367Epoch 6/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3794 - accuracy: 0.8382\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3969 - accuracy: 0.8364\n",
      "Epoch 6/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.2234 - accuracy: 1.0000Epoch 6/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3663 - accuracy: 0.8472\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3543 - accuracy: 0.8587\n",
      "611/720 [========================>.....] - ETA: 0s - loss: 0.3637 - accuracy: 0.8480Epoch 7/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8490\n",
      "Epoch 7/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3524 - accuracy: 0.8549\n",
      "120/720 [====>.........................] - ETA: 1s - loss: 0.3668 - accuracy: 0.8500Epoch 7/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3857 - accuracy: 0.8340\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3735 - accuracy: 0.8365\n",
      "Epoch 7/100\n",
      "687/720 [===========================>..] - ETA: 0s - loss: 0.3662 - accuracy: 0.8476Epoch 7/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3654 - accuracy: 0.8487\n",
      "698/720 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8426Epoch 7/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3841 - accuracy: 0.8435\n",
      "Epoch 7/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3584 - accuracy: 0.8511\n",
      "Epoch 7/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8569\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3552 - accuracy: 0.8535\n",
      "462/720 [==================>...........] - ETA: 0s - loss: 0.3530 - accuracy: 0.8530Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3800 - accuracy: 0.8358\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8583\n",
      "538/720 [=====================>........] - ETA: 0s - loss: 0.3563 - accuracy: 0.8513Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3686 - accuracy: 0.8528\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3660 - accuracy: 0.8460\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3573 - accuracy: 0.8529\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3544 - accuracy: 0.8524\n",
      "181/720 [======>.......................] - ETA: 0s - loss: 0.3496 - accuracy: 0.8541Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3502 - accuracy: 0.8547\n",
      "612/720 [========================>.....] - ETA: 0s - loss: 0.3467 - accuracy: 0.8570Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3494 - accuracy: 0.8608\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3752 - accuracy: 0.8353\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3439 - accuracy: 0.8585\n",
      "Epoch 9/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.3593 - accuracy: 0.8000Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3565 - accuracy: 0.8565\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8503\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.8561\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3520 - accuracy: 0.8531\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3471 - accuracy: 0.8579\n",
      "Epoch 10/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8583\n",
      "574/720 [======================>.......] - ETA: 0s - loss: 0.3593 - accuracy: 0.8502Epoch 10/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3481 - accuracy: 0.8599\n",
      "703/720 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.8602Epoch 10/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.8610\n",
      "590/720 [=======================>......] - ETA: 0s - loss: 0.3575 - accuracy: 0.8544Epoch 10/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3712 - accuracy: 0.8389\n",
      "Epoch 10/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3496 - accuracy: 0.8561\n",
      "144/720 [=====>........................] - ETA: 0s - loss: 0.3686 - accuracy: 0.8458Epoch 10/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3572 - accuracy: 0.8544\n",
      "Epoch 10/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8561\n",
      "167/720 [=====>........................] - ETA: 1s - loss: 0.3556 - accuracy: 0.8443Epoch 10/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8579\n",
      "487/720 [===================>..........] - ETA: 0s - loss: 0.3493 - accuracy: 0.8610Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3444 - accuracy: 0.8590\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3471 - accuracy: 0.8596\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3400 - accuracy: 0.8611\n",
      " 38/720 [>.............................] - ETA: 0s - loss: 0.3435 - accuracy: 0.8684Epoch 11/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8371\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3537 - accuracy: 0.8557\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8581\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8562\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.8586\n",
      "511/720 [====================>.........] - ETA: 0s - loss: 0.3707 - accuracy: 0.8337Epoch 12/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8614\n",
      " 34/720 [>.............................] - ETA: 1s - loss: 0.3568 - accuracy: 0.8559Epoch 12/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8599\n",
      "Epoch 12/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3391 - accuracy: 0.8585\n",
      "Epoch 12/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3463 - accuracy: 0.8585\n",
      "682/720 [===========================>..] - ETA: 0s - loss: 0.3661 - accuracy: 0.8378Epoch 12/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8388\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3515 - accuracy: 0.8581\n",
      "182/720 [======>.......................] - ETA: 0s - loss: 0.3286 - accuracy: 0.8692Epoch 12/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.3472 - accuracy: 0.8000Epoch 12/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3466 - accuracy: 0.8571\n",
      "332/720 [============>.................] - ETA: 0s - loss: 0.3362 - accuracy: 0.8672Epoch 12/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3407 - accuracy: 0.8578\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3463 - accuracy: 0.8608\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3399 - accuracy: 0.8601\n",
      "698/720 [============================>.] - ETA: 0s - loss: 0.3358 - accuracy: 0.8629Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3378 - accuracy: 0.8612\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3455 - accuracy: 0.8575\n",
      "206/720 [=======>......................] - ETA: 0s - loss: 0.3156 - accuracy: 0.8660Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3626 - accuracy: 0.8375\n",
      "113/720 [===>..........................] - ETA: 1s - loss: 0.3404 - accuracy: 0.8584Epoch 13/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8585\n",
      "611/720 [========================>.....] - ETA: 0s - loss: 0.3442 - accuracy: 0.8571Epoch 13/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8569\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3392 - accuracy: 0.8565\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3382 - accuracy: 0.8624\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3456 - accuracy: 0.8594\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8610\n",
      "191/720 [======>.......................] - ETA: 0s - loss: 0.3534 - accuracy: 0.8492Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3439 - accuracy: 0.8619\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3599 - accuracy: 0.8394\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3471 - accuracy: 0.8603\n",
      "605/720 [========================>.....] - ETA: 0s - loss: 0.3469 - accuracy: 0.8574Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3443 - accuracy: 0.8581\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3386 - accuracy: 0.8576\n",
      "511/720 [====================>.........] - ETA: 0s - loss: 0.3394 - accuracy: 0.8611Epoch 15/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3455 - accuracy: 0.8612\n",
      "350/720 [=============>................] - ETA: 0s - loss: 0.3463 - accuracy: 0.8571Epoch 15/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3372 - accuracy: 0.8626\n",
      "Epoch 15/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3361 - accuracy: 0.8624\n",
      "Epoch 15/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8571\n",
      "584/720 [=======================>......] - ETA: 0s - loss: 0.3505 - accuracy: 0.8620Epoch 15/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3577 - accuracy: 0.8388\n",
      "170/720 [======>.......................] - ETA: 0s - loss: 0.3296 - accuracy: 0.8571Epoch 15/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8633\n",
      "Epoch 15/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3429 - accuracy: 0.8611\n",
      "337/720 [=============>................] - ETA: 0s - loss: 0.3356 - accuracy: 0.8659Epoch 15/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3370 - accuracy: 0.8604\n",
      "606/720 [========================>.....] - ETA: 0s - loss: 0.3428 - accuracy: 0.8583Epoch 16/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3447 - accuracy: 0.8615\n",
      "Epoch 16/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3366 - accuracy: 0.8626\n",
      "Epoch 16/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8626\n",
      "669/720 [==========================>...] - ETA: 0s - loss: 0.3568 - accuracy: 0.8469Epoch 16/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8604\n",
      "591/720 [=======================>......] - ETA: 0s - loss: 0.3404 - accuracy: 0.8613Epoch 16/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3554 - accuracy: 0.8471\n",
      "612/720 [========================>.....] - ETA: 0s - loss: 0.3406 - accuracy: 0.8598Epoch 16/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8601\n",
      "Epoch 16/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3425 - accuracy: 0.8596\n",
      "170/720 [======>.......................] - ETA: 0s - loss: 0.3336 - accuracy: 0.8694Epoch 16/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3366 - accuracy: 0.8599\n",
      "Epoch 17/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8617\n",
      "478/720 [==================>...........] - ETA: 0s - loss: 0.3558 - accuracy: 0.8479Epoch 17/100\n",
      "565/720 [======================>.......] - ETA: 0s - loss: 0.3396 - accuracy: 0.8591"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[1;32m      4\u001b[0m clf \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mbuild_ann_clf, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_pp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m acc\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# création d'un wrapper pour utiliser le modèle keras dans sklearn\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = KerasClassifier(build_fn=build_ann_clf, batch_size=10, epochs=100)\n",
    "acc = cross_val_score(estimator=clf, X=X_train_pp, y=y_train, cv=10, n_jobs=-1)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8599999964237213, 0.008732134188685693)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.mean(), acc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m parametres \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m25\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m150\u001b[39m],\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     11\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mclf, param_grid\u001b[38;5;241m=\u001b[39mparametres, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m grid\u001b[38;5;241m.\u001b[39mbest_params_, grid\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:223\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid shape for y: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKerasClassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:166\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m fit_args \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(Sequential\u001b[38;5;241m.\u001b[39mfit))\n\u001b[1;32m    164\u001b[0m fit_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 166\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1098\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1093\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1094\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1095\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1096\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[1;32m   1097\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1098\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1100\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 780\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count()\n\u001b[1;32m    783\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:807\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    804\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    805\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    806\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 807\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    810\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    811\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2829\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2828\u001b[0m   graph_function, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filtered_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1843\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filtered_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs, cancellation_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1828\u001b[0m   \u001b[38;5;124;03m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[1;32m   1829\u001b[0m \n\u001b[1;32m   1830\u001b[0m \u001b[38;5;124;03m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;124;03m    `args` and `kwargs`.\u001b[39;00m\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1843\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseResourceVariable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1923\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1918\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1919\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1922\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1925\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m     args,\n\u001b[1;32m   1927\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1928\u001b[0m     executing_eagerly)\n\u001b[1;32m   1929\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:545\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    544\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    554\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    558\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# affinage des hyperparamètres par validation croisée : GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = KerasClassifier(build_fn=build_ann_clf)\n",
    "\n",
    "parametres = {\n",
    "    'batch_size' : [5, 10, 25],\n",
    "    'epochs': [100, 150],\n",
    "    'optimizer' : ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf, param_grid=parametres, scoring='accuracy', cv=8)\n",
    "grid = grid.fit(X_train_pp, y_train, verbose=0)\n",
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde et chargement des réseaux\n",
    "\n",
    "Regarder les méthodes `save` et `load_model` de la librairie `keras.models` pour la sauvegarde et le chargement des modèle. Quel format de fichier utiliser ?\n",
    "\n",
    "Si vous souhaitez ne sauvegarder que l'architecture du modèle (sans les poids ni la configuration d'entraînement), vous pouvez utiliser `to_json`.\n",
    "\n",
    "Enfin, pour ne sauvegarder que les poids, vous avez la méthode `save_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.save()\n",
    "\n",
    "Cette fonction sauvegarde : \n",
    "- l'architecture du modèle : permet de le recréer si besoin\n",
    "- les poids du modèle\n",
    "- les paramètres d'apprentissage (loss, optimizer, metrics de l'étape `compile`)\n",
    "- l'état de l'optimisation ce qui permet de reprendre l'apprentissage où on l'avait laissé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save('models/mlp_bank.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.load_model()\n",
    "charge un modèle enregistrés et l'ensemble des infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('models/mlp_bank.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.40640736,  0.2504217 ,  1.0757139 ,  0.75616646,  1.1995943 ,\n",
       "         0.80780786, -0.11462856, -0.3914252 ], dtype=float32),\n",
       " array([-0.40640736,  0.2504217 ,  1.0757139 ,  0.75616646,  1.1995943 ,\n",
       "         0.80780786, -0.11462856, -0.3914252 ], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()[1], mlp.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7faf0c75eb20>,\n",
       " <function tensorflow.python.keras.losses.binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer, new_model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18816015],\n",
       "       [0.06006962],\n",
       "       [0.0058144 ],\n",
       "       ...,\n",
       "       [0.02872148],\n",
       "       [0.9914901 ],\n",
       "       [0.03783619]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(X_test_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 0s 597us/step - loss: 0.3414 - accuracy: 0.8545\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 612us/step - loss: 0.3387 - accuracy: 0.8555\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 530us/step - loss: 0.3387 - accuracy: 0.8550\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 585us/step - loss: 0.3367 - accuracy: 0.8605\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 567us/step - loss: 0.3363 - accuracy: 0.8575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fae9f3a9310>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(X_test_pp, y_test, batch_size=20, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.to_json()\n",
    "\n",
    "Si on a juste besoin de sauvegarder **la structure d'un réseau, sans ses paramètres d'apprentissage ni ses poids**, on peut utiliser les 2 fonctions suivantes (pour sauvegarder et charger)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 11], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 11], \"dtype\": \"float32\", \"units\": 8, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 6, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sauvegarde en json\n",
    "json = mlp.to_json()\n",
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# reconstruire un modèle depuis une sauvegarde json\n",
    "from keras.models import model_from_json\n",
    "new_model2 = model_from_json(json)\n",
    "new_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.2851035 , -0.47825703,  0.26700902, -0.09673935,  0.3867796 ,\n",
       "          0.2644499 , -0.31293163,  0.39127475],\n",
       "        [ 0.19264537,  0.22873503,  0.342259  ,  0.5180369 ,  0.18809956,\n",
       "          0.40081382,  0.5525113 ,  0.0584442 ],\n",
       "        [ 0.25613844, -0.3675022 ,  0.5002273 , -0.0732854 ,  0.25263083,\n",
       "         -0.36980718, -0.5465233 ,  0.08018857],\n",
       "        [-0.4395377 , -0.5209357 , -0.4718772 ,  0.22666454, -0.35063618,\n",
       "          0.19318998, -0.188882  , -0.21800086],\n",
       "        [-0.3761191 ,  0.36368138, -0.17171249, -0.47624534,  0.05104798,\n",
       "          0.03966105, -0.47040206,  0.03478914],\n",
       "        [ 0.46323568,  0.4932924 ,  0.00163776, -0.07278833,  0.22610664,\n",
       "          0.02552593,  0.29678547, -0.32815465],\n",
       "        [-0.00625551, -0.33984882,  0.08233625,  0.07234365,  0.05499756,\n",
       "         -0.36217773,  0.517443  , -0.3457936 ],\n",
       "        [-0.42046544, -0.2563634 , -0.23070267, -0.33277187,  0.09513402,\n",
       "         -0.19241545, -0.2730787 , -0.23855108],\n",
       "        [-0.45270216, -0.46899688,  0.411956  ,  0.11913419,  0.40291035,\n",
       "         -0.00326872, -0.19056544, -0.35965568],\n",
       "        [ 0.13736492, -0.24546215, -0.34612602, -0.20443341,  0.02311134,\n",
       "         -0.5578876 ,  0.2968282 , -0.14867604],\n",
       "        [-0.3243069 , -0.09410906, -0.15149859, -0.36609608, -0.27983946,\n",
       "          0.52518004, -0.46847478,  0.39730746]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.06009203, -0.48808527,  0.24206412,  0.26392633, -0.3445286 ,\n",
       "          0.20405298],\n",
       "        [-0.6407426 , -0.414652  ,  0.17231297, -0.225898  ,  0.30259037,\n",
       "         -0.21934256],\n",
       "        [ 0.5805769 ,  0.3660059 , -0.35488087, -0.31783426,  0.0424214 ,\n",
       "          0.20140237],\n",
       "        [ 0.23429734, -0.54381514, -0.4936232 , -0.12706387,  0.38032508,\n",
       "         -0.07906955],\n",
       "        [-0.31078312,  0.64905584, -0.43868792, -0.20356974, -0.25210097,\n",
       "         -0.08128119],\n",
       "        [-0.43596697, -0.24732253, -0.60510117,  0.11889142,  0.01989102,\n",
       "          0.59096134],\n",
       "        [ 0.21918416, -0.42160743,  0.12580973,  0.4520471 ,  0.3066134 ,\n",
       "         -0.21848068],\n",
       "        [-0.27945676, -0.37524357, -0.5916262 , -0.17812577,  0.592224  ,\n",
       "          0.07584894]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.18713939],\n",
       "        [-0.39037132],\n",
       "        [-0.12871784],\n",
       "        [ 0.00771701],\n",
       "        [-0.0117467 ],\n",
       "        [ 0.14741087]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(new_model2.optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.save_weights()\n",
    "\n",
    "Si jamais, on veut uniquement les poids d'un modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save_weights('models/mes_poids.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model3 = Sequential([\n",
    "    Dense(units=8, activation='relu', input_dim=11),\n",
    "    Dense(units=6, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "new_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-7.17370629e-01,  5.07246017e-01, -1.17547013e-01,\n",
       "         -5.76582789e-01,  2.72090524e-01,  8.54372382e-02,\n",
       "          5.11946082e-01,  7.85673037e-02],\n",
       "        [-4.05586660e-01,  5.56773320e-02, -2.26069480e-01,\n",
       "          5.48489213e-01, -1.66155174e-01, -3.34440405e-03,\n",
       "          4.98131305e-01, -2.88371116e-01],\n",
       "        [ 5.00869870e-01, -1.61655108e-03, -2.80214339e-01,\n",
       "          3.38897496e-01,  1.90462455e-01,  3.07290345e-01,\n",
       "         -1.20579086e-01,  5.49690351e-02],\n",
       "        [-6.69761956e-01,  1.84862018e-02, -1.79556474e-01,\n",
       "          8.84288996e-02, -7.96168693e-04,  4.62862216e-02,\n",
       "         -3.31855834e-01, -9.21989530e-02],\n",
       "        [-3.33012104e-01,  1.24566339e-01,  8.83827568e-04,\n",
       "         -1.38776675e-02, -2.96704262e-01, -5.40259123e-01,\n",
       "          1.09486556e+00,  1.14615083e+00],\n",
       "        [-4.67029184e-01,  3.70786004e-02, -7.59298131e-02,\n",
       "          1.16880007e-01,  8.35068300e-02, -1.80306762e-01,\n",
       "          1.50968000e-01, -5.23742847e-02],\n",
       "        [-3.39907497e-01, -4.70766187e-01, -2.31884062e-01,\n",
       "         -6.75925851e-01, -4.69468348e-02, -1.09980300e-01,\n",
       "         -6.37794256e-01,  8.55493918e-02],\n",
       "        [-2.99477398e-01, -1.50364769e+00, -3.65304261e-01,\n",
       "         -2.65665054e-01, -5.52230299e-01, -6.38082385e-01,\n",
       "          4.90548790e-01, -9.04193163e-01],\n",
       "        [-1.88633770e-01,  5.52422106e-02, -1.70366406e-01,\n",
       "          6.97211130e-03,  1.07166953e-01, -1.08499594e-01,\n",
       "          3.42704058e-01, -1.16468035e-01],\n",
       "        [ 6.78151026e-02, -2.86878437e-01, -2.68530011e-01,\n",
       "          8.07469934e-02,  3.78781781e-02,  3.67390305e-01,\n",
       "          2.36989334e-01,  8.18767786e-01],\n",
       "        [ 3.57470065e-01, -2.36342996e-02,  1.09217584e-01,\n",
       "         -2.10966855e-01, -2.05967389e-02,  3.23655337e-01,\n",
       "          6.31883740e-02,  1.59356773e-01]], dtype=float32),\n",
       " array([-0.40640736,  0.2504217 ,  1.0757139 ,  0.75616646,  1.1995943 ,\n",
       "         0.80780786, -0.11462856, -0.3914252 ], dtype=float32),\n",
       " array([[-1.4659486 ,  0.12368938,  0.24946356,  0.59056294, -0.53213876,\n",
       "         -0.43785313],\n",
       "        [ 0.29600817,  1.2997007 , -0.41298255, -0.05513765, -0.8257946 ,\n",
       "         -0.68926656],\n",
       "        [ 0.19863425,  0.44369504,  0.7979764 , -0.39800277, -0.6884757 ,\n",
       "          0.6402695 ],\n",
       "        [ 0.52723056,  0.0494524 ,  0.40323135, -0.87268895,  0.10105137,\n",
       "          0.77839214],\n",
       "        [-1.006006  , -0.2426775 ,  1.2690806 , -1.1940271 ,  0.0098621 ,\n",
       "          0.13683267],\n",
       "        [ 0.07996578,  0.4578341 ,  0.47519255, -0.7438689 ,  0.7968578 ,\n",
       "          0.27474445],\n",
       "        [ 0.04942411,  0.00447975, -0.6884146 ,  0.7522496 ,  1.1727343 ,\n",
       "         -0.09742638],\n",
       "        [-1.0394837 ,  0.30659893, -1.106717  , -0.49326232,  1.1171398 ,\n",
       "          0.0624347 ]], dtype=float32),\n",
       " array([ 0.30670604,  0.31412676,  0.58128124,  1.0136641 , -0.28967333,\n",
       "         0.15085848], dtype=float32),\n",
       " array([[ 1.237488  ],\n",
       "        [ 0.8509293 ],\n",
       "        [-0.92308795],\n",
       "        [ 1.867747  ],\n",
       "        [-0.8448795 ],\n",
       "        [-0.7524186 ]], dtype=float32),\n",
       " array([0.2680773], dtype=float32)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# poids initialisés par défaut\n",
    "new_model3.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-7.17370629e-01,  5.07246017e-01, -1.17547013e-01,\n",
       "         -5.76582789e-01,  2.72090524e-01,  8.54372382e-02,\n",
       "          5.11946082e-01,  7.85673037e-02],\n",
       "        [-4.05586660e-01,  5.56773320e-02, -2.26069480e-01,\n",
       "          5.48489213e-01, -1.66155174e-01, -3.34440405e-03,\n",
       "          4.98131305e-01, -2.88371116e-01],\n",
       "        [ 5.00869870e-01, -1.61655108e-03, -2.80214339e-01,\n",
       "          3.38897496e-01,  1.90462455e-01,  3.07290345e-01,\n",
       "         -1.20579086e-01,  5.49690351e-02],\n",
       "        [-6.69761956e-01,  1.84862018e-02, -1.79556474e-01,\n",
       "          8.84288996e-02, -7.96168693e-04,  4.62862216e-02,\n",
       "         -3.31855834e-01, -9.21989530e-02],\n",
       "        [-3.33012104e-01,  1.24566339e-01,  8.83827568e-04,\n",
       "         -1.38776675e-02, -2.96704262e-01, -5.40259123e-01,\n",
       "          1.09486556e+00,  1.14615083e+00],\n",
       "        [-4.67029184e-01,  3.70786004e-02, -7.59298131e-02,\n",
       "          1.16880007e-01,  8.35068300e-02, -1.80306762e-01,\n",
       "          1.50968000e-01, -5.23742847e-02],\n",
       "        [-3.39907497e-01, -4.70766187e-01, -2.31884062e-01,\n",
       "         -6.75925851e-01, -4.69468348e-02, -1.09980300e-01,\n",
       "         -6.37794256e-01,  8.55493918e-02],\n",
       "        [-2.99477398e-01, -1.50364769e+00, -3.65304261e-01,\n",
       "         -2.65665054e-01, -5.52230299e-01, -6.38082385e-01,\n",
       "          4.90548790e-01, -9.04193163e-01],\n",
       "        [-1.88633770e-01,  5.52422106e-02, -1.70366406e-01,\n",
       "          6.97211130e-03,  1.07166953e-01, -1.08499594e-01,\n",
       "          3.42704058e-01, -1.16468035e-01],\n",
       "        [ 6.78151026e-02, -2.86878437e-01, -2.68530011e-01,\n",
       "          8.07469934e-02,  3.78781781e-02,  3.67390305e-01,\n",
       "          2.36989334e-01,  8.18767786e-01],\n",
       "        [ 3.57470065e-01, -2.36342996e-02,  1.09217584e-01,\n",
       "         -2.10966855e-01, -2.05967389e-02,  3.23655337e-01,\n",
       "          6.31883740e-02,  1.59356773e-01]], dtype=float32),\n",
       " array([-0.40640736,  0.2504217 ,  1.0757139 ,  0.75616646,  1.1995943 ,\n",
       "         0.80780786, -0.11462856, -0.3914252 ], dtype=float32),\n",
       " array([[-1.4659486 ,  0.12368938,  0.24946356,  0.59056294, -0.53213876,\n",
       "         -0.43785313],\n",
       "        [ 0.29600817,  1.2997007 , -0.41298255, -0.05513765, -0.8257946 ,\n",
       "         -0.68926656],\n",
       "        [ 0.19863425,  0.44369504,  0.7979764 , -0.39800277, -0.6884757 ,\n",
       "          0.6402695 ],\n",
       "        [ 0.52723056,  0.0494524 ,  0.40323135, -0.87268895,  0.10105137,\n",
       "          0.77839214],\n",
       "        [-1.006006  , -0.2426775 ,  1.2690806 , -1.1940271 ,  0.0098621 ,\n",
       "          0.13683267],\n",
       "        [ 0.07996578,  0.4578341 ,  0.47519255, -0.7438689 ,  0.7968578 ,\n",
       "          0.27474445],\n",
       "        [ 0.04942411,  0.00447975, -0.6884146 ,  0.7522496 ,  1.1727343 ,\n",
       "         -0.09742638],\n",
       "        [-1.0394837 ,  0.30659893, -1.106717  , -0.49326232,  1.1171398 ,\n",
       "          0.0624347 ]], dtype=float32),\n",
       " array([ 0.30670604,  0.31412676,  0.58128124,  1.0136641 , -0.28967333,\n",
       "         0.15085848], dtype=float32),\n",
       " array([[ 1.237488  ],\n",
       "        [ 0.8509293 ],\n",
       "        [-0.92308795],\n",
       "        [ 1.867747  ],\n",
       "        [-0.8448795 ],\n",
       "        [-0.7524186 ]], dtype=float32),\n",
       " array([0.2680773], dtype=float32)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chargement des poids sauvegardés\n",
    "new_model3.load_weights('models/mes_poids.h5')\n",
    "new_model3.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complément sur l'overfitting\n",
    "\n",
    "Toujours sur les données de la banque, entrainer un réseau ayant une structure complexe avec beaucoup de neurones et de couches afin de générer une situation d'overfitting.  \n",
    "Comparer l'accuracy sur les échantillons train et test pour confirmer le cas de sur-apprentissage.\n",
    "\n",
    "Reprendre le même réseau en utilisant des layers `Dropout` pour réduire ce problème.  \n",
    "Comparer à nouveau l'accuracy pour voir l'effet des `Dropout` sur l'overfitting.\n",
    "\n",
    "Une autre méthode pour limiter le sur-apprentissage est la régularisation. Est-il possible d'en faire avec un réseau de neurones ? Si oui, allez-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
