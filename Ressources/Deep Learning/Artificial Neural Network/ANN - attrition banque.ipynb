{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de neurones et attrition des clients bancaires\n",
    "\n",
    "Réseau de neurones avec Python (Keras)\n",
    "\n",
    "## La problématique\n",
    "\n",
    "On s'intéresse ici à une problème classique du domaine bancaire (mais pas que !) qui est l'attrition ou *churn* en anglais et correspond à la perte de client. \n",
    "Récemment de nombreux clients ont quitté la banque Crédit Friqué. La question est de comprendre pourquoi ces départs ? Ou plutôt de prédire s'ils vont partir...\n",
    "\n",
    "## Les données\n",
    "\n",
    "Pour répondre à cette question, la banque a sélectionné 6 mois plus tôt un sous ensemble de ses clients pour lesquels elle a stocké un certain nombre d’information puis, dans les 6 mois qui ont suivis, elle a observé si les clients avaient quitté ou non la banque. Vous voilà donc, 6 mois plus tard, contacté par la banque qui vous propose un beau dataset (pour une fois!) et vous demande de déterminer les profils des clients les plus à même de partir.\n",
    "Vous disposez du fichier banque_abandon.csv qui est la base de données de la banque virtuelle Crédit Friqué.\n",
    "\n",
    "## Quelques questions préliminaires\n",
    "\n",
    "C'est juste pour vous échauffer donc ça doit être fait en moins d'une heure ça !\n",
    "1. À quoi correspondent les différentes variables du datasets ?\n",
    "2. Pour pas perdre les bonnes habitudes, faites quelques visualisations pour voir ce qu'il y a dans vos données.\n",
    "3. À quelle type de problème avez-vous à faire ici : classification ou régression ?\n",
    ">- Lister un certain nombre de modèles vous permettant de le résoudre\n",
    ">- Lister les métriques associées à ce type de problème\n",
    ">- Choisir un modèle, l'entraîner et l'évaluer avec la métrique de votre choix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flemme de tout refaire et vous commencez à être au point là dessus normalement\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "df = pd.read_csv('data/banque_abandon.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.000500e+03</td>\n",
       "      <td>2886.895680</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2500.75</td>\n",
       "      <td>5.000500e+03</td>\n",
       "      <td>7.500250e+03</td>\n",
       "      <td>10000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>71936.186123</td>\n",
       "      <td>15565701.00</td>\n",
       "      <td>15628528.25</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>15815690.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>6.505288e+02</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>350.00</td>\n",
       "      <td>584.00</td>\n",
       "      <td>6.520000e+02</td>\n",
       "      <td>7.180000e+02</td>\n",
       "      <td>850.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.892180e+01</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>18.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.012800e+00</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.648589e+04</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.719854e+04</td>\n",
       "      <td>1.276442e+05</td>\n",
       "      <td>250898.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.530200e+00</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.055000e-01</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.151000e-01</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.000902e+05</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>11.58</td>\n",
       "      <td>51002.11</td>\n",
       "      <td>1.001939e+05</td>\n",
       "      <td>1.493882e+05</td>\n",
       "      <td>199992.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.037000e-01</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count          mean           std          min  \\\n",
       "RowNumber        10000.0  5.000500e+03   2886.895680         1.00   \n",
       "CustomerId       10000.0  1.569094e+07  71936.186123  15565701.00   \n",
       "CreditScore      10000.0  6.505288e+02     96.653299       350.00   \n",
       "Age              10000.0  3.892180e+01     10.487806        18.00   \n",
       "Tenure           10000.0  5.012800e+00      2.892174         0.00   \n",
       "Balance          10000.0  7.648589e+04  62397.405202         0.00   \n",
       "NumOfProducts    10000.0  1.530200e+00      0.581654         1.00   \n",
       "HasCrCard        10000.0  7.055000e-01      0.455840         0.00   \n",
       "IsActiveMember   10000.0  5.151000e-01      0.499797         0.00   \n",
       "EstimatedSalary  10000.0  1.000902e+05  57510.492818        11.58   \n",
       "Exited           10000.0  2.037000e-01      0.402769         0.00   \n",
       "\n",
       "                         25%           50%           75%          max  \n",
       "RowNumber            2500.75  5.000500e+03  7.500250e+03     10000.00  \n",
       "CustomerId       15628528.25  1.569074e+07  1.575323e+07  15815690.00  \n",
       "CreditScore           584.00  6.520000e+02  7.180000e+02       850.00  \n",
       "Age                    32.00  3.700000e+01  4.400000e+01        92.00  \n",
       "Tenure                  3.00  5.000000e+00  7.000000e+00        10.00  \n",
       "Balance                 0.00  9.719854e+04  1.276442e+05    250898.09  \n",
       "NumOfProducts           1.00  1.000000e+00  2.000000e+00         4.00  \n",
       "HasCrCard               0.00  1.000000e+00  1.000000e+00         1.00  \n",
       "IsActiveMember          0.00  1.000000e+00  1.000000e+00         1.00  \n",
       "EstimatedSalary     51002.11  1.001939e+05  1.493882e+05    199992.48  \n",
       "Exited                  0.00  0.000000e+00  0.000000e+00         1.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df==0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dans le vif du sujet\n",
    "\n",
    "Vous l'aurez compris, il s'agit ici de résoudre le problème à l'aide d'un réseau de neurones.   \n",
    "Vous aurez bien sûr besoin du package `keras` et il vous faudra aussi certainement installer `tensorflow`(et peut-être `theano` si besoin).  \n",
    "À vous de jouer !\n",
    "N'oubliez pas le preprocessing !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# création des tables X et y\n",
    "X = df.iloc[:, 3:13] # pour virer row, id et nom\n",
    "y = df.iloc[:, 13]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography\n",
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.value_counts('Geography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (2000, 10), (8000,), (2000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# échantillons train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 11), (2000, 11))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot-encoding sur les variables catégoriques\n",
    "# feature scaling sur les numériques\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "\n",
    "preprocessing = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), ['Geography', 'Gender']),\n",
    "    (StandardScaler(), make_column_selector(dtype_exclude='object')))\n",
    "\n",
    "X_train_pp =  preprocessing.fit_transform(X_train)\n",
    "X_test_pp =  preprocessing.transform(X_test)\n",
    "X_train_pp.shape, X_test_pp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 09:59:40.810516: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 09:59:40.830681: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 09:59:40.831180: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562050aecbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 09:59:40.831218: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "400/400 [==============================] - 0s 789us/step - loss: 0.4937 - accuracy: 0.7941 - val_loss: 0.4587 - val_accuracy: 0.7965\n",
      "Epoch 2/100\n",
      "400/400 [==============================] - 0s 673us/step - loss: 0.4398 - accuracy: 0.8086 - val_loss: 0.4388 - val_accuracy: 0.8115\n",
      "Epoch 3/100\n",
      "400/400 [==============================] - 0s 632us/step - loss: 0.4245 - accuracy: 0.8223 - val_loss: 0.4289 - val_accuracy: 0.8155\n",
      "Epoch 4/100\n",
      "400/400 [==============================] - 0s 627us/step - loss: 0.4168 - accuracy: 0.8261 - val_loss: 0.4217 - val_accuracy: 0.8215\n",
      "Epoch 5/100\n",
      "400/400 [==============================] - 0s 616us/step - loss: 0.4120 - accuracy: 0.8276 - val_loss: 0.4175 - val_accuracy: 0.8220\n",
      "Epoch 6/100\n",
      "400/400 [==============================] - 0s 623us/step - loss: 0.4082 - accuracy: 0.8309 - val_loss: 0.4149 - val_accuracy: 0.8240\n",
      "Epoch 7/100\n",
      "400/400 [==============================] - 0s 609us/step - loss: 0.4053 - accuracy: 0.8322 - val_loss: 0.4124 - val_accuracy: 0.8265\n",
      "Epoch 8/100\n",
      "400/400 [==============================] - 0s 594us/step - loss: 0.4022 - accuracy: 0.8321 - val_loss: 0.4086 - val_accuracy: 0.8295\n",
      "Epoch 9/100\n",
      "400/400 [==============================] - 0s 605us/step - loss: 0.3985 - accuracy: 0.8346 - val_loss: 0.4044 - val_accuracy: 0.8305\n",
      "Epoch 10/100\n",
      "400/400 [==============================] - 0s 688us/step - loss: 0.3947 - accuracy: 0.8341 - val_loss: 0.3999 - val_accuracy: 0.8290\n",
      "Epoch 11/100\n",
      "400/400 [==============================] - 0s 697us/step - loss: 0.3896 - accuracy: 0.8349 - val_loss: 0.3952 - val_accuracy: 0.8300\n",
      "Epoch 12/100\n",
      "400/400 [==============================] - 0s 696us/step - loss: 0.3826 - accuracy: 0.8355 - val_loss: 0.3870 - val_accuracy: 0.8300\n",
      "Epoch 13/100\n",
      "400/400 [==============================] - 0s 688us/step - loss: 0.3774 - accuracy: 0.8367 - val_loss: 0.3828 - val_accuracy: 0.8300\n",
      "Epoch 14/100\n",
      "400/400 [==============================] - 0s 633us/step - loss: 0.3722 - accuracy: 0.8353 - val_loss: 0.3811 - val_accuracy: 0.8325\n",
      "Epoch 15/100\n",
      "400/400 [==============================] - 0s 664us/step - loss: 0.3680 - accuracy: 0.8350 - val_loss: 0.3762 - val_accuracy: 0.8340\n",
      "Epoch 16/100\n",
      "400/400 [==============================] - 0s 614us/step - loss: 0.3649 - accuracy: 0.8395 - val_loss: 0.3707 - val_accuracy: 0.8425\n",
      "Epoch 17/100\n",
      "400/400 [==============================] - 0s 696us/step - loss: 0.3621 - accuracy: 0.8479 - val_loss: 0.3685 - val_accuracy: 0.8470\n",
      "Epoch 18/100\n",
      "400/400 [==============================] - 0s 613us/step - loss: 0.3583 - accuracy: 0.8520 - val_loss: 0.3648 - val_accuracy: 0.8485\n",
      "Epoch 19/100\n",
      "400/400 [==============================] - 0s 669us/step - loss: 0.3544 - accuracy: 0.8574 - val_loss: 0.3629 - val_accuracy: 0.8505\n",
      "Epoch 20/100\n",
      "400/400 [==============================] - 0s 624us/step - loss: 0.3496 - accuracy: 0.8597 - val_loss: 0.3557 - val_accuracy: 0.8530\n",
      "Epoch 21/100\n",
      "400/400 [==============================] - 0s 632us/step - loss: 0.3454 - accuracy: 0.8581 - val_loss: 0.3534 - val_accuracy: 0.8500\n",
      "Epoch 22/100\n",
      "400/400 [==============================] - 0s 625us/step - loss: 0.3419 - accuracy: 0.8608 - val_loss: 0.3580 - val_accuracy: 0.8570\n",
      "Epoch 23/100\n",
      "400/400 [==============================] - 0s 618us/step - loss: 0.3413 - accuracy: 0.8597 - val_loss: 0.3498 - val_accuracy: 0.8530\n",
      "Epoch 24/100\n",
      "400/400 [==============================] - 0s 612us/step - loss: 0.3401 - accuracy: 0.8594 - val_loss: 0.3488 - val_accuracy: 0.8560\n",
      "Epoch 25/100\n",
      "400/400 [==============================] - 0s 592us/step - loss: 0.3393 - accuracy: 0.8595 - val_loss: 0.3502 - val_accuracy: 0.8550\n",
      "Epoch 26/100\n",
      "400/400 [==============================] - 0s 599us/step - loss: 0.3388 - accuracy: 0.8609 - val_loss: 0.3505 - val_accuracy: 0.8560\n",
      "Epoch 27/100\n",
      "400/400 [==============================] - 0s 599us/step - loss: 0.3382 - accuracy: 0.8619 - val_loss: 0.3493 - val_accuracy: 0.8570\n",
      "Epoch 28/100\n",
      "400/400 [==============================] - 0s 607us/step - loss: 0.3373 - accuracy: 0.8600 - val_loss: 0.3484 - val_accuracy: 0.8575\n",
      "Epoch 29/100\n",
      "400/400 [==============================] - 0s 598us/step - loss: 0.3375 - accuracy: 0.8621 - val_loss: 0.3492 - val_accuracy: 0.8585\n",
      "Epoch 30/100\n",
      "400/400 [==============================] - 0s 610us/step - loss: 0.3364 - accuracy: 0.8609 - val_loss: 0.3486 - val_accuracy: 0.8565\n",
      "Epoch 31/100\n",
      "400/400 [==============================] - 0s 611us/step - loss: 0.3356 - accuracy: 0.8621 - val_loss: 0.3540 - val_accuracy: 0.8580\n",
      "Epoch 32/100\n",
      "400/400 [==============================] - 0s 605us/step - loss: 0.3363 - accuracy: 0.8599 - val_loss: 0.3498 - val_accuracy: 0.8555\n",
      "Epoch 33/100\n",
      "400/400 [==============================] - 0s 657us/step - loss: 0.3355 - accuracy: 0.8622 - val_loss: 0.3484 - val_accuracy: 0.8570\n",
      "Epoch 34/100\n",
      "400/400 [==============================] - 0s 610us/step - loss: 0.3346 - accuracy: 0.8616 - val_loss: 0.3501 - val_accuracy: 0.8590\n",
      "Epoch 35/100\n",
      "400/400 [==============================] - 0s 654us/step - loss: 0.3349 - accuracy: 0.8614 - val_loss: 0.3490 - val_accuracy: 0.8560\n",
      "Epoch 36/100\n",
      "400/400 [==============================] - 0s 668us/step - loss: 0.3345 - accuracy: 0.8621 - val_loss: 0.3492 - val_accuracy: 0.8570\n",
      "Epoch 37/100\n",
      "400/400 [==============================] - 0s 662us/step - loss: 0.3336 - accuracy: 0.8621 - val_loss: 0.3505 - val_accuracy: 0.8575\n",
      "Epoch 38/100\n",
      "400/400 [==============================] - 0s 683us/step - loss: 0.3340 - accuracy: 0.8604 - val_loss: 0.3499 - val_accuracy: 0.8575\n",
      "Epoch 39/100\n",
      "400/400 [==============================] - 0s 655us/step - loss: 0.3336 - accuracy: 0.8614 - val_loss: 0.3512 - val_accuracy: 0.8505\n",
      "Epoch 40/100\n",
      "400/400 [==============================] - 0s 667us/step - loss: 0.3336 - accuracy: 0.8604 - val_loss: 0.3511 - val_accuracy: 0.8575\n",
      "Epoch 41/100\n",
      "400/400 [==============================] - 0s 605us/step - loss: 0.3326 - accuracy: 0.8635 - val_loss: 0.3497 - val_accuracy: 0.8565\n",
      "Epoch 42/100\n",
      "400/400 [==============================] - 0s 595us/step - loss: 0.3331 - accuracy: 0.8605 - val_loss: 0.3503 - val_accuracy: 0.8535\n",
      "Epoch 43/100\n",
      "400/400 [==============================] - 0s 664us/step - loss: 0.3328 - accuracy: 0.8616 - val_loss: 0.3517 - val_accuracy: 0.8590\n",
      "Epoch 44/100\n",
      "400/400 [==============================] - 0s 663us/step - loss: 0.3324 - accuracy: 0.8629 - val_loss: 0.3510 - val_accuracy: 0.8535\n",
      "Epoch 45/100\n",
      "400/400 [==============================] - 0s 665us/step - loss: 0.3327 - accuracy: 0.8620 - val_loss: 0.3514 - val_accuracy: 0.8615\n",
      "Epoch 46/100\n",
      "400/400 [==============================] - 0s 614us/step - loss: 0.3326 - accuracy: 0.8619 - val_loss: 0.3519 - val_accuracy: 0.8565\n",
      "Epoch 47/100\n",
      "400/400 [==============================] - 0s 638us/step - loss: 0.3320 - accuracy: 0.8625 - val_loss: 0.3505 - val_accuracy: 0.8545\n",
      "Epoch 48/100\n",
      "400/400 [==============================] - 0s 648us/step - loss: 0.3321 - accuracy: 0.8634 - val_loss: 0.3503 - val_accuracy: 0.8580\n",
      "Epoch 49/100\n",
      "400/400 [==============================] - 0s 650us/step - loss: 0.3316 - accuracy: 0.8612 - val_loss: 0.3514 - val_accuracy: 0.8540\n",
      "Epoch 50/100\n",
      "400/400 [==============================] - 0s 650us/step - loss: 0.3314 - accuracy: 0.8627 - val_loss: 0.3515 - val_accuracy: 0.8600\n",
      "Epoch 51/100\n",
      "400/400 [==============================] - 0s 638us/step - loss: 0.3313 - accuracy: 0.8620 - val_loss: 0.3532 - val_accuracy: 0.8595\n",
      "Epoch 52/100\n",
      "400/400 [==============================] - 0s 649us/step - loss: 0.3318 - accuracy: 0.8624 - val_loss: 0.3496 - val_accuracy: 0.8565\n",
      "Epoch 53/100\n",
      "400/400 [==============================] - 0s 643us/step - loss: 0.3310 - accuracy: 0.8610 - val_loss: 0.3508 - val_accuracy: 0.8595\n",
      "Epoch 54/100\n",
      "400/400 [==============================] - 0s 630us/step - loss: 0.3314 - accuracy: 0.8633 - val_loss: 0.3489 - val_accuracy: 0.8580\n",
      "Epoch 55/100\n",
      "400/400 [==============================] - 0s 602us/step - loss: 0.3311 - accuracy: 0.8615 - val_loss: 0.3486 - val_accuracy: 0.8560\n",
      "Epoch 56/100\n",
      "400/400 [==============================] - 0s 601us/step - loss: 0.3309 - accuracy: 0.8622 - val_loss: 0.3497 - val_accuracy: 0.8580\n",
      "Epoch 57/100\n",
      "400/400 [==============================] - 0s 602us/step - loss: 0.3309 - accuracy: 0.8639 - val_loss: 0.3488 - val_accuracy: 0.8575\n",
      "Epoch 58/100\n",
      "400/400 [==============================] - 0s 594us/step - loss: 0.3305 - accuracy: 0.8626 - val_loss: 0.3484 - val_accuracy: 0.8590\n",
      "Epoch 59/100\n",
      "400/400 [==============================] - 0s 603us/step - loss: 0.3305 - accuracy: 0.8636 - val_loss: 0.3487 - val_accuracy: 0.8585\n",
      "Epoch 60/100\n",
      "400/400 [==============================] - 0s 602us/step - loss: 0.3307 - accuracy: 0.8629 - val_loss: 0.3483 - val_accuracy: 0.8590\n",
      "Epoch 61/100\n",
      "400/400 [==============================] - 0s 653us/step - loss: 0.3300 - accuracy: 0.8630 - val_loss: 0.3488 - val_accuracy: 0.8580\n",
      "Epoch 62/100\n",
      "400/400 [==============================] - 0s 635us/step - loss: 0.3299 - accuracy: 0.8635 - val_loss: 0.3481 - val_accuracy: 0.8550\n",
      "Epoch 63/100\n",
      "400/400 [==============================] - 0s 638us/step - loss: 0.3296 - accuracy: 0.8630 - val_loss: 0.3482 - val_accuracy: 0.8595\n",
      "Epoch 64/100\n",
      "400/400 [==============================] - 0s 643us/step - loss: 0.3300 - accuracy: 0.8631 - val_loss: 0.3483 - val_accuracy: 0.8585\n",
      "Epoch 65/100\n",
      "400/400 [==============================] - 0s 662us/step - loss: 0.3295 - accuracy: 0.8627 - val_loss: 0.3518 - val_accuracy: 0.8590\n",
      "Epoch 66/100\n",
      "400/400 [==============================] - 0s 638us/step - loss: 0.3295 - accuracy: 0.8610 - val_loss: 0.3472 - val_accuracy: 0.8545\n",
      "Epoch 67/100\n",
      "400/400 [==============================] - 0s 618us/step - loss: 0.3294 - accuracy: 0.8633 - val_loss: 0.3471 - val_accuracy: 0.8580\n",
      "Epoch 68/100\n",
      "400/400 [==============================] - 0s 665us/step - loss: 0.3291 - accuracy: 0.8622 - val_loss: 0.3491 - val_accuracy: 0.8580\n",
      "Epoch 69/100\n",
      "400/400 [==============================] - 0s 634us/step - loss: 0.3289 - accuracy: 0.8644 - val_loss: 0.3479 - val_accuracy: 0.8575\n",
      "Epoch 70/100\n",
      "400/400 [==============================] - 0s 628us/step - loss: 0.3292 - accuracy: 0.8635 - val_loss: 0.3479 - val_accuracy: 0.8560\n",
      "Epoch 71/100\n",
      "400/400 [==============================] - 0s 607us/step - loss: 0.3291 - accuracy: 0.8618 - val_loss: 0.3479 - val_accuracy: 0.8585\n",
      "Epoch 72/100\n",
      "400/400 [==============================] - 0s 599us/step - loss: 0.3285 - accuracy: 0.8637 - val_loss: 0.3468 - val_accuracy: 0.8560\n",
      "Epoch 73/100\n",
      "400/400 [==============================] - 0s 606us/step - loss: 0.3288 - accuracy: 0.8626 - val_loss: 0.3480 - val_accuracy: 0.8570\n",
      "Epoch 74/100\n",
      "400/400 [==============================] - 0s 600us/step - loss: 0.3286 - accuracy: 0.8639 - val_loss: 0.3460 - val_accuracy: 0.8560\n",
      "Epoch 75/100\n",
      "400/400 [==============================] - 0s 600us/step - loss: 0.3293 - accuracy: 0.8626 - val_loss: 0.3475 - val_accuracy: 0.8545\n",
      "Epoch 76/100\n",
      "400/400 [==============================] - 0s 609us/step - loss: 0.3287 - accuracy: 0.8633 - val_loss: 0.3458 - val_accuracy: 0.8555\n",
      "Epoch 77/100\n",
      "400/400 [==============================] - 0s 606us/step - loss: 0.3284 - accuracy: 0.8634 - val_loss: 0.3456 - val_accuracy: 0.8560\n",
      "Epoch 78/100\n",
      "400/400 [==============================] - 0s 616us/step - loss: 0.3282 - accuracy: 0.8651 - val_loss: 0.3481 - val_accuracy: 0.8575\n",
      "Epoch 79/100\n",
      "400/400 [==============================] - 0s 606us/step - loss: 0.3280 - accuracy: 0.8636 - val_loss: 0.3468 - val_accuracy: 0.8565\n",
      "Epoch 80/100\n",
      "400/400 [==============================] - 0s 596us/step - loss: 0.3281 - accuracy: 0.8646 - val_loss: 0.3476 - val_accuracy: 0.8585\n",
      "Epoch 81/100\n",
      "400/400 [==============================] - 0s 631us/step - loss: 0.3279 - accuracy: 0.8654 - val_loss: 0.3504 - val_accuracy: 0.8575\n",
      "Epoch 82/100\n",
      "400/400 [==============================] - 0s 597us/step - loss: 0.3275 - accuracy: 0.8624 - val_loss: 0.3459 - val_accuracy: 0.8580\n",
      "Epoch 83/100\n",
      "400/400 [==============================] - 0s 655us/step - loss: 0.3284 - accuracy: 0.8637 - val_loss: 0.3466 - val_accuracy: 0.8570\n",
      "Epoch 84/100\n",
      "400/400 [==============================] - 0s 620us/step - loss: 0.3278 - accuracy: 0.8631 - val_loss: 0.3484 - val_accuracy: 0.8575\n",
      "Epoch 85/100\n",
      "400/400 [==============================] - 0s 621us/step - loss: 0.3274 - accuracy: 0.8639 - val_loss: 0.3455 - val_accuracy: 0.8530\n",
      "Epoch 86/100\n",
      "400/400 [==============================] - 0s 664us/step - loss: 0.3274 - accuracy: 0.8620 - val_loss: 0.3471 - val_accuracy: 0.8570\n",
      "Epoch 87/100\n",
      "400/400 [==============================] - 0s 602us/step - loss: 0.3274 - accuracy: 0.8639 - val_loss: 0.3474 - val_accuracy: 0.8575\n",
      "Epoch 88/100\n",
      "400/400 [==============================] - 0s 619us/step - loss: 0.3267 - accuracy: 0.8633 - val_loss: 0.3462 - val_accuracy: 0.8590\n",
      "Epoch 89/100\n",
      "400/400 [==============================] - 0s 627us/step - loss: 0.3267 - accuracy: 0.8659 - val_loss: 0.3489 - val_accuracy: 0.8595\n",
      "Epoch 90/100\n",
      "400/400 [==============================] - 0s 657us/step - loss: 0.3267 - accuracy: 0.8665 - val_loss: 0.3510 - val_accuracy: 0.8560\n",
      "Epoch 91/100\n",
      "400/400 [==============================] - 0s 595us/step - loss: 0.3268 - accuracy: 0.8649 - val_loss: 0.3459 - val_accuracy: 0.8550\n",
      "Epoch 92/100\n",
      "400/400 [==============================] - 0s 625us/step - loss: 0.3272 - accuracy: 0.8661 - val_loss: 0.3469 - val_accuracy: 0.8575\n",
      "Epoch 93/100\n",
      "400/400 [==============================] - 0s 607us/step - loss: 0.3274 - accuracy: 0.8629 - val_loss: 0.3453 - val_accuracy: 0.8555\n",
      "Epoch 94/100\n",
      "400/400 [==============================] - 0s 605us/step - loss: 0.3267 - accuracy: 0.8659 - val_loss: 0.3451 - val_accuracy: 0.8565\n",
      "Epoch 95/100\n",
      "400/400 [==============================] - 0s 704us/step - loss: 0.3267 - accuracy: 0.8658 - val_loss: 0.3452 - val_accuracy: 0.8540\n",
      "Epoch 96/100\n",
      "400/400 [==============================] - 0s 678us/step - loss: 0.3270 - accuracy: 0.8651 - val_loss: 0.3469 - val_accuracy: 0.8565\n",
      "Epoch 97/100\n",
      "400/400 [==============================] - 0s 606us/step - loss: 0.3266 - accuracy: 0.8652 - val_loss: 0.3448 - val_accuracy: 0.8540\n",
      "Epoch 98/100\n",
      "400/400 [==============================] - 0s 616us/step - loss: 0.3271 - accuracy: 0.8640 - val_loss: 0.3460 - val_accuracy: 0.8555\n",
      "Epoch 99/100\n",
      "400/400 [==============================] - 0s 689us/step - loss: 0.3267 - accuracy: 0.8644 - val_loss: 0.3467 - val_accuracy: 0.8555\n",
      "Epoch 100/100\n",
      "400/400 [==============================] - 0s 660us/step - loss: 0.3264 - accuracy: 0.8645 - val_loss: 0.3460 - val_accuracy: 0.8540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1ff8530430>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on passe à l'ANN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# architecture\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=8, activation='relu', input_dim=11))\n",
    "mlp.add(Dense(units=6, activation='relu'))\n",
    "mlp.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# paramètres d'apprentissage\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# entrainement\n",
    "mlp.fit(X_train_pp, y_train, epochs=100, batch_size=20, validation_data=(X_test_pp, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions sur le testset\n",
    "y_pred = mlp.predict(X_test_pp)\n",
    "classes_pred = 1 * (y_pred > 0.5)\n",
    "\n",
    "# matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "sns.heatmap(confusion_matrix(y_test, classes_pred),\n",
    "            annot=True, cbar=False, fmt='d', cmap='Reds');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1593\n",
      "           1       0.71      0.47      0.57       407\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.79      0.71      0.74      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, classes_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rappel : 180/(180+227) = 0.44226044226044225\n",
      "Précision : 180/(180+62) = 0.743801652892562\n"
     ]
    }
   ],
   "source": [
    "print(f'Rappel : {180/(180+227) = }')\n",
    "print(f'Précision : {180/(180+62) = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation du réseau et affinage des hyper-paramètres\n",
    "\n",
    "Jusqu'à maintenant, on a évalué les réseaux qu'on a vu en regardant uniquement l'accuracy mais cette valeur n'est pas déterministe puisqu'elle dépend de certains paramètres aléatoires comme le train_test_split, l'intialisation des paramètres etc...\n",
    "\n",
    "Une solution par rapport à ce problème est de répéter l'entraînement plusieurs fois et de regarder les résultats en moyenne. On l'a déjà utilisé et ça s'appelle la validation croisée.\n",
    "\n",
    "Mettez en place la validation croisée en utilisant `cross_val_score` puis affiner les paramètres avec `GridSearchCV`.\n",
    "\n",
    "__/!\\\\__ Vous aurez besoin de ce qu'on appelle un wrapper pour pouvoir relier `keras` à `sklearn` et utiliser un modèle de l'un dans l'autre. Ça tombe bien, ça existe : regarder la librairie `keras.wrappers.scikit_learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition d'une fonction pour instancier le modèle\n",
    "def build_ann_clf(optimizer='adam'):\n",
    "    clf = Sequential()\n",
    "    clf.add(Dense(units=8, activation='relu', input_dim=11))\n",
    "    clf.add(Dense(units=6, activation='relu'))\n",
    "    clf.add(Dense(units=1, activation='sigmoid'))\n",
    "    clf.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 10:00:10.133389: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 10:00:10.158133: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 10:00:10.158568: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5629adc97930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 10:00:10.158592: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 10:00:10.194983: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 10:00:10.202220: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 10:00:10.202625: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f156918930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 10:00:10.202650: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 10:00:10.290167: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 10:00:10.297240: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 10:00:10.297988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b1b60e5930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 10:00:10.298267: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 10:00:10.320732: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 10:00:10.323629: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 10:00:10.327626: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 10:00:10.327999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556bf65bc930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 10:00:10.328029: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 10:00:10.328078: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 10:00:10.330416: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 10:00:10.331123: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562efd07e930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 10:00:10.331383: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 10:00:10.366227: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 10:00:10.366957: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x565405fe2930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 10:00:10.366989: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 10:00:10.380717: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 10:00:10.383520: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 10:00:10.387780: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 10:00:10.388184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558c6a8e5930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 10:00:10.388211: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-27 10:00:10.400468: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1999965000 Hz\n",
      "2022-01-27 10:00:10.401152: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d2e3c17930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-27 10:00:10.401181: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 32/720 [>.............................] - ETA: 1s - loss: 0.7552 - accuracy: 0.4437Epoch 1/100\n",
      " 77/720 [==>...........................] - ETA: 0s - loss: 0.6180 - accuracy: 0.6468Epoch 1/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.6821 - accuracy: 0.6000Epoch 1/100\n",
      "116/720 [===>..........................] - ETA: 0s - loss: 0.5898 - accuracy: 0.6905Epoch 1/100\n",
      " 49/720 [=>............................] - ETA: 0s - loss: 0.7408 - accuracy: 0.3714Epoch 1/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.6425 - accuracy: 0.7000Epoch 1/100\n",
      " 90/720 [==>...........................] - ETA: 0s - loss: 0.7164 - accuracy: 0.4767Epoch 1/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.5258 - accuracy: 0.7646\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4806 - accuracy: 0.7815\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.5132 - accuracy: 0.7531\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.5531 - accuracy: 0.7490\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4835 - accuracy: 0.7949\n",
      "619/720 [========================>.....] - ETA: 0s - loss: 0.4817 - accuracy: 0.8019Epoch 2/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4788 - accuracy: 0.7885\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7503\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.8012\n",
      "267/720 [==========>...................] - ETA: 0s - loss: 0.4325 - accuracy: 0.8056Epoch 2/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4142 - accuracy: 0.8194\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4258 - accuracy: 0.8129\n",
      " 33/720 [>.............................] - ETA: 1s - loss: 0.3952 - accuracy: 0.8394Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4251 - accuracy: 0.8067\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4262 - accuracy: 0.8071\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4163 - accuracy: 0.8183\n",
      "557/720 [======================>.......] - ETA: 0s - loss: 0.4164 - accuracy: 0.8163Epoch 3/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.6363 - accuracy: 0.6000Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4357 - accuracy: 0.7964\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4164 - accuracy: 0.8254\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4182 - accuracy: 0.8132\n",
      "257/720 [=========>....................] - ETA: 0s - loss: 0.3972 - accuracy: 0.8374Epoch 3/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3812 - accuracy: 0.8356\n",
      "660/720 [==========================>...] - ETA: 0s - loss: 0.4044 - accuracy: 0.8297Epoch 4/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4023 - accuracy: 0.8319\n",
      "442/720 [=================>............] - ETA: 0s - loss: 0.4001 - accuracy: 0.8190Epoch 4/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3695 - accuracy: 0.8415\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3987 - accuracy: 0.8182\n",
      "Epoch 4/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.3842 - accuracy: 0.8000Epoch 4/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4274 - accuracy: 0.8032\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4123 - accuracy: 0.8126\n",
      "Epoch 4/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.2306 - accuracy: 1.0000Epoch 4/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3806 - accuracy: 0.8413\n",
      "Epoch 4/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4023 - accuracy: 0.8197\n",
      "Epoch 4/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3671 - accuracy: 0.8429\n",
      "Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3737 - accuracy: 0.8493\n",
      "Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3988 - accuracy: 0.8175\n",
      "Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3764 - accuracy: 0.8383\n",
      "Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3630 - accuracy: 0.8504\n",
      "Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3582 - accuracy: 0.8497\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4215 - accuracy: 0.8138\n",
      "Epoch 5/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.5576 - accuracy: 0.7000Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3885 - accuracy: 0.8256\n",
      "188/720 [======>.......................] - ETA: 0s - loss: 0.3642 - accuracy: 0.8532Epoch 5/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3607 - accuracy: 0.8492\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3630 - accuracy: 0.8479\n",
      "651/720 [==========================>...] - ETA: 0s - loss: 0.4139 - accuracy: 0.8249Epoch 6/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3563 - accuracy: 0.8564\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3830 - accuracy: 0.8354\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3543 - accuracy: 0.8556\n",
      "685/720 [===========================>..] - ETA: 0s - loss: 0.4152 - accuracy: 0.8241Epoch 6/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3530 - accuracy: 0.8522\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4155 - accuracy: 0.8226\n",
      "582/720 [=======================>......] - ETA: 0s - loss: 0.3831 - accuracy: 0.8249Epoch 6/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3787 - accuracy: 0.8285\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3561 - accuracy: 0.8501\n",
      "655/720 [==========================>...] - ETA: 0s - loss: 0.3462 - accuracy: 0.8598Epoch 7/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3466 - accuracy: 0.8594\n",
      "Epoch 7/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3486 - accuracy: 0.8578\n",
      "Epoch 7/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3692 - accuracy: 0.8458\n",
      "Epoch 7/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8511\n",
      "113/720 [===>..........................] - ETA: 0s - loss: 0.3325 - accuracy: 0.8752Epoch 7/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.4062 - accuracy: 0.8301\n",
      "Epoch 7/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8544\n",
      "Epoch 7/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3721 - accuracy: 0.8353\n",
      "Epoch 7/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8550\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3418 - accuracy: 0.8611\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3526 - accuracy: 0.8565\n",
      " 30/720 [>.............................] - ETA: 1s - loss: 0.3611 - accuracy: 0.8500Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3611 - accuracy: 0.8490\n",
      " 32/720 [>.............................] - ETA: 1s - loss: 0.3458 - accuracy: 0.8500Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3916 - accuracy: 0.8374\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8564\n",
      " 29/720 [>.............................] - ETA: 1s - loss: 0.3806 - accuracy: 0.8345Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3474 - accuracy: 0.8568\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3662 - accuracy: 0.8514\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3558 - accuracy: 0.8537\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3503 - accuracy: 0.8554\n",
      "504/720 [====================>.........] - ETA: 0s - loss: 0.3423 - accuracy: 0.8556Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3389 - accuracy: 0.8612\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3752 - accuracy: 0.8457\n",
      " 37/720 [>.............................] - ETA: 0s - loss: 0.3841 - accuracy: 0.8432Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3503 - accuracy: 0.8549\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3427 - accuracy: 0.8579\n",
      " 36/720 [>.............................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8722Epoch 9/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8568\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3628 - accuracy: 0.8557\n",
      "279/720 [==========>...................] - ETA: 0s - loss: 0.3390 - accuracy: 0.8613Epoch 9/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3530 - accuracy: 0.8553\n",
      "598/720 [=======================>......] - ETA: 0s - loss: 0.3389 - accuracy: 0.8605Epoch 10/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3483 - accuracy: 0.8564\n",
      "Epoch 10/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3487 - accuracy: 0.8562\n",
      "Epoch 10/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3590 - accuracy: 0.8551\n",
      " 54/720 [=>............................] - ETA: 1s - loss: 0.3420 - accuracy: 0.8407Epoch 10/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3375 - accuracy: 0.8631\n",
      "Epoch 10/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3412 - accuracy: 0.8592\n",
      "610/720 [========================>.....] - ETA: 0s - loss: 0.3424 - accuracy: 0.8574Epoch 10/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3435 - accuracy: 0.8578\n",
      "Epoch 10/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3595 - accuracy: 0.8599\n",
      "Epoch 10/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3509 - accuracy: 0.8567\n",
      "389/720 [===============>..............] - ETA: 0s - loss: 0.3577 - accuracy: 0.8620Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3465 - accuracy: 0.8575\n",
      "696/720 [============================>.] - ETA: 0s - loss: 0.3496 - accuracy: 0.8568Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3489 - accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3473 - accuracy: 0.8571\n",
      " 30/720 [>.............................] - ETA: 1s - loss: 0.3383 - accuracy: 0.8600Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3355 - accuracy: 0.8621\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3400 - accuracy: 0.8585\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3425 - accuracy: 0.8587\n",
      "642/720 [=========================>....] - ETA: 0s - loss: 0.3529 - accuracy: 0.8621Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3566 - accuracy: 0.8596\n",
      "259/720 [=========>....................] - ETA: 0s - loss: 0.3484 - accuracy: 0.8560Epoch 11/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3489 - accuracy: 0.8576\n",
      "452/720 [=================>............] - ETA: 0s - loss: 0.3450 - accuracy: 0.8544Epoch 12/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3460 - accuracy: 0.8586\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3343 - accuracy: 0.8626\n",
      "Epoch 12/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.0652 - accuracy: 1.0000Epoch 12/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3451 - accuracy: 0.8590\n",
      "Epoch 12/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3390 - accuracy: 0.8585\n",
      "Epoch 12/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8574\n",
      "Epoch 12/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8572\n",
      "111/720 [===>..........................] - ETA: 0s - loss: 0.3459 - accuracy: 0.8640Epoch 12/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3536 - accuracy: 0.8626\n",
      "206/720 [=======>......................] - ETA: 0s - loss: 0.3424 - accuracy: 0.8607Epoch 12/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3474 - accuracy: 0.8587\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3384 - accuracy: 0.8592\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3421 - accuracy: 0.8581\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3448 - accuracy: 0.8608\n",
      "Epoch 13/100\n",
      " 37/720 [>.............................] - ETA: 0s - loss: 0.3545 - accuracy: 0.8514Epoch 13/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8637\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3435 - accuracy: 0.8599\n",
      " 37/720 [>.............................] - ETA: 0s - loss: 0.3384 - accuracy: 0.8486Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3399 - accuracy: 0.8593\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8635\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3463 - accuracy: 0.8585\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3378 - accuracy: 0.8610\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3319 - accuracy: 0.8644\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3435 - accuracy: 0.8603\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8581\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.8590\n",
      " 76/720 [==>...........................] - ETA: 0s - loss: 0.3232 - accuracy: 0.8724Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3399 - accuracy: 0.8603\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3495 - accuracy: 0.8624\n",
      "264/720 [==========>...................] - ETA: 0s - loss: 0.3379 - accuracy: 0.8610Epoch 14/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3449 - accuracy: 0.8603\n",
      "686/720 [===========================>..] - ETA: 0s - loss: 0.3315 - accuracy: 0.8644Epoch 15/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3313 - accuracy: 0.8643\n",
      "588/720 [=======================>......] - ETA: 0s - loss: 0.3380 - accuracy: 0.8617Epoch 15/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3367 - accuracy: 0.8608\n",
      "397/720 [===============>..............] - ETA: 0s - loss: 0.3480 - accuracy: 0.8637Epoch 15/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3394 - accuracy: 0.8603\n",
      "112/720 [===>..........................] - ETA: 0s - loss: 0.3838 - accuracy: 0.8402Epoch 15/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8603\n",
      "Epoch 15/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3415 - accuracy: 0.8593\n",
      "626/720 [=========================>....] - ETA: 0s - loss: 0.3384 - accuracy: 0.8599Epoch 15/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8592\n",
      "Epoch 15/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3474 - accuracy: 0.8633\n",
      "Epoch 15/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3441 - accuracy: 0.8601\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3304 - accuracy: 0.8628\n",
      "Epoch 16/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.4276 - accuracy: 0.9000Epoch 16/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3361 - accuracy: 0.8621\n",
      "Epoch 16/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3382 - accuracy: 0.8606\n",
      "Epoch 16/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3410 - accuracy: 0.8606\n",
      "Epoch 16/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8610\n",
      "150/720 [=====>........................] - ETA: 0s - loss: 0.3168 - accuracy: 0.8740Epoch 16/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3386 - accuracy: 0.8592\n",
      "Epoch 16/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3457 - accuracy: 0.8631\n",
      "Epoch 16/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3296 - accuracy: 0.8640\n",
      "506/720 [====================>.........] - ETA: 0s - loss: 0.3318 - accuracy: 0.8644Epoch 17/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.8586\n",
      "402/720 [===============>..............] - ETA: 0s - loss: 0.3349 - accuracy: 0.8597Epoch 17/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3352 - accuracy: 0.8618\n",
      "437/720 [=================>............] - ETA: 0s - loss: 0.3358 - accuracy: 0.8590Epoch 17/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3375 - accuracy: 0.8594\n",
      "Epoch 17/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3410 - accuracy: 0.8610\n",
      "Epoch 17/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3399 - accuracy: 0.8601\n",
      "179/720 [======>.......................] - ETA: 0s - loss: 0.3388 - accuracy: 0.8609Epoch 17/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3383 - accuracy: 0.8608\n",
      "Epoch 17/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8658\n",
      "Epoch 17/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3434 - accuracy: 0.8615\n",
      "534/720 [=====================>........] - ETA: 0s - loss: 0.3335 - accuracy: 0.8650Epoch 18/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8624\n",
      "445/720 [=================>............] - ETA: 0s - loss: 0.3409 - accuracy: 0.8596Epoch 18/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.8621\n",
      "Epoch 18/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8611\n",
      "Epoch 18/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3395 - accuracy: 0.8614\n",
      "541/720 [=====================>........] - ETA: 0s - loss: 0.3449 - accuracy: 0.8617Epoch 18/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3401 - accuracy: 0.8617\n",
      "264/720 [==========>...................] - ETA: 0s - loss: 0.3437 - accuracy: 0.8591Epoch 18/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3379 - accuracy: 0.8594\n",
      " 76/720 [==>...........................] - ETA: 0s - loss: 0.3535 - accuracy: 0.8500Epoch 18/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3432 - accuracy: 0.8636\n",
      "Epoch 18/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3410 - accuracy: 0.8610\n",
      "677/720 [===========================>..] - ETA: 0s - loss: 0.3270 - accuracy: 0.8647Epoch 19/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3284 - accuracy: 0.8637\n",
      "Epoch 19/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3346 - accuracy: 0.8621\n",
      "Epoch 19/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3348 - accuracy: 0.8612\n",
      "629/720 [=========================>....] - ETA: 0s - loss: 0.3373 - accuracy: 0.8652Epoch 19/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3391 - accuracy: 0.8636\n",
      "Epoch 19/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3385 - accuracy: 0.8639\n",
      "179/720 [======>.......................] - ETA: 0s - loss: 0.3395 - accuracy: 0.8581Epoch 19/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3375 - accuracy: 0.8624\n",
      "Epoch 19/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8654\n",
      "Epoch 19/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3420 - accuracy: 0.8637\n",
      "Epoch 20/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3283 - accuracy: 0.8636\n",
      "446/720 [=================>............] - ETA: 0s - loss: 0.3426 - accuracy: 0.8621Epoch 20/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3341 - accuracy: 0.8632\n",
      "579/720 [=======================>......] - ETA: 0s - loss: 0.3393 - accuracy: 0.8618Epoch 20/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8622\n",
      "Epoch 20/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3386 - accuracy: 0.8624\n",
      "683/720 [===========================>..] - ETA: 0s - loss: 0.3376 - accuracy: 0.8599Epoch 20/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8615\n",
      "457/720 [==================>...........] - ETA: 0s - loss: 0.3377 - accuracy: 0.8678Epoch 20/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3374 - accuracy: 0.8600\n",
      "Epoch 20/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8640\n",
      "Epoch 20/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3282 - accuracy: 0.8622\n",
      "Epoch 21/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3411 - accuracy: 0.8628\n",
      "Epoch 21/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3342 - accuracy: 0.8631\n",
      "Epoch 21/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3343 - accuracy: 0.8622\n",
      "Epoch 21/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3379 - accuracy: 0.8615\n",
      "455/720 [=================>............] - ETA: 0s - loss: 0.3390 - accuracy: 0.8642Epoch 21/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8614\n",
      "235/720 [========>.....................] - ETA: 0s - loss: 0.3436 - accuracy: 0.8621Epoch 21/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8599\n",
      "524/720 [====================>.........] - ETA: 0s - loss: 0.3406 - accuracy: 0.8635Epoch 21/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8647\n",
      "504/720 [====================>.........] - ETA: 0s - loss: 0.3313 - accuracy: 0.8643Epoch 21/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3275 - accuracy: 0.8643\n",
      "Epoch 22/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.8624\n",
      "Epoch 22/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3338 - accuracy: 0.8631\n",
      "641/720 [=========================>....] - ETA: 0s - loss: 0.3352 - accuracy: 0.8604Epoch 22/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3336 - accuracy: 0.8621\n",
      "Epoch 22/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3366 - accuracy: 0.8615\n",
      "Epoch 22/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3380 - accuracy: 0.8618\n",
      "Epoch 22/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.8608\n",
      "Epoch 22/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3402 - accuracy: 0.8646\n",
      "173/720 [======>.......................] - ETA: 0s - loss: 0.3253 - accuracy: 0.8694Epoch 22/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3277 - accuracy: 0.8651\n",
      "Epoch 23/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3391 - accuracy: 0.8624\n",
      "Epoch 23/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8637\n",
      "623/720 [========================>.....] - ETA: 0s - loss: 0.3334 - accuracy: 0.8610Epoch 23/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3333 - accuracy: 0.8624\n",
      "Epoch 23/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3372 - accuracy: 0.8607\n",
      "Epoch 23/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3369 - accuracy: 0.8610\n",
      "144/720 [=====>........................] - ETA: 0s - loss: 0.3275 - accuracy: 0.8625Epoch 23/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3359 - accuracy: 0.8607\n",
      "Epoch 23/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8644\n",
      "555/720 [======================>.......] - ETA: 0s - loss: 0.3242 - accuracy: 0.8609Epoch 23/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8624\n",
      "Epoch 24/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3391 - accuracy: 0.8615\n",
      "601/720 [========================>.....] - ETA: 0s - loss: 0.3393 - accuracy: 0.8642Epoch 24/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.8642\n",
      "Epoch 24/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3371 - accuracy: 0.8643\n",
      "661/720 [==========================>...] - ETA: 0s - loss: 0.3358 - accuracy: 0.8610Epoch 24/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3361 - accuracy: 0.8615\n",
      "197/720 [=======>......................] - ETA: 0s - loss: 0.2926 - accuracy: 0.8878Epoch 24/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8631\n",
      " 34/720 [>.............................] - ETA: 1s - loss: 0.3613 - accuracy: 0.8647Epoch 24/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3358 - accuracy: 0.8610\n",
      "Epoch 24/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3387 - accuracy: 0.8658\n",
      "550/720 [=====================>........] - ETA: 0s - loss: 0.3380 - accuracy: 0.8616Epoch 24/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3271 - accuracy: 0.8671\n",
      "Epoch 25/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.8626\n",
      "579/720 [=======================>......] - ETA: 0s - loss: 0.3343 - accuracy: 0.8620Epoch 25/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.8628\n",
      "Epoch 25/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3363 - accuracy: 0.8631\n",
      " 71/720 [=>............................] - ETA: 0s - loss: 0.3450 - accuracy: 0.8676Epoch 25/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3318 - accuracy: 0.8635\n",
      "135/720 [====>.........................] - ETA: 0s - loss: 0.3212 - accuracy: 0.8644Epoch 25/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8624\n",
      "274/720 [==========>...................] - ETA: 0s - loss: 0.3462 - accuracy: 0.8591Epoch 25/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3351 - accuracy: 0.8640\n",
      "114/720 [===>..........................] - ETA: 0s - loss: 0.3486 - accuracy: 0.8544Epoch 25/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.8664\n",
      "Epoch 25/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3261 - accuracy: 0.8656\n",
      "Epoch 26/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.8642\n",
      "601/720 [========================>.....] - ETA: 0s - loss: 0.3422 - accuracy: 0.8594Epoch 26/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3381 - accuracy: 0.8614\n",
      " 76/720 [==>...........................] - ETA: 0s - loss: 0.3386 - accuracy: 0.8645Epoch 26/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3369 - accuracy: 0.8621\n",
      "Epoch 26/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3310 - accuracy: 0.8621\n",
      "Epoch 26/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3352 - accuracy: 0.8621\n",
      "Epoch 26/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3349 - accuracy: 0.8624\n",
      "Epoch 26/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3374 - accuracy: 0.8643\n",
      "498/720 [===================>..........] - ETA: 0s - loss: 0.3367 - accuracy: 0.8606Epoch 26/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3259 - accuracy: 0.8647\n",
      "Epoch 27/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3314 - accuracy: 0.8646\n",
      "526/720 [====================>.........] - ETA: 0s - loss: 0.3355 - accuracy: 0.8608Epoch 27/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3376 - accuracy: 0.8628\n",
      "Epoch 27/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8635\n",
      "Epoch 27/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8636\n",
      "Epoch 27/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3349 - accuracy: 0.8619\n",
      " 27/720 [>.............................] - ETA: 1s - loss: 0.3754 - accuracy: 0.8333Epoch 27/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8631\n",
      "119/720 [===>..........................] - ETA: 1s - loss: 0.3397 - accuracy: 0.8538Epoch 27/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3370 - accuracy: 0.8665\n",
      "665/720 [==========================>...] - ETA: 0s - loss: 0.3393 - accuracy: 0.8630Epoch 27/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.8628\n",
      "Epoch 28/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3252 - accuracy: 0.8646\n",
      "Epoch 28/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3373 - accuracy: 0.8636\n",
      "Epoch 28/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3355 - accuracy: 0.8628\n",
      "212/720 [=======>......................] - ETA: 0s - loss: 0.3498 - accuracy: 0.8632Epoch 28/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3341 - accuracy: 0.8621\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3348 - accuracy: 0.8624\n",
      "Epoch 28/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.2279 - accuracy: 1.0000Epoch 28/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8631\n",
      "236/720 [========>.....................] - ETA: 0s - loss: 0.3118 - accuracy: 0.8737Epoch 28/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3368 - accuracy: 0.8661\n",
      "436/720 [=================>............] - ETA: 0s - loss: 0.3339 - accuracy: 0.8628Epoch 28/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3319 - accuracy: 0.8643\n",
      "Epoch 29/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3368 - accuracy: 0.8626\n",
      "Epoch 29/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.8642\n",
      "Epoch 29/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.8626\n",
      "Epoch 29/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3339 - accuracy: 0.8614\n",
      "Epoch 29/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3339 - accuracy: 0.8626\n",
      "332/720 [============>.................] - ETA: 0s - loss: 0.3470 - accuracy: 0.8602Epoch 29/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8625\n",
      "Epoch 29/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3311 - accuracy: 0.8636\n",
      "Epoch 30/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3363 - accuracy: 0.8649\n",
      "Epoch 29/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8612\n",
      "Epoch 30/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3263 - accuracy: 0.8646\n",
      "Epoch 30/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3351 - accuracy: 0.8626\n",
      "193/720 [=======>......................] - ETA: 0s - loss: 0.3227 - accuracy: 0.8699Epoch 30/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3338 - accuracy: 0.8614\n",
      "Epoch 30/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3295 - accuracy: 0.8636\n",
      "Epoch 30/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3340 - accuracy: 0.8637\n",
      "Epoch 30/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3364 - accuracy: 0.8657\n",
      "Epoch 30/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8644\n",
      "Epoch 31/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3358 - accuracy: 0.8632\n",
      "Epoch 31/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3256 - accuracy: 0.8651\n",
      "498/720 [===================>..........] - ETA: 0s - loss: 0.3305 - accuracy: 0.8627Epoch 31/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3343 - accuracy: 0.8624\n",
      "611/720 [========================>.....] - ETA: 0s - loss: 0.3260 - accuracy: 0.8668Epoch 31/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3342 - accuracy: 0.8643\n",
      "Epoch 31/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3298 - accuracy: 0.8629\n",
      "Epoch 31/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3335 - accuracy: 0.8631\n",
      "Epoch 31/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3356 - accuracy: 0.8660\n",
      "468/720 [==================>...........] - ETA: 0s - loss: 0.3317 - accuracy: 0.8632Epoch 31/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.8629\n",
      "Epoch 32/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3357 - accuracy: 0.8631\n",
      "675/720 [===========================>..] - ETA: 0s - loss: 0.3262 - accuracy: 0.8656Epoch 32/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8647\n",
      "Epoch 32/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3339 - accuracy: 0.8606\n",
      "688/720 [===========================>..] - ETA: 0s - loss: 0.3359 - accuracy: 0.8629Epoch 32/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8639\n",
      "290/720 [===========>..................] - ETA: 0s - loss: 0.3511 - accuracy: 0.8545Epoch 32/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3292 - accuracy: 0.8628\n",
      "325/720 [============>.................] - ETA: 0s - loss: 0.3428 - accuracy: 0.8600Epoch 32/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8642\n",
      "256/720 [=========>....................] - ETA: 0s - loss: 0.3241 - accuracy: 0.8707Epoch 32/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3312 - accuracy: 0.8643\n",
      "Epoch 33/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3340 - accuracy: 0.8669\n",
      "448/720 [=================>............] - ETA: 0s - loss: 0.3357 - accuracy: 0.8583Epoch 32/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3354 - accuracy: 0.8631\n",
      "Epoch 33/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3251 - accuracy: 0.8640\n",
      "Epoch 33/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3341 - accuracy: 0.8622\n",
      "Epoch 33/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8622\n",
      "Epoch 33/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8625\n",
      "Epoch 33/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.8637\n",
      "498/720 [===================>..........] - ETA: 0s - loss: 0.3337 - accuracy: 0.8637Epoch 33/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3315 - accuracy: 0.8629\n",
      "Epoch 34/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3350 - accuracy: 0.8639\n",
      "419/720 [================>.............] - ETA: 0s - loss: 0.3310 - accuracy: 0.8647Epoch 34/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8649\n",
      "655/720 [==========================>...] - ETA: 0s - loss: 0.3269 - accuracy: 0.8640Epoch 33/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3254 - accuracy: 0.8650\n",
      " 72/720 [==>...........................] - ETA: 0s - loss: 0.2951 - accuracy: 0.8931Epoch 34/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8622\n",
      "386/720 [===============>..............] - ETA: 0s - loss: 0.3398 - accuracy: 0.8585Epoch 34/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8632\n",
      "Epoch 34/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8635\n",
      "Epoch 34/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.8639\n",
      "Epoch 34/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3311 - accuracy: 0.8635\n",
      "Epoch 35/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3353 - accuracy: 0.8626\n",
      " 58/720 [=>............................] - ETA: 1s - loss: 0.3530 - accuracy: 0.8431Epoch 35/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.8647\n",
      "681/720 [===========================>..] - ETA: 0s - loss: 0.3230 - accuracy: 0.8651Epoch 34/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3250 - accuracy: 0.8650\n",
      "Epoch 35/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3334 - accuracy: 0.8628\n",
      "Epoch 35/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8636\n",
      "693/720 [===========================>..] - ETA: 0s - loss: 0.3268 - accuracy: 0.8658Epoch 35/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8653\n",
      "389/720 [===============>..............] - ETA: 0s - loss: 0.3212 - accuracy: 0.8679Epoch 35/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3326 - accuracy: 0.8633\n",
      "Epoch 35/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.8637\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3346 - accuracy: 0.8636\n",
      "686/720 [===========================>..] - ETA: 0s - loss: 0.3323 - accuracy: 0.8652Epoch 36/100\n",
      "313/720 [============>.................] - ETA: 0s - loss: 0.3280 - accuracy: 0.8617Epoch 36/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3320 - accuracy: 0.8657\n",
      "Epoch 35/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8647\n",
      "Epoch 36/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8610\n",
      "Epoch 36/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3334 - accuracy: 0.8621\n",
      "Epoch 36/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3283 - accuracy: 0.8636\n",
      " 39/720 [>.............................] - ETA: 0s - loss: 0.3006 - accuracy: 0.8897Epoch 36/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3321 - accuracy: 0.8649\n",
      "Epoch 36/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3339 - accuracy: 0.8625\n",
      "347/720 [=============>................] - ETA: 0s - loss: 0.3296 - accuracy: 0.8634Epoch 37/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8639\n",
      "Epoch 37/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3320 - accuracy: 0.8642\n",
      "Epoch 36/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3251 - accuracy: 0.8643\n",
      "101/720 [===>..........................] - ETA: 0s - loss: 0.3052 - accuracy: 0.8871Epoch 37/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.8628\n",
      "281/720 [==========>...................] - ETA: 0s - loss: 0.3177 - accuracy: 0.8715Epoch 37/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3283 - accuracy: 0.8635\n",
      "Epoch 37/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8639\n",
      "598/720 [=======================>......] - ETA: 0s - loss: 0.3330 - accuracy: 0.8652Epoch 37/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.8649\n",
      "485/720 [===================>..........] - ETA: 0s - loss: 0.3186 - accuracy: 0.8654Epoch 37/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3349 - accuracy: 0.8639\n",
      "Epoch 38/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3314 - accuracy: 0.8646\n",
      "Epoch 37/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8636\n",
      "Epoch 38/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8646\n",
      "Epoch 38/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.8615\n",
      "Epoch 38/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8631\n",
      "151/720 [=====>........................] - ETA: 0s - loss: 0.3180 - accuracy: 0.8662Epoch 38/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8637\n",
      "449/720 [=================>............] - ETA: 0s - loss: 0.3344 - accuracy: 0.8621Epoch 38/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3318 - accuracy: 0.8631\n",
      "432/720 [=================>............] - ETA: 0s - loss: 0.3245 - accuracy: 0.8637Epoch 38/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3333 - accuracy: 0.8657\n",
      "523/720 [====================>.........] - ETA: 0s - loss: 0.3266 - accuracy: 0.8625Epoch 39/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3314 - accuracy: 0.8651\n",
      "Epoch 38/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3310 - accuracy: 0.8640\n",
      "658/720 [==========================>...] - ETA: 0s - loss: 0.3212 - accuracy: 0.8658Epoch 39/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.8650\n",
      "557/720 [======================>.......] - ETA: 0s - loss: 0.3352 - accuracy: 0.8619Epoch 39/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3325 - accuracy: 0.8629\n",
      "Epoch 39/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8629\n",
      "651/720 [==========================>...] - ETA: 0s - loss: 0.3364 - accuracy: 0.8604Epoch 39/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8621\n",
      "531/720 [=====================>........] - ETA: 0s - loss: 0.3316 - accuracy: 0.8680Epoch 39/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8646\n",
      "Epoch 39/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8644\n",
      "551/720 [=====================>........] - ETA: 0s - loss: 0.3250 - accuracy: 0.8646Epoch 40/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3307 - accuracy: 0.8674\n",
      "Epoch 39/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3308 - accuracy: 0.8643\n",
      "Epoch 40/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8661\n",
      "Epoch 40/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8622\n",
      "Epoch 40/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3270 - accuracy: 0.8622\n",
      "Epoch 40/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3324 - accuracy: 0.8632\n",
      "Epoch 40/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.8647\n",
      "Epoch 40/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3307 - accuracy: 0.8649\n",
      "Epoch 41/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8640\n",
      "564/720 [======================>.......] - ETA: 0s - loss: 0.3288 - accuracy: 0.8658Epoch 41/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3314 - accuracy: 0.8640\n",
      "327/720 [============>.................] - ETA: 0s - loss: 0.3270 - accuracy: 0.8636Epoch 40/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3234 - accuracy: 0.8662\n",
      "Epoch 41/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8622\n",
      "Epoch 41/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8644\n",
      "Epoch 41/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8637\n",
      "Epoch 41/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3311 - accuracy: 0.8635\n",
      "Epoch 41/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.8633\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3310 - accuracy: 0.8650\n",
      "268/720 [==========>...................] - ETA: 0s - loss: 0.3266 - accuracy: 0.8649Epoch 42/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.0893 - accuracy: 1.0000Epoch 41/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8650\n",
      "Epoch 42/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3241 - accuracy: 0.8660\n",
      "130/720 [====>.........................] - ETA: 0s - loss: 0.3355 - accuracy: 0.8631Epoch 42/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3319 - accuracy: 0.8632\n",
      "436/720 [=================>............] - ETA: 0s - loss: 0.3330 - accuracy: 0.8617Epoch 42/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8632\n",
      "642/720 [=========================>....] - ETA: 0s - loss: 0.3305 - accuracy: 0.8642Epoch 42/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8635\n",
      "558/720 [======================>.......] - ETA: 0s - loss: 0.3248 - accuracy: 0.8701Epoch 42/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.8635\n",
      "704/720 [============================>.] - ETA: 0s - loss: 0.3316 - accuracy: 0.8653Epoch 43/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8656\n",
      "674/720 [===========================>..] - ETA: 0s - loss: 0.3319 - accuracy: 0.8662Epoch 42/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8664\n",
      "Epoch 42/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8636\n",
      "Epoch 43/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3242 - accuracy: 0.8665\n",
      "435/720 [=================>............] - ETA: 0s - loss: 0.3276 - accuracy: 0.8683Epoch 43/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8637\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3268 - accuracy: 0.8624\n",
      "Epoch 43/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.1671 - accuracy: 1.0000Epoch 43/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.8651\n",
      "Epoch 43/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3328 - accuracy: 0.8644\n",
      "Epoch 44/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8633\n",
      "260/720 [=========>....................] - ETA: 0s - loss: 0.3265 - accuracy: 0.8646Epoch 43/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8662\n",
      "Epoch 43/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3305 - accuracy: 0.8660\n",
      "Epoch 44/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3241 - accuracy: 0.8651\n",
      "142/720 [====>.........................] - ETA: 0s - loss: 0.3595 - accuracy: 0.8556Epoch 44/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3269 - accuracy: 0.8633\n",
      "Epoch 44/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8619\n",
      "647/720 [=========================>....] - ETA: 0s - loss: 0.3273 - accuracy: 0.8665Epoch 44/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3318 - accuracy: 0.8637\n",
      "Epoch 44/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3324 - accuracy: 0.8629\n",
      "Epoch 45/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8650\n",
      "Epoch 44/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3307 - accuracy: 0.8656\n",
      "Epoch 44/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8642\n",
      "118/720 [===>..........................] - ETA: 1s - loss: 0.3244 - accuracy: 0.8644Epoch 45/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8642\n",
      "Epoch 45/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3264 - accuracy: 0.8636\n",
      "656/720 [==========================>...] - ETA: 0s - loss: 0.3311 - accuracy: 0.8640Epoch 45/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3320 - accuracy: 0.8622\n",
      "529/720 [=====================>........] - ETA: 0s - loss: 0.3396 - accuracy: 0.8599Epoch 45/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8637\n",
      "Epoch 45/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3324 - accuracy: 0.8649\n",
      "602/720 [========================>.....] - ETA: 0s - loss: 0.3284 - accuracy: 0.8650Epoch 46/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3305 - accuracy: 0.8637\n",
      "718/720 [============================>.] - ETA: 0s - loss: 0.3299 - accuracy: 0.8645Epoch 46/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3304 - accuracy: 0.8643\n",
      "369/720 [==============>...............] - ETA: 0s - loss: 0.3258 - accuracy: 0.8634Epoch 45/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8644\n",
      "Epoch 45/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8653\n",
      "Epoch 46/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3264 - accuracy: 0.8640\n",
      "Epoch 46/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8644\n",
      "Epoch 46/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3317 - accuracy: 0.8632\n",
      "496/720 [===================>..........] - ETA: 0s - loss: 0.3263 - accuracy: 0.8643Epoch 46/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3324 - accuracy: 0.8639\n",
      "Epoch 47/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3302 - accuracy: 0.8654\n",
      "630/720 [=========================>....] - ETA: 0s - loss: 0.3324 - accuracy: 0.8638Epoch 47/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3307 - accuracy: 0.8644\n",
      "Epoch 46/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3311 - accuracy: 0.8631\n",
      "232/720 [========>.....................] - ETA: 0s - loss: 0.3307 - accuracy: 0.8668Epoch 46/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3234 - accuracy: 0.8657\n",
      "Epoch 47/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3256 - accuracy: 0.8633\n",
      "Epoch 47/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8642\n",
      "330/720 [============>.................] - ETA: 0s - loss: 0.3315 - accuracy: 0.8688Epoch 47/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.8624\n",
      "555/720 [======================>.......] - ETA: 0s - loss: 0.3294 - accuracy: 0.8641Epoch 47/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.8635\n",
      "443/720 [=================>............] - ETA: 0s - loss: 0.3290 - accuracy: 0.8679Epoch 48/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8639\n",
      "Epoch 48/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8667\n",
      "686/720 [===========================>..] - ETA: 0s - loss: 0.3312 - accuracy: 0.8644Epoch 47/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8643\n",
      "Epoch 47/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3236 - accuracy: 0.8671\n",
      "301/720 [===========>..................] - ETA: 0s - loss: 0.3337 - accuracy: 0.8654Epoch 48/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8635\n",
      "Epoch 48/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3319 - accuracy: 0.8643\n",
      "Epoch 49/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8619\n",
      "702/720 [============================>.] - ETA: 0s - loss: 0.3322 - accuracy: 0.8632Epoch 48/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8629\n",
      "228/720 [========>.....................] - ETA: 0s - loss: 0.3109 - accuracy: 0.8645Epoch 48/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3304 - accuracy: 0.8633\n",
      "327/720 [============>.................] - ETA: 0s - loss: 0.3172 - accuracy: 0.8639Epoch 49/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8658\n",
      "299/720 [===========>..................] - ETA: 0s - loss: 0.3232 - accuracy: 0.8672Epoch 48/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8649\n",
      "296/720 [===========>..................] - ETA: 0s - loss: 0.3323 - accuracy: 0.8591Epoch 48/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8651\n",
      "163/720 [=====>........................] - ETA: 1s - loss: 0.3420 - accuracy: 0.8626Epoch 49/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3261 - accuracy: 0.8633\n",
      "Epoch 49/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3320 - accuracy: 0.8618\n",
      "132/720 [====>.........................] - ETA: 1s - loss: 0.3008 - accuracy: 0.8727Epoch 50/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3311 - accuracy: 0.8622\n",
      "Epoch 49/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8628\n",
      "Epoch 49/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8658\n",
      "Epoch 50/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3306 - accuracy: 0.8650\n",
      "Epoch 49/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8651\n",
      " 28/720 [>.............................] - ETA: 1s - loss: 0.2804 - accuracy: 0.8929Epoch 49/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8647\n",
      "Epoch 50/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8621\n",
      "Epoch 50/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3317 - accuracy: 0.8640\n",
      "Epoch 51/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3313 - accuracy: 0.8628\n",
      "Epoch 50/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8629\n",
      "155/720 [=====>........................] - ETA: 0s - loss: 0.3380 - accuracy: 0.8568Epoch 50/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8636\n",
      "608/720 [========================>.....] - ETA: 0s - loss: 0.3328 - accuracy: 0.8633Epoch 51/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8644\n",
      "Epoch 50/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8653\n",
      "313/720 [============>.................] - ETA: 0s - loss: 0.3315 - accuracy: 0.8620Epoch 50/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3229 - accuracy: 0.8651\n",
      "Epoch 51/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3258 - accuracy: 0.8631\n",
      "Epoch 51/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8621\n",
      "573/720 [======================>.......] - ETA: 0s - loss: 0.3316 - accuracy: 0.8634Epoch 51/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8632\n",
      "415/720 [================>.............] - ETA: 0s - loss: 0.3269 - accuracy: 0.8663Epoch 52/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3302 - accuracy: 0.8640\n",
      "254/720 [=========>....................] - ETA: 0s - loss: 0.3289 - accuracy: 0.8654Epoch 52/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8640\n",
      "Epoch 51/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8653\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3304 - accuracy: 0.8653\n",
      "Epoch 51/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.1884 - accuracy: 0.9000Epoch 51/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3229 - accuracy: 0.8660\n",
      "Epoch 52/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8644\n",
      "Epoch 52/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8658\n",
      "Epoch 52/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3311 - accuracy: 0.8656\n",
      "Epoch 53/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3303 - accuracy: 0.8644\n",
      "Epoch 53/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3307 - accuracy: 0.8629\n",
      "Epoch 52/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8631\n",
      "Epoch 52/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3222 - accuracy: 0.8657\n",
      "167/720 [=====>........................] - ETA: 0s - loss: 0.3079 - accuracy: 0.8766Epoch 53/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8647\n",
      "Epoch 52/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8651\n",
      "702/720 [============================>.] - ETA: 0s - loss: 0.3285 - accuracy: 0.8647Epoch 53/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3311 - accuracy: 0.8633\n",
      "258/720 [=========>....................] - ETA: 0s - loss: 0.3190 - accuracy: 0.8640Epoch 53/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3311 - accuracy: 0.8631\n",
      "Epoch 54/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8662\n",
      "347/720 [=============>................] - ETA: 0s - loss: 0.3203 - accuracy: 0.8648Epoch 54/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8643\n",
      "211/720 [=======>......................] - ETA: 0s - loss: 0.3397 - accuracy: 0.8607Epoch 53/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3297 - accuracy: 0.8646\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3236 - accuracy: 0.8653\n",
      "Epoch 53/100\n",
      "300/720 [===========>..................] - ETA: 0s - loss: 0.3416 - accuracy: 0.8613Epoch 54/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8646\n",
      "Epoch 53/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3256 - accuracy: 0.8647\n",
      "Epoch 54/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3315 - accuracy: 0.8643\n",
      "Epoch 55/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3307 - accuracy: 0.8636\n",
      "Epoch 54/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8647\n",
      "116/720 [===>..........................] - ETA: 0s - loss: 0.3312 - accuracy: 0.8681Epoch 55/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8626\n",
      "632/720 [=========================>....] - ETA: 0s - loss: 0.3226 - accuracy: 0.8668Epoch 54/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8651\n",
      "Epoch 55/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8649\n",
      "Epoch 54/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8662\n",
      "Epoch 54/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3251 - accuracy: 0.8649\n",
      "298/720 [===========>..................] - ETA: 0s - loss: 0.3279 - accuracy: 0.8621Epoch 55/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3313 - accuracy: 0.8632\n",
      "Epoch 56/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3307 - accuracy: 0.8626\n",
      "Epoch 55/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.8636\n",
      "Epoch 56/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8647\n",
      "Epoch 55/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8650\n",
      "Epoch 55/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3224 - accuracy: 0.8665\n",
      "Epoch 56/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3296 - accuracy: 0.8646\n",
      "660/720 [==========================>...] - ETA: 0s - loss: 0.3277 - accuracy: 0.8659Epoch 55/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3306 - accuracy: 0.8646\n",
      "Epoch 57/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3253 - accuracy: 0.8624\n",
      "Epoch 56/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3306 - accuracy: 0.8637\n",
      "Epoch 56/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8651\n",
      "Epoch 57/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8633\n",
      "Epoch 56/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8656\n",
      "Epoch 56/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3224 - accuracy: 0.8661\n",
      "536/720 [=====================>........] - ETA: 0s - loss: 0.3208 - accuracy: 0.8666Epoch 57/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8664\n",
      "Epoch 56/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3251 - accuracy: 0.8646\n",
      "Epoch 57/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8636\n",
      "329/720 [============>.................] - ETA: 0s - loss: 0.3236 - accuracy: 0.8669Epoch 58/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3309 - accuracy: 0.8618\n",
      "109/720 [===>..........................] - ETA: 0s - loss: 0.3286 - accuracy: 0.8725Epoch 57/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3298 - accuracy: 0.8654\n",
      "595/720 [=======================>......] - ETA: 0s - loss: 0.3250 - accuracy: 0.8659Epoch 58/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8637\n",
      "Epoch 57/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3221 - accuracy: 0.8669\n",
      "492/720 [===================>..........] - ETA: 0s - loss: 0.3367 - accuracy: 0.8593Epoch 58/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8643\n",
      "Epoch 57/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8650\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3256 - accuracy: 0.8637\n",
      "Epoch 57/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.1022 - accuracy: 1.0000Epoch 58/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8631\n",
      "Epoch 59/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3306 - accuracy: 0.8618\n",
      "Epoch 58/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3302 - accuracy: 0.8639\n",
      "Epoch 59/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8636\n",
      "Epoch 58/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.8654\n",
      "Epoch 59/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8660\n",
      "Epoch 58/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3253 - accuracy: 0.8633\n",
      "143/720 [====>.........................] - ETA: 0s - loss: 0.2979 - accuracy: 0.8748Epoch 59/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3302 - accuracy: 0.8656\n",
      "Epoch 58/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3305 - accuracy: 0.8612\n",
      "Epoch 60/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8633\n",
      "Epoch 59/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8656\n",
      "Epoch 60/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8650\n",
      "139/720 [====>.........................] - ETA: 1s - loss: 0.3558 - accuracy: 0.8482Epoch 59/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3225 - accuracy: 0.8662\n",
      "Epoch 60/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3289 - accuracy: 0.8656\n",
      "Epoch 59/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3302 - accuracy: 0.8642\n",
      "146/720 [=====>........................] - ETA: 0s - loss: 0.3112 - accuracy: 0.8664Epoch 61/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8651\n",
      "Epoch 59/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8628\n",
      "380/720 [==============>...............] - ETA: 0s - loss: 0.3303 - accuracy: 0.8642Epoch 60/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8618\n",
      "Epoch 60/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8660\n",
      "Epoch 61/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8643\n",
      "363/720 [==============>...............] - ETA: 0s - loss: 0.3308 - accuracy: 0.8612Epoch 60/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3223 - accuracy: 0.8661\n",
      "Epoch 61/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3286 - accuracy: 0.8647\n",
      "Epoch 60/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3248 - accuracy: 0.8635\n",
      "Epoch 61/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8653\n",
      "171/720 [======>.......................] - ETA: 0s - loss: 0.3223 - accuracy: 0.8678Epoch 62/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8640\n",
      "Epoch 60/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8619\n",
      "Epoch 61/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3293 - accuracy: 0.8644\n",
      "Epoch 62/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3282 - accuracy: 0.8668\n",
      "Epoch 61/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3223 - accuracy: 0.8671\n",
      "425/720 [================>.............] - ETA: 0s - loss: 0.3319 - accuracy: 0.8628Epoch 62/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8636\n",
      "Epoch 61/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3298 - accuracy: 0.8653\n",
      "Epoch 63/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3252 - accuracy: 0.8654\n",
      "Epoch 62/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3297 - accuracy: 0.8629\n",
      " 45/720 [>.............................] - ETA: 0s - loss: 0.3163 - accuracy: 0.8844Epoch 61/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8640\n",
      "Epoch 62/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8664\n",
      "572/720 [======================>.......] - ETA: 0s - loss: 0.3237 - accuracy: 0.8640Epoch 63/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3291 - accuracy: 0.8644\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8646\n",
      "Epoch 62/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.1286 - accuracy: 0.9000Epoch 62/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3221 - accuracy: 0.8660\n",
      "Epoch 63/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3298 - accuracy: 0.8636\n",
      "199/720 [=======>......................] - ETA: 0s - loss: 0.3375 - accuracy: 0.8603Epoch 64/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3253 - accuracy: 0.8654\n",
      "699/720 [============================>.] - ETA: 0s - loss: 0.3288 - accuracy: 0.8651Epoch 63/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8647\n",
      "Epoch 62/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8650\n",
      "Epoch 63/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8660\n",
      "Epoch 64/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3279 - accuracy: 0.8646\n",
      "Epoch 63/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8649\n",
      "437/720 [=================>............] - ETA: 0s - loss: 0.3211 - accuracy: 0.8691Epoch 63/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.8669\n",
      " 36/720 [>.............................] - ETA: 0s - loss: 0.3526 - accuracy: 0.8583Epoch 64/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3298 - accuracy: 0.8636\n",
      "Epoch 65/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8668\n",
      "Epoch 64/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8650\n",
      "Epoch 63/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8631\n",
      "Epoch 64/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3297 - accuracy: 0.8651\n",
      "Epoch 65/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3292 - accuracy: 0.8649\n",
      "101/720 [===>..........................] - ETA: 0s - loss: 0.3459 - accuracy: 0.8614Epoch 64/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8656\n",
      "Epoch 64/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3223 - accuracy: 0.8657\n",
      "425/720 [================>.............] - ETA: 0s - loss: 0.3239 - accuracy: 0.8631Epoch 65/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8639\n",
      "Epoch 66/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8643\n",
      "Epoch 65/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3298 - accuracy: 0.8625\n",
      "Epoch 65/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8649\n",
      "437/720 [=================>............] - ETA: 0s - loss: 0.3298 - accuracy: 0.8629Epoch 64/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8657\n",
      "196/720 [=======>......................] - ETA: 0s - loss: 0.3206 - accuracy: 0.8607Epoch 66/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8639\n",
      "327/720 [============>.................] - ETA: 0s - loss: 0.3231 - accuracy: 0.8642Epoch 65/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3216 - accuracy: 0.8665\n",
      "Epoch 66/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8664\n",
      " 36/720 [>.............................] - ETA: 0s - loss: 0.3301 - accuracy: 0.8639Epoch 65/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3300 - accuracy: 0.8626\n",
      "Epoch 67/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8637\n",
      "714/720 [============================>.] - ETA: 0s - loss: 0.3290 - accuracy: 0.8634Epoch 66/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8635\n",
      "151/720 [=====>........................] - ETA: 0s - loss: 0.3140 - accuracy: 0.8775Epoch 66/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8639\n",
      " 62/720 [=>............................] - ETA: 1s - loss: 0.3068 - accuracy: 0.8823Epoch 65/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3295 - accuracy: 0.8647\n",
      "166/720 [=====>........................] - ETA: 0s - loss: 0.3230 - accuracy: 0.8687Epoch 67/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3216 - accuracy: 0.8669\n",
      "Epoch 67/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8647\n",
      "Epoch 66/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8660\n",
      "396/720 [===============>..............] - ETA: 0s - loss: 0.3160 - accuracy: 0.8694Epoch 66/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3292 - accuracy: 0.8658\n",
      "Epoch 68/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8631\n",
      "Epoch 67/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3252 - accuracy: 0.8646\n",
      "Epoch 67/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8644\n",
      "Epoch 66/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8660\n",
      "369/720 [==============>...............] - ETA: 0s - loss: 0.3263 - accuracy: 0.8640Epoch 68/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3211 - accuracy: 0.8675\n",
      " 72/720 [==>...........................] - ETA: 0s - loss: 0.2956 - accuracy: 0.8889Epoch 68/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3284 - accuracy: 0.8636\n",
      "296/720 [===========>..................] - ETA: 0s - loss: 0.3489 - accuracy: 0.8551Epoch 67/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3280 - accuracy: 0.8653\n",
      "Epoch 67/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8635\n",
      "Epoch 69/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8612\n",
      "468/720 [==================>...........] - ETA: 0s - loss: 0.3321 - accuracy: 0.8643Epoch 68/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3245 - accuracy: 0.8640\n",
      "Epoch 68/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8647\n",
      "371/720 [==============>...............] - ETA: 0s - loss: 0.3319 - accuracy: 0.8642Epoch 69/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8639\n",
      "Epoch 67/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3217 - accuracy: 0.8654\n",
      "Epoch 69/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8640\n",
      "Epoch 68/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8644\n",
      "Epoch 68/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8631\n",
      "318/720 [============>.................] - ETA: 0s - loss: 0.3187 - accuracy: 0.8714Epoch 70/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8622\n",
      "Epoch 69/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.8635\n",
      "Epoch 69/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3293 - accuracy: 0.8653\n",
      "600/720 [========================>.....] - ETA: 0s - loss: 0.3306 - accuracy: 0.8648Epoch 70/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3212 - accuracy: 0.8671\n",
      "Epoch 70/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8639\n",
      "695/720 [===========================>..] - ETA: 0s - loss: 0.3297 - accuracy: 0.8635Epoch 68/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8637\n",
      " 27/720 [>.............................] - ETA: 1s - loss: 0.3452 - accuracy: 0.8407Epoch 69/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3273 - accuracy: 0.8662\n",
      "431/720 [================>.............] - ETA: 0s - loss: 0.3275 - accuracy: 0.8647Epoch 69/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8640\n",
      "Epoch 71/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8653\n",
      "Epoch 70/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8656\n",
      "514/720 [====================>.........] - ETA: 0s - loss: 0.3290 - accuracy: 0.8630Epoch 70/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8654\n",
      "Epoch 71/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3218 - accuracy: 0.8657\n",
      "Epoch 71/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3285 - accuracy: 0.8651\n",
      "Epoch 69/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8647\n",
      "Epoch 70/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8657\n",
      "Epoch 70/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8636\n",
      "Epoch 72/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3293 - accuracy: 0.8628\n",
      "600/720 [========================>.....] - ETA: 0s - loss: 0.3261 - accuracy: 0.8625Epoch 71/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8633\n",
      "Epoch 71/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3219 - accuracy: 0.8662\n",
      "Epoch 72/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
      "Epoch 71/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8633\n",
      " 75/720 [==>...........................] - ETA: 0s - loss: 0.3182 - accuracy: 0.8773Epoch 70/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8642\n",
      "115/720 [===>..........................] - ETA: 0s - loss: 0.3004 - accuracy: 0.8783Epoch 72/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8675\n",
      "Epoch 71/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8647\n",
      "Epoch 73/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3291 - accuracy: 0.8628\n",
      "401/720 [===============>..............] - ETA: 0s - loss: 0.3254 - accuracy: 0.8671Epoch 72/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8649\n",
      "Epoch 72/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8658\n",
      "Epoch 73/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8649\n",
      "Epoch 72/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8650\n",
      "376/720 [==============>...............] - ETA: 0s - loss: 0.3207 - accuracy: 0.8662Epoch 71/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8667\n",
      "652/720 [==========================>...] - ETA: 0s - loss: 0.3305 - accuracy: 0.8655Epoch 73/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8665\n",
      "Epoch 72/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3290 - accuracy: 0.8643\n",
      "Epoch 74/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8632\n",
      "415/720 [================>.............] - ETA: 0s - loss: 0.3257 - accuracy: 0.8689Epoch 73/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8644\n",
      "652/720 [==========================>...] - ETA: 0s - loss: 0.3152 - accuracy: 0.8698Epoch 73/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3212 - accuracy: 0.8671\n",
      "Epoch 74/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3284 - accuracy: 0.8654\n",
      "Epoch 72/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8656\n",
      "Epoch 73/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8650\n",
      "Epoch 74/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3267 - accuracy: 0.8676\n",
      "181/720 [======>.......................] - ETA: 0s - loss: 0.3292 - accuracy: 0.8608Epoch 73/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8625\n",
      "404/720 [===============>..............] - ETA: 0s - loss: 0.3304 - accuracy: 0.8666Epoch 75/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8643\n",
      "Epoch 74/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3246 - accuracy: 0.8650\n",
      "Epoch 74/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8643\n",
      "Epoch 73/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8671\n",
      "Epoch 75/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8650\n",
      "Epoch 74/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8651\n",
      "647/720 [=========================>....] - ETA: 0s - loss: 0.3314 - accuracy: 0.8640Epoch 75/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8667\n",
      "Epoch 74/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3291 - accuracy: 0.8642\n",
      "Epoch 76/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3242 - accuracy: 0.8647\n",
      "Epoch 75/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8637\n",
      "Epoch 75/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8635\n",
      "Epoch 75/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8658\n",
      "360/720 [==============>...............] - ETA: 0s - loss: 0.3337 - accuracy: 0.8611Epoch 74/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8668\n",
      "166/720 [=====>........................] - ETA: 0s - loss: 0.3095 - accuracy: 0.8639Epoch 76/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3258 - accuracy: 0.8654\n",
      "Epoch 75/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8656\n",
      "247/720 [=========>....................] - ETA: 0s - loss: 0.3136 - accuracy: 0.8709Epoch 76/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8632\n",
      "378/720 [==============>...............] - ETA: 0s - loss: 0.3209 - accuracy: 0.8714Epoch 77/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8629\n",
      "284/720 [==========>...................] - ETA: 0s - loss: 0.3481 - accuracy: 0.8542Epoch 76/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8637\n",
      "Epoch 76/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3283 - accuracy: 0.8653\n",
      "Epoch 75/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3279 - accuracy: 0.8650\n",
      " 54/720 [=>............................] - ETA: 1s - loss: 0.3041 - accuracy: 0.8648Epoch 76/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3212 - accuracy: 0.8692\n",
      "Epoch 77/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3259 - accuracy: 0.8668\n",
      "226/720 [========>.....................] - ETA: 0s - loss: 0.3351 - accuracy: 0.8611Epoch 76/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8653\n",
      "Epoch 77/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3286 - accuracy: 0.8637\n",
      "Epoch 78/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8631\n",
      "678/720 [===========================>..] - ETA: 0s - loss: 0.3277 - accuracy: 0.8640Epoch 77/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8643\n",
      "Epoch 76/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8635\n",
      "571/720 [======================>.......] - ETA: 0s - loss: 0.3267 - accuracy: 0.8680Epoch 77/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8646\n",
      "Epoch 77/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8671\n",
      "Epoch 78/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3256 - accuracy: 0.8681\n",
      "116/720 [===>..........................] - ETA: 1s - loss: 0.3165 - accuracy: 0.8586Epoch 77/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8643\n",
      "Epoch 78/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8636\n",
      "Epoch 79/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8635\n",
      "Epoch 78/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3277 - accuracy: 0.8639\n",
      "Epoch 78/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3216 - accuracy: 0.8674\n",
      "Epoch 79/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8632\n",
      "Epoch 78/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8654\n",
      " 56/720 [=>............................] - ETA: 1s - loss: 0.3503 - accuracy: 0.8482Epoch 77/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3259 - accuracy: 0.8660\n",
      " 82/720 [==>...........................] - ETA: 1s - loss: 0.3347 - accuracy: 0.8598Epoch 78/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8660\n",
      "Epoch 79/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3290 - accuracy: 0.8618\n",
      "315/720 [============>.................] - ETA: 0s - loss: 0.3346 - accuracy: 0.8594Epoch 80/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8626\n",
      "Epoch 79/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8642\n",
      "433/720 [=================>............] - ETA: 0s - loss: 0.3292 - accuracy: 0.8642Epoch 79/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3215 - accuracy: 0.8664\n",
      "Epoch 80/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8650\n",
      "Epoch 79/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8650\n",
      "167/720 [=====>........................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8623Epoch 79/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8651\n",
      "Epoch 78/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8647\n",
      "150/720 [=====>........................] - ETA: 0s - loss: 0.3388 - accuracy: 0.8573Epoch 80/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8644\n",
      "294/720 [===========>..................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8687Epoch 81/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8644\n",
      "Epoch 80/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8644\n",
      "Epoch 80/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8624\n",
      "Epoch 80/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3209 - accuracy: 0.8667\n",
      "463/720 [==================>...........] - ETA: 0s - loss: 0.3166 - accuracy: 0.8635Epoch 81/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8658\n",
      "Epoch 80/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8661\n",
      "Epoch 79/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8660\n",
      "230/720 [========>.....................] - ETA: 0s - loss: 0.3260 - accuracy: 0.8713Epoch 81/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8619\n",
      "Epoch 82/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8637\n",
      "Epoch 81/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8637\n",
      "690/720 [===========================>..] - ETA: 0s - loss: 0.3236 - accuracy: 0.8654Epoch 81/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3214 - accuracy: 0.8692\n",
      "Epoch 82/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8654\n",
      "Epoch 81/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3251 - accuracy: 0.8672\n",
      " 79/720 [==>...........................] - ETA: 0s - loss: 0.3580 - accuracy: 0.8570Epoch 81/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8644\n",
      "193/720 [=======>......................] - ETA: 0s - loss: 0.3276 - accuracy: 0.8694Epoch 80/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8640\n",
      "277/720 [==========>...................] - ETA: 0s - loss: 0.3304 - accuracy: 0.8549Epoch 83/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8635\n",
      "Epoch 82/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8632\n",
      "Epoch 82/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3239 - accuracy: 0.8644\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8678\n",
      "Epoch 82/100\n",
      "447/720 [=================>............] - ETA: 0s - loss: 0.3291 - accuracy: 0.8613Epoch 83/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3254 - accuracy: 0.8672\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8651\n",
      "Epoch 82/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.4158 - accuracy: 0.9000Epoch 82/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8639\n",
      "130/720 [====>.........................] - ETA: 0s - loss: 0.3166 - accuracy: 0.8708Epoch 81/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3286 - accuracy: 0.8657\n",
      "Epoch 83/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8639\n",
      "287/720 [==========>...................] - ETA: 0s - loss: 0.3090 - accuracy: 0.8746Epoch 84/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8678\n",
      "Epoch 84/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3279 - accuracy: 0.8647\n",
      "Epoch 83/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3253 - accuracy: 0.8671\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8661\n",
      "Epoch 83/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.3989 - accuracy: 0.8000Epoch 83/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8650\n",
      "Epoch 83/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8651\n",
      "230/720 [========>.....................] - ETA: 0s - loss: 0.3432 - accuracy: 0.8630Epoch 82/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8657\n",
      "Epoch 84/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8636\n",
      "Epoch 85/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3215 - accuracy: 0.8675\n",
      "Epoch 85/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3280 - accuracy: 0.8651\n",
      "477/720 [==================>...........] - ETA: 0s - loss: 0.3353 - accuracy: 0.8618Epoch 84/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8640\n",
      "693/720 [===========================>..] - ETA: 0s - loss: 0.3265 - accuracy: 0.8651Epoch 84/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3249 - accuracy: 0.8658\n",
      "Epoch 84/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8651\n",
      "399/720 [===============>..............] - ETA: 0s - loss: 0.3236 - accuracy: 0.8657Epoch 84/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8654\n",
      "679/720 [===========================>..] - ETA: 0s - loss: 0.3254 - accuracy: 0.8672Epoch 85/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8660\n",
      "Epoch 83/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8647\n",
      "330/720 [============>.................] - ETA: 0s - loss: 0.3254 - accuracy: 0.8691Epoch 86/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8646\n",
      "Epoch 85/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3290 - accuracy: 0.8621\n",
      "Epoch 85/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.8664\n",
      "Epoch 86/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3250 - accuracy: 0.8662\n",
      "Epoch 85/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8651\n",
      " 98/720 [===>..........................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8612Epoch 85/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8642\n",
      "Epoch 84/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8654\n",
      "Epoch 86/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8647\n",
      "438/720 [=================>............] - ETA: 0s - loss: 0.3303 - accuracy: 0.8623Epoch 87/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8639\n",
      "628/720 [=========================>....] - ETA: 0s - loss: 0.3289 - accuracy: 0.8623Epoch 86/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8642\n",
      "Epoch 86/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.8671\n",
      "485/720 [===================>..........] - ETA: 0s - loss: 0.3303 - accuracy: 0.8641Epoch 86/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3211 - accuracy: 0.8675\n",
      "505/720 [====================>.........] - ETA: 0s - loss: 0.3331 - accuracy: 0.8620Epoch 87/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8643\n",
      " 66/720 [=>............................] - ETA: 1s - loss: 0.3135 - accuracy: 0.8758Epoch 86/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8643\n",
      "546/720 [=====================>........] - ETA: 0s - loss: 0.3318 - accuracy: 0.8626Epoch 85/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8646\n",
      "Epoch 87/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8642\n",
      "Epoch 88/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8642\n",
      "626/720 [=========================>....] - ETA: 0s - loss: 0.3183 - accuracy: 0.8677Epoch 87/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8665\n",
      "Epoch 87/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3204 - accuracy: 0.8686\n",
      "273/720 [==========>...................] - ETA: 0s - loss: 0.3315 - accuracy: 0.8637Epoch 88/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8650\n",
      "Epoch 87/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8658\n",
      " 90/720 [==>...........................] - ETA: 1s - loss: 0.3221 - accuracy: 0.8500Epoch 87/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8667\n",
      "Epoch 88/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8650\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8651\n",
      "Epoch 86/100\n",
      "448/720 [=================>............] - ETA: 0s - loss: 0.3270 - accuracy: 0.8654Epoch 89/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8643\n",
      "Epoch 88/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8642\n",
      "Epoch 88/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8686\n",
      "Epoch 89/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8664\n",
      " 67/720 [=>............................] - ETA: 0s - loss: 0.3524 - accuracy: 0.8448Epoch 88/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8668\n",
      "Epoch 88/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3280 - accuracy: 0.8650\n",
      "Epoch 89/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3281 - accuracy: 0.8644\n",
      "323/720 [============>.................] - ETA: 0s - loss: 0.3270 - accuracy: 0.8659Epoch 90/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8665\n",
      "Epoch 87/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8654\n",
      "Epoch 89/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8643\n",
      "336/720 [=============>................] - ETA: 0s - loss: 0.3251 - accuracy: 0.8631Epoch 89/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8682\n",
      "710/720 [============================>.] - ETA: 0s - loss: 0.3243 - accuracy: 0.8649Epoch 90/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8656\n",
      "426/720 [================>.............] - ETA: 0s - loss: 0.3319 - accuracy: 0.8662Epoch 89/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8660\n",
      "510/720 [====================>.........] - ETA: 0s - loss: 0.3320 - accuracy: 0.8627Epoch 89/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8651\n",
      "Epoch 90/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3285 - accuracy: 0.8644\n",
      "Epoch 91/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3274 - accuracy: 0.8650\n",
      "450/720 [=================>............] - ETA: 0s - loss: 0.3200 - accuracy: 0.8673Epoch 88/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8658\n",
      "Epoch 90/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8637\n",
      "325/720 [============>.................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8686Epoch 90/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.8658\n",
      "Epoch 91/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8644\n",
      "Epoch 90/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8669\n",
      "Epoch 90/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3283 - accuracy: 0.8628\n",
      "Epoch 92/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8654\n",
      "399/720 [===============>..............] - ETA: 0s - loss: 0.3232 - accuracy: 0.8642Epoch 91/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8632\n",
      "Epoch 89/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3278 - accuracy: 0.8642\n",
      "371/720 [==============>...............] - ETA: 0s - loss: 0.3184 - accuracy: 0.8687Epoch 91/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3278 - accuracy: 0.8640\n",
      "611/720 [========================>.....] - ETA: 0s - loss: 0.3253 - accuracy: 0.8638Epoch 91/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8636\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8672\n",
      "236/720 [========>.....................] - ETA: 0s - loss: 0.3325 - accuracy: 0.8648Epoch 91/100\n",
      "  1/720 [..............................] - ETA: 0s - loss: 0.1131 - accuracy: 1.0000Epoch 92/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8664\n",
      "Epoch 91/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3277 - accuracy: 0.8668\n",
      "Epoch 92/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8635\n",
      "Epoch 93/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3274 - accuracy: 0.8633\n",
      "694/720 [===========================>..] - ETA: 0s - loss: 0.3270 - accuracy: 0.8637Epoch 92/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8639\n",
      "695/720 [===========================>..] - ETA: 0s - loss: 0.3290 - accuracy: 0.8616Epoch 90/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8618\n",
      "Epoch 92/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3205 - accuracy: 0.8656\n",
      "432/720 [=================>............] - ETA: 0s - loss: 0.3209 - accuracy: 0.8701Epoch 93/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8656\n",
      "Epoch 92/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8672\n",
      "Epoch 92/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8662\n",
      "Epoch 93/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8643\n",
      "Epoch 94/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8639\n",
      "Epoch 93/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8660\n",
      "Epoch 91/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8632\n",
      "Epoch 93/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3211 - accuracy: 0.8675\n",
      "Epoch 94/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3229 - accuracy: 0.8654\n",
      "Epoch 93/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8679\n",
      "608/720 [========================>.....] - ETA: 0s - loss: 0.3309 - accuracy: 0.8650Epoch 93/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8642\n",
      "Epoch 95/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8660\n",
      "Epoch 94/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8649\n",
      "Epoch 92/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8639\n",
      "Epoch 94/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8618\n",
      "572/720 [======================>.......] - ETA: 0s - loss: 0.3191 - accuracy: 0.8685Epoch 94/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8639\n",
      "Epoch 94/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8651\n",
      "Epoch 94/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8640\n",
      "Epoch 96/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8646\n",
      "Epoch 95/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8660\n",
      "Epoch 95/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8625\n",
      "Epoch 95/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8649\n",
      "422/720 [================>.............] - ETA: 0s - loss: 0.3149 - accuracy: 0.8713Epoch 93/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8667\n",
      "Epoch 96/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3280 - accuracy: 0.8637\n",
      "719/720 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8637Epoch 97/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8636\n",
      "Epoch 95/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8683\n",
      "Epoch 95/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8671\n",
      "Epoch 96/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3274 - accuracy: 0.8650\n",
      "Epoch 96/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8622\n",
      "Epoch 96/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3269 - accuracy: 0.8649\n",
      "687/720 [===========================>..] - ETA: 0s - loss: 0.3189 - accuracy: 0.8690Epoch 94/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8678\n",
      "Epoch 97/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8643\n",
      "161/720 [=====>........................] - ETA: 0s - loss: 0.3285 - accuracy: 0.8646Epoch 96/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8647\n",
      "583/720 [=======================>......] - ETA: 0s - loss: 0.3291 - accuracy: 0.8669Epoch 98/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8686\n",
      "Epoch 96/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8668\n",
      "119/720 [===>..........................] - ETA: 1s - loss: 0.3454 - accuracy: 0.8546Epoch 97/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8637\n",
      "Epoch 97/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8639\n",
      "Epoch 97/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3211 - accuracy: 0.8678\n",
      "245/720 [=========>....................] - ETA: 0s - loss: 0.3147 - accuracy: 0.8722Epoch 98/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8640\n",
      "Epoch 95/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8674\n",
      "Epoch 97/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8640\n",
      "Epoch 97/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8639\n",
      "Epoch 99/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8654\n",
      "Epoch 98/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8653\n",
      "215/720 [=======>......................] - ETA: 0s - loss: 0.3085 - accuracy: 0.8730Epoch 98/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8629\n",
      "Epoch 98/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3208 - accuracy: 0.8675\n",
      "Epoch 99/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3267 - accuracy: 0.8650\n",
      " 56/720 [=>............................] - ETA: 1s - loss: 0.3062 - accuracy: 0.8911Epoch 96/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8647\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8639\n",
      "Epoch 98/100\n",
      "303/720 [===========>..................] - ETA: 0s - loss: 0.3143 - accuracy: 0.8733Epoch 100/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8694\n",
      "397/720 [===============>..............] - ETA: 0s - loss: 0.3337 - accuracy: 0.8587Epoch 98/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8676\n",
      "Epoch 99/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8639\n",
      "Epoch 99/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8631\n",
      "Epoch 99/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3203 - accuracy: 0.8686\n",
      "138/720 [====>.........................] - ETA: 0s - loss: 0.3293 - accuracy: 0.8659Epoch 100/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8649\n",
      "Epoch 97/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3231 - accuracy: 0.8654\n",
      "206/720 [=======>......................] - ETA: 0s - loss: 0.2982 - accuracy: 0.8748Epoch 99/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3279 - accuracy: 0.8650\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8668\n",
      "Epoch 99/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8651\n",
      "Epoch 100/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3274 - accuracy: 0.8644\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.8675\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8626\n",
      "Epoch 100/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8686\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3267 - accuracy: 0.8639\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3815 - accuracy: 0.8413\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8643\n",
      "Epoch 100/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3239 - accuracy: 0.8667\n",
      "Epoch 100/100\n",
      "104/720 [===>..........................] - ETA: 0s - loss: 0.3087 - accuracy: 0.8615Epoch 1/100\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8661\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8637\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3275 - accuracy: 0.8649\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8650\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8537\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8600\n",
      "80/80 [==============================] - 0s 858us/step - loss: 0.3216 - accuracy: 0.8675\n",
      "370/720 [==============>...............] - ETA: 0s - loss: 0.5557 - accuracy: 0.7589Epoch 1/100\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3232 - accuracy: 0.8676\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3228 - accuracy: 0.8639\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.5090 - accuracy: 0.7817\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 805us/step - loss: 0.3602 - accuracy: 0.8612\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8487\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 0.3264 - accuracy: 0.8661\n",
      "Epoch 100/100\n",
      "720/720 [==============================] - 1s 925us/step - loss: 0.5232 - accuracy: 0.7807\n",
      "Epoch 2/100\n",
      "720/720 [==============================] - 1s 707us/step - loss: 0.4153 - accuracy: 0.8267\n",
      "Epoch 3/100\n",
      "720/720 [==============================] - 0s 648us/step - loss: 0.3264 - accuracy: 0.8651\n",
      "720/720 [==============================] - 0s 637us/step - loss: 0.4197 - accuracy: 0.8082\n",
      "406/720 [===============>..............] - ETA: 0s - loss: 0.3962 - accuracy: 0.8320Epoch 3/100\n",
      "80/80 [==============================] - 0s 558us/step - loss: 0.3394 - accuracy: 0.8575\n",
      "720/720 [==============================] - 0s 602us/step - loss: 0.3905 - accuracy: 0.8367\n",
      "Epoch 4/100\n",
      "720/720 [==============================] - 0s 552us/step - loss: 0.3838 - accuracy: 0.8340\n",
      "Epoch 4/100\n",
      "720/720 [==============================] - 0s 498us/step - loss: 0.3746 - accuracy: 0.8431\n",
      "Epoch 5/100\n",
      "720/720 [==============================] - 0s 517us/step - loss: 0.3634 - accuracy: 0.8485\n",
      "Epoch 5/100\n",
      "720/720 [==============================] - 0s 503us/step - loss: 0.3624 - accuracy: 0.8494\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 0s 520us/step - loss: 0.3556 - accuracy: 0.8529\n",
      "Epoch 6/100\n",
      "720/720 [==============================] - 0s 505us/step - loss: 0.3542 - accuracy: 0.8547\n",
      "Epoch 7/100\n",
      "720/720 [==============================] - 0s 521us/step - loss: 0.3503 - accuracy: 0.8558\n",
      "494/720 [===================>..........] - ETA: 0s - loss: 0.3442 - accuracy: 0.8587Epoch 7/100\n",
      "720/720 [==============================] - 0s 514us/step - loss: 0.3493 - accuracy: 0.8578\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 0s 537us/step - loss: 0.3482 - accuracy: 0.8585\n",
      "Epoch 8/100\n",
      "720/720 [==============================] - 0s 508us/step - loss: 0.3465 - accuracy: 0.8586\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 0s 525us/step - loss: 0.3458 - accuracy: 0.8587\n",
      "Epoch 9/100\n",
      "720/720 [==============================] - 0s 519us/step - loss: 0.3445 - accuracy: 0.8586\n",
      "Epoch 10/100\n",
      "720/720 [==============================] - 0s 519us/step - loss: 0.3446 - accuracy: 0.8619\n",
      "Epoch 10/100\n",
      "720/720 [==============================] - 0s 510us/step - loss: 0.3431 - accuracy: 0.8587\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 0s 541us/step - loss: 0.3434 - accuracy: 0.8608\n",
      "Epoch 11/100\n",
      "720/720 [==============================] - 0s 523us/step - loss: 0.3422 - accuracy: 0.8582\n",
      "Epoch 12/100\n",
      "720/720 [==============================] - 0s 553us/step - loss: 0.3425 - accuracy: 0.8610\n",
      "Epoch 12/100\n",
      "720/720 [==============================] - 0s 531us/step - loss: 0.3419 - accuracy: 0.8583\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 0s 533us/step - loss: 0.3418 - accuracy: 0.8594\n",
      "Epoch 13/100\n",
      "720/720 [==============================] - 0s 508us/step - loss: 0.3413 - accuracy: 0.8611\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 0s 521us/step - loss: 0.3408 - accuracy: 0.8611\n",
      "Epoch 14/100\n",
      "720/720 [==============================] - 0s 509us/step - loss: 0.3399 - accuracy: 0.8601\n",
      "Epoch 15/100\n",
      "720/720 [==============================] - 0s 520us/step - loss: 0.3400 - accuracy: 0.8615\n",
      "Epoch 15/100\n",
      "720/720 [==============================] - 0s 510us/step - loss: 0.3400 - accuracy: 0.8597\n",
      "Epoch 16/100\n",
      "720/720 [==============================] - 0s 518us/step - loss: 0.3390 - accuracy: 0.8618\n",
      "Epoch 16/100\n",
      "720/720 [==============================] - 0s 492us/step - loss: 0.3390 - accuracy: 0.8618\n",
      "Epoch 17/100\n",
      "720/720 [==============================] - 0s 521us/step - loss: 0.3382 - accuracy: 0.8614\n",
      "Epoch 18/100\n",
      "720/720 [==============================] - 0s 539us/step - loss: 0.3388 - accuracy: 0.8619\n",
      "Epoch 17/100\n",
      "720/720 [==============================] - 0s 525us/step - loss: 0.3380 - accuracy: 0.8618\n",
      "Epoch 19/100\n",
      "720/720 [==============================] - 0s 537us/step - loss: 0.3383 - accuracy: 0.8633\n",
      "Epoch 18/100\n",
      "720/720 [==============================] - 0s 528us/step - loss: 0.3378 - accuracy: 0.8621\n",
      "Epoch 20/100\n",
      "720/720 [==============================] - 0s 537us/step - loss: 0.3379 - accuracy: 0.8612\n",
      "Epoch 19/100\n",
      "720/720 [==============================] - 0s 511us/step - loss: 0.3380 - accuracy: 0.8617\n",
      "Epoch 21/100\n",
      "720/720 [==============================] - 0s 534us/step - loss: 0.3375 - accuracy: 0.8626\n",
      "Epoch 20/100\n",
      "720/720 [==============================] - 0s 512us/step - loss: 0.3370 - accuracy: 0.8604\n",
      "Epoch 22/100\n",
      "720/720 [==============================] - 0s 522us/step - loss: 0.3371 - accuracy: 0.8633\n",
      "Epoch 21/100\n",
      "720/720 [==============================] - 0s 521us/step - loss: 0.3368 - accuracy: 0.8619\n",
      "Epoch 23/100\n",
      "720/720 [==============================] - 0s 538us/step - loss: 0.3368 - accuracy: 0.8640\n",
      "Epoch 22/100\n",
      "720/720 [==============================] - 0s 501us/step - loss: 0.3370 - accuracy: 0.8610\n",
      "Epoch 24/100\n",
      "720/720 [==============================] - 0s 523us/step - loss: 0.3366 - accuracy: 0.8626\n",
      "Epoch 23/100\n",
      "720/720 [==============================] - 0s 546us/step - loss: 0.3362 - accuracy: 0.8642\n",
      "Epoch 25/100\n",
      "720/720 [==============================] - 0s 568us/step - loss: 0.3364 - accuracy: 0.8647\n",
      "Epoch 24/100\n",
      "720/720 [==============================] - 0s 540us/step - loss: 0.3355 - accuracy: 0.8614\n",
      "Epoch 26/100\n",
      "720/720 [==============================] - 0s 556us/step - loss: 0.3360 - accuracy: 0.8629\n",
      "Epoch 25/100\n",
      "720/720 [==============================] - 0s 504us/step - loss: 0.3352 - accuracy: 0.8603\n",
      "Epoch 27/100\n",
      "720/720 [==============================] - 0s 520us/step - loss: 0.3353 - accuracy: 0.8632\n",
      "Epoch 26/100\n",
      "720/720 [==============================] - 0s 505us/step - loss: 0.3351 - accuracy: 0.8637\n",
      "Epoch 28/100\n",
      "720/720 [==============================] - 0s 504us/step - loss: 0.3356 - accuracy: 0.8631\n",
      "Epoch 27/100\n",
      "720/720 [==============================] - 0s 493us/step - loss: 0.3347 - accuracy: 0.8615\n",
      "Epoch 29/100\n",
      "720/720 [==============================] - 0s 517us/step - loss: 0.3347 - accuracy: 0.8631\n",
      "Epoch 28/100\n",
      "720/720 [==============================] - 0s 518us/step - loss: 0.3343 - accuracy: 0.8632\n",
      "Epoch 30/100\n",
      "720/720 [==============================] - 0s 543us/step - loss: 0.3346 - accuracy: 0.8646\n",
      "Epoch 29/100\n",
      "720/720 [==============================] - 0s 524us/step - loss: 0.3344 - accuracy: 0.8619\n",
      "Epoch 31/100\n",
      "720/720 [==============================] - 0s 544us/step - loss: 0.3344 - accuracy: 0.8640\n",
      "Epoch 30/100\n",
      "720/720 [==============================] - 0s 531us/step - loss: 0.3335 - accuracy: 0.8633\n",
      "Epoch 32/100\n",
      "720/720 [==============================] - 0s 548us/step - loss: 0.3335 - accuracy: 0.8639\n",
      "Epoch 31/100\n",
      "720/720 [==============================] - 0s 524us/step - loss: 0.3342 - accuracy: 0.8633\n",
      "Epoch 33/100\n",
      "720/720 [==============================] - 0s 552us/step - loss: 0.3339 - accuracy: 0.8643\n",
      "Epoch 32/100\n",
      "720/720 [==============================] - 0s 521us/step - loss: 0.3333 - accuracy: 0.8625\n",
      "Epoch 34/100\n",
      "720/720 [==============================] - 0s 533us/step - loss: 0.3337 - accuracy: 0.8640\n",
      "Epoch 33/100\n",
      "720/720 [==============================] - 0s 526us/step - loss: 0.3336 - accuracy: 0.8643\n",
      "Epoch 35/100\n",
      "720/720 [==============================] - 0s 532us/step - loss: 0.3336 - accuracy: 0.8656\n",
      "Epoch 34/100\n",
      "720/720 [==============================] - 0s 500us/step - loss: 0.3331 - accuracy: 0.8636\n",
      "Epoch 36/100\n",
      "720/720 [==============================] - 0s 518us/step - loss: 0.3331 - accuracy: 0.8646\n",
      "Epoch 35/100\n",
      "720/720 [==============================] - 0s 505us/step - loss: 0.3322 - accuracy: 0.8612\n",
      "Epoch 37/100\n",
      "720/720 [==============================] - 0s 524us/step - loss: 0.3333 - accuracy: 0.8636\n",
      "Epoch 36/100\n",
      "720/720 [==============================] - 0s 504us/step - loss: 0.3328 - accuracy: 0.8629\n",
      "Epoch 38/100\n",
      "720/720 [==============================] - 0s 524us/step - loss: 0.3331 - accuracy: 0.8658\n",
      "Epoch 37/100\n",
      "720/720 [==============================] - 0s 513us/step - loss: 0.3323 - accuracy: 0.8633\n",
      "Epoch 39/100\n",
      "720/720 [==============================] - 0s 517us/step - loss: 0.3327 - accuracy: 0.8644\n",
      "Epoch 38/100\n",
      "720/720 [==============================] - 0s 507us/step - loss: 0.3322 - accuracy: 0.8633\n",
      "Epoch 40/100\n",
      "720/720 [==============================] - 0s 529us/step - loss: 0.3328 - accuracy: 0.8650\n",
      "Epoch 39/100\n",
      "720/720 [==============================] - 0s 516us/step - loss: 0.3322 - accuracy: 0.8619\n",
      "Epoch 41/100\n",
      "720/720 [==============================] - 0s 529us/step - loss: 0.3321 - accuracy: 0.8649\n",
      "Epoch 40/100\n",
      "720/720 [==============================] - 0s 502us/step - loss: 0.3323 - accuracy: 0.8635\n",
      "Epoch 42/100\n",
      "720/720 [==============================] - 0s 521us/step - loss: 0.3320 - accuracy: 0.8674\n",
      "Epoch 41/100\n",
      "720/720 [==============================] - 0s 510us/step - loss: 0.3321 - accuracy: 0.8622\n",
      "Epoch 43/100\n",
      "720/720 [==============================] - 0s 516us/step - loss: 0.3318 - accuracy: 0.8656\n",
      "Epoch 42/100\n",
      "720/720 [==============================] - 0s 514us/step - loss: 0.3319 - accuracy: 0.8607\n",
      "Epoch 44/100\n",
      "720/720 [==============================] - 0s 506us/step - loss: 0.3319 - accuracy: 0.8646\n",
      "Epoch 43/100\n",
      "720/720 [==============================] - 0s 508us/step - loss: 0.3314 - accuracy: 0.8628\n",
      "Epoch 45/100\n",
      "720/720 [==============================] - 0s 597us/step - loss: 0.3314 - accuracy: 0.8637\n",
      "Epoch 44/100\n",
      "720/720 [==============================] - 0s 575us/step - loss: 0.3313 - accuracy: 0.8631\n",
      "Epoch 46/100\n",
      "720/720 [==============================] - 0s 537us/step - loss: 0.3313 - accuracy: 0.8662\n",
      "Epoch 45/100\n",
      "720/720 [==============================] - 0s 519us/step - loss: 0.3312 - accuracy: 0.8612\n",
      " 97/720 [===>..........................] - ETA: 0s - loss: 0.3309 - accuracy: 0.8639Epoch 47/100\n",
      "720/720 [==============================] - 0s 527us/step - loss: 0.3316 - accuracy: 0.8651\n",
      "Epoch 46/100\n",
      "720/720 [==============================] - 0s 515us/step - loss: 0.3308 - accuracy: 0.8643\n",
      "Epoch 48/100\n",
      "720/720 [==============================] - 0s 527us/step - loss: 0.3316 - accuracy: 0.8639\n",
      "Epoch 47/100\n",
      "720/720 [==============================] - 0s 510us/step - loss: 0.3306 - accuracy: 0.8618\n",
      "Epoch 49/100\n",
      "720/720 [==============================] - 0s 518us/step - loss: 0.3310 - accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "720/720 [==============================] - 0s 512us/step - loss: 0.3303 - accuracy: 0.8636\n",
      "Epoch 50/100\n",
      "720/720 [==============================] - 0s 514us/step - loss: 0.3309 - accuracy: 0.8669\n",
      "Epoch 49/100\n",
      "720/720 [==============================] - 0s 505us/step - loss: 0.3299 - accuracy: 0.8636\n",
      "Epoch 51/100\n",
      "720/720 [==============================] - 0s 531us/step - loss: 0.3305 - accuracy: 0.8662\n",
      "Epoch 50/100\n",
      "720/720 [==============================] - 0s 514us/step - loss: 0.3299 - accuracy: 0.8626\n",
      "Epoch 52/100\n",
      "720/720 [==============================] - 0s 528us/step - loss: 0.3302 - accuracy: 0.8621\n",
      "Epoch 53/100\n",
      "720/720 [==============================] - 0s 544us/step - loss: 0.3305 - accuracy: 0.8669\n",
      "Epoch 51/100\n",
      "720/720 [==============================] - 0s 524us/step - loss: 0.3301 - accuracy: 0.8650\n",
      "Epoch 54/100\n",
      "720/720 [==============================] - 0s 545us/step - loss: 0.3307 - accuracy: 0.8662\n",
      "Epoch 52/100\n",
      "720/720 [==============================] - 0s 507us/step - loss: 0.3295 - accuracy: 0.8608\n",
      "Epoch 55/100\n",
      "720/720 [==============================] - 0s 518us/step - loss: 0.3299 - accuracy: 0.8649\n",
      "Epoch 53/100\n",
      "720/720 [==============================] - 0s 534us/step - loss: 0.3298 - accuracy: 0.8642\n",
      "Epoch 56/100\n",
      "720/720 [==============================] - 0s 542us/step - loss: 0.3300 - accuracy: 0.8650\n",
      "Epoch 54/100\n",
      "720/720 [==============================] - 0s 524us/step - loss: 0.3295 - accuracy: 0.8628\n",
      "Epoch 57/100\n",
      "720/720 [==============================] - 0s 546us/step - loss: 0.3302 - accuracy: 0.8650\n",
      " 99/720 [===>..........................] - ETA: 0s - loss: 0.3069 - accuracy: 0.8667Epoch 55/100\n",
      "720/720 [==============================] - 0s 499us/step - loss: 0.3290 - accuracy: 0.8639\n",
      "Epoch 58/100\n",
      "720/720 [==============================] - 0s 520us/step - loss: 0.3297 - accuracy: 0.8649\n",
      "Epoch 56/100\n",
      "720/720 [==============================] - 0s 502us/step - loss: 0.3291 - accuracy: 0.8649\n",
      "Epoch 59/100\n",
      "720/720 [==============================] - 0s 513us/step - loss: 0.3299 - accuracy: 0.8665\n",
      "Epoch 57/100\n",
      "720/720 [==============================] - 0s 539us/step - loss: 0.3291 - accuracy: 0.8640\n",
      "Epoch 60/100\n",
      "720/720 [==============================] - 0s 558us/step - loss: 0.3297 - accuracy: 0.8656\n",
      "Epoch 58/100\n",
      "720/720 [==============================] - 0s 542us/step - loss: 0.3286 - accuracy: 0.8628\n",
      "Epoch 61/100\n",
      "720/720 [==============================] - 0s 563us/step - loss: 0.3297 - accuracy: 0.8681\n",
      "Epoch 59/100\n",
      "720/720 [==============================] - 0s 527us/step - loss: 0.3289 - accuracy: 0.8656\n",
      "Epoch 62/100\n",
      "720/720 [==============================] - 0s 539us/step - loss: 0.3293 - accuracy: 0.8643\n",
      "Epoch 60/100\n",
      "720/720 [==============================] - 0s 504us/step - loss: 0.3287 - accuracy: 0.8636\n",
      "Epoch 63/100\n",
      "720/720 [==============================] - 0s 525us/step - loss: 0.3299 - accuracy: 0.8658\n",
      "Epoch 61/100\n",
      "720/720 [==============================] - 0s 515us/step - loss: 0.3285 - accuracy: 0.8639\n",
      "Epoch 64/100\n",
      "720/720 [==============================] - 0s 516us/step - loss: 0.3292 - accuracy: 0.8635\n",
      "Epoch 62/100\n",
      "720/720 [==============================] - 0s 529us/step - loss: 0.3280 - accuracy: 0.8626\n",
      "Epoch 65/100\n",
      "720/720 [==============================] - 0s 538us/step - loss: 0.3292 - accuracy: 0.8650\n",
      "Epoch 63/100\n",
      "720/720 [==============================] - 0s 497us/step - loss: 0.3281 - accuracy: 0.8633\n",
      "Epoch 66/100\n",
      "720/720 [==============================] - 0s 535us/step - loss: 0.3290 - accuracy: 0.8647\n",
      "Epoch 64/100\n",
      "720/720 [==============================] - 0s 533us/step - loss: 0.3279 - accuracy: 0.8654\n",
      "Epoch 67/100\n",
      "720/720 [==============================] - 0s 541us/step - loss: 0.3291 - accuracy: 0.8646\n",
      "Epoch 65/100\n",
      "720/720 [==============================] - 0s 512us/step - loss: 0.3282 - accuracy: 0.8632\n",
      "Epoch 68/100\n",
      "720/720 [==============================] - 0s 527us/step - loss: 0.3290 - accuracy: 0.8656\n",
      "Epoch 66/100\n",
      "720/720 [==============================] - 0s 532us/step - loss: 0.3277 - accuracy: 0.8649\n",
      "Epoch 69/100\n",
      "720/720 [==============================] - 0s 521us/step - loss: 0.3285 - accuracy: 0.8649\n",
      "Epoch 67/100\n",
      "720/720 [==============================] - 0s 505us/step - loss: 0.3275 - accuracy: 0.8650\n",
      "Epoch 70/100\n",
      "720/720 [==============================] - 0s 512us/step - loss: 0.3285 - accuracy: 0.8676\n",
      "Epoch 68/100\n",
      "720/720 [==============================] - 0s 508us/step - loss: 0.3279 - accuracy: 0.8642\n",
      "Epoch 71/100\n",
      "720/720 [==============================] - 0s 536us/step - loss: 0.3280 - accuracy: 0.8653\n",
      "Epoch 69/100\n",
      "720/720 [==============================] - 0s 522us/step - loss: 0.3272 - accuracy: 0.8647\n",
      "Epoch 72/100\n",
      "720/720 [==============================] - 0s 520us/step - loss: 0.3283 - accuracy: 0.8656\n",
      "Epoch 70/100\n",
      "720/720 [==============================] - 0s 511us/step - loss: 0.3281 - accuracy: 0.8628\n",
      "Epoch 73/100\n",
      "720/720 [==============================] - 0s 538us/step - loss: 0.3285 - accuracy: 0.8649\n",
      "Epoch 71/100\n",
      "720/720 [==============================] - 0s 531us/step - loss: 0.3274 - accuracy: 0.8633\n",
      "Epoch 74/100\n",
      "720/720 [==============================] - 0s 525us/step - loss: 0.3285 - accuracy: 0.8640\n",
      "Epoch 72/100\n",
      "720/720 [==============================] - 0s 492us/step - loss: 0.3268 - accuracy: 0.8650\n",
      "Epoch 75/100\n",
      "720/720 [==============================] - 0s 507us/step - loss: 0.3282 - accuracy: 0.8665\n",
      "Epoch 73/100\n",
      "720/720 [==============================] - 0s 485us/step - loss: 0.3273 - accuracy: 0.8633\n",
      "Epoch 76/100\n",
      "720/720 [==============================] - 0s 515us/step - loss: 0.3281 - accuracy: 0.8658\n",
      "Epoch 74/100\n",
      "720/720 [==============================] - 0s 497us/step - loss: 0.3273 - accuracy: 0.8647\n",
      "Epoch 77/100\n",
      "720/720 [==============================] - 0s 505us/step - loss: 0.3280 - accuracy: 0.8650\n",
      "Epoch 75/100\n",
      "720/720 [==============================] - 0s 505us/step - loss: 0.3269 - accuracy: 0.8660\n",
      "Epoch 78/100\n",
      "720/720 [==============================] - 0s 532us/step - loss: 0.3277 - accuracy: 0.8647\n",
      "Epoch 76/100\n",
      "720/720 [==============================] - 0s 510us/step - loss: 0.3273 - accuracy: 0.8639\n",
      "Epoch 79/100\n",
      "720/720 [==============================] - 0s 525us/step - loss: 0.3276 - accuracy: 0.8658\n",
      "Epoch 77/100\n",
      "720/720 [==============================] - 0s 505us/step - loss: 0.3270 - accuracy: 0.8643\n",
      "Epoch 80/100\n",
      "720/720 [==============================] - 0s 515us/step - loss: 0.3276 - accuracy: 0.8665\n",
      "Epoch 78/100\n",
      "720/720 [==============================] - 0s 498us/step - loss: 0.3268 - accuracy: 0.8644\n",
      "Epoch 81/100\n",
      "720/720 [==============================] - 0s 515us/step - loss: 0.3279 - accuracy: 0.8656\n",
      "Epoch 79/100\n",
      "720/720 [==============================] - 0s 506us/step - loss: 0.3275 - accuracy: 0.8628\n",
      "Epoch 82/100\n",
      "720/720 [==============================] - 0s 522us/step - loss: 0.3278 - accuracy: 0.8650\n",
      "Epoch 80/100\n",
      "720/720 [==============================] - 0s 502us/step - loss: 0.3270 - accuracy: 0.8631\n",
      "Epoch 83/100\n",
      "720/720 [==============================] - 0s 543us/step - loss: 0.3275 - accuracy: 0.8658\n",
      "Epoch 81/100\n",
      "720/720 [==============================] - 0s 524us/step - loss: 0.3265 - accuracy: 0.8643\n",
      "Epoch 84/100\n",
      "720/720 [==============================] - 0s 545us/step - loss: 0.3278 - accuracy: 0.8668\n",
      "664/720 [==========================>...] - ETA: 0s - loss: 0.3284 - accuracy: 0.8645Epoch 82/100\n",
      "720/720 [==============================] - 0s 531us/step - loss: 0.3268 - accuracy: 0.8646\n",
      "Epoch 85/100\n",
      "720/720 [==============================] - 0s 571us/step - loss: 0.3280 - accuracy: 0.8672\n",
      "Epoch 83/100\n",
      "720/720 [==============================] - 0s 531us/step - loss: 0.3270 - accuracy: 0.8633\n",
      "Epoch 86/100\n",
      "720/720 [==============================] - 0s 529us/step - loss: 0.3263 - accuracy: 0.8647\n",
      "Epoch 87/100\n",
      "720/720 [==============================] - 0s 536us/step - loss: 0.3270 - accuracy: 0.8650\n",
      "Epoch 84/100\n",
      "720/720 [==============================] - 0s 520us/step - loss: 0.3267 - accuracy: 0.8653\n",
      "Epoch 88/100\n",
      "720/720 [==============================] - 0s 538us/step - loss: 0.3273 - accuracy: 0.8665\n",
      "Epoch 85/100\n",
      "720/720 [==============================] - 0s 530us/step - loss: 0.3265 - accuracy: 0.8646\n",
      "Epoch 89/100\n",
      "720/720 [==============================] - 0s 541us/step - loss: 0.3275 - accuracy: 0.8668\n",
      "Epoch 86/100\n",
      "720/720 [==============================] - 0s 514us/step - loss: 0.3263 - accuracy: 0.8637\n",
      "Epoch 90/100\n",
      "720/720 [==============================] - 0s 528us/step - loss: 0.3278 - accuracy: 0.8651\n",
      "Epoch 87/100\n",
      "720/720 [==============================] - 0s 507us/step - loss: 0.3265 - accuracy: 0.8646\n",
      "Epoch 91/100\n",
      "720/720 [==============================] - 0s 531us/step - loss: 0.3274 - accuracy: 0.8656\n",
      " 97/720 [===>..........................] - ETA: 0s - loss: 0.3188 - accuracy: 0.8598Epoch 88/100\n",
      "720/720 [==============================] - 0s 508us/step - loss: 0.3269 - accuracy: 0.8647\n",
      "Epoch 92/100\n",
      "720/720 [==============================] - 0s 524us/step - loss: 0.3273 - accuracy: 0.8675\n",
      "Epoch 89/100\n",
      "720/720 [==============================] - 0s 508us/step - loss: 0.3266 - accuracy: 0.8631\n",
      "Epoch 93/100\n",
      "720/720 [==============================] - 0s 514us/step - loss: 0.3273 - accuracy: 0.8662\n",
      "Epoch 90/100\n",
      "720/720 [==============================] - 0s 511us/step - loss: 0.3259 - accuracy: 0.8672\n",
      "566/720 [======================>.......] - ETA: 0s - loss: 0.3264 - accuracy: 0.8655Epoch 94/100\n",
      "720/720 [==============================] - 0s 520us/step - loss: 0.3277 - accuracy: 0.8644\n",
      "Epoch 91/100\n",
      "720/720 [==============================] - 0s 481us/step - loss: 0.3263 - accuracy: 0.8639\n",
      "Epoch 95/100\n",
      "720/720 [==============================] - 0s 511us/step - loss: 0.3262 - accuracy: 0.8674\n",
      "Epoch 92/100\n",
      "720/720 [==============================] - 0s 510us/step - loss: 0.3261 - accuracy: 0.8644\n",
      "Epoch 96/100\n",
      "720/720 [==============================] - 0s 522us/step - loss: 0.3268 - accuracy: 0.8651\n",
      "Epoch 93/100\n",
      "720/720 [==============================] - 0s 536us/step - loss: 0.3265 - accuracy: 0.8646\n",
      "Epoch 97/100\n",
      "720/720 [==============================] - 0s 558us/step - loss: 0.3270 - accuracy: 0.8664\n",
      "Epoch 94/100\n",
      "720/720 [==============================] - 0s 553us/step - loss: 0.3268 - accuracy: 0.8658\n",
      "Epoch 98/100\n",
      "720/720 [==============================] - 0s 567us/step - loss: 0.3272 - accuracy: 0.8654\n",
      "Epoch 95/100\n",
      "720/720 [==============================] - 0s 507us/step - loss: 0.3264 - accuracy: 0.8637\n",
      "Epoch 99/100\n",
      "720/720 [==============================] - 0s 519us/step - loss: 0.3267 - accuracy: 0.8665\n",
      "Epoch 96/100\n",
      "720/720 [==============================] - 0s 515us/step - loss: 0.3260 - accuracy: 0.8644\n",
      "Epoch 100/100\n",
      "720/720 [==============================] - 0s 536us/step - loss: 0.3273 - accuracy: 0.8643\n",
      "Epoch 97/100\n",
      "720/720 [==============================] - 0s 503us/step - loss: 0.3261 - accuracy: 0.8647\n",
      "80/80 [==============================] - 0s 458us/step - loss: 0.3359 - accuracy: 0.8750\n",
      "720/720 [==============================] - 0s 509us/step - loss: 0.3269 - accuracy: 0.8656\n",
      "Epoch 98/100\n",
      "720/720 [==============================] - 0s 508us/step - loss: 0.3274 - accuracy: 0.8664\n",
      "Epoch 99/100\n",
      "720/720 [==============================] - 0s 529us/step - loss: 0.3269 - accuracy: 0.8662\n",
      "Epoch 100/100\n",
      "720/720 [==============================] - 0s 532us/step - loss: 0.3265 - accuracy: 0.8654\n",
      "80/80 [==============================] - 0s 445us/step - loss: 0.3336 - accuracy: 0.8675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.86750001, 0.84125   , 0.86750001, 0.84875   , 0.85750002,\n",
       "       0.86000001, 0.85374999, 0.86124998, 0.875     , 0.86750001])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# création d'un wrapper pour utiliser le modèle keras dans sklearn\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = KerasClassifier(build_fn=build_ann_clf, batch_size=10, epochs=100)\n",
    "acc = cross_val_score(estimator=clf, X=X_train_pp, y=y_train, cv=10, n_jobs=-1)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8600000023841858, 0.009585146497508468)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.mean(), acc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elka/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'batch_size': 5, 'epochs': 100, 'optimizer': 'adam'}, 0.860375)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# affinage des hyperparamètres par validation croisée : GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = KerasClassifier(build_fn=build_ann_clf)\n",
    "\n",
    "parametres = {\n",
    "    'batch_size' : [5, 10, 25],\n",
    "    'epochs': [100, 150],\n",
    "    'optimizer' : ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf, param_grid=parametres, scoring='accuracy', cv=8)\n",
    "grid = grid.fit(X_train_pp, y_train, verbose=0)\n",
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 438us/step - loss: 0.3491 - accuracy: 0.8540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8539999723434448"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.score(X_test_pp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde et chargement des réseaux\n",
    "\n",
    "Regarder les méthodes `save` et `load_model` de la librairie `keras.models` pour la sauvegarde et le chargement des modèle. Quel format de fichier utiliser ?\n",
    "\n",
    "Si vous souhaitez ne sauvegarder que l'architecture du modèle (sans les poids ni la configuration d'entraînement), vous pouvez utiliser `to_json`.\n",
    "\n",
    "Enfin, pour ne sauvegarder que les poids, vous avez la méthode `save_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.save()\n",
    "\n",
    "Cette fonction sauvegarde : \n",
    "- l'architecture du modèle : permet de le recréer si besoin\n",
    "- les poids du modèle\n",
    "- les paramètres d'apprentissage (loss, optimizer, metrics de l'étape `compile`)\n",
    "- l'état de l'optimisation ce qui permet de reprendre l'apprentissage où on l'avait laissé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save('models/mlp_bank.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.load_model()\n",
    "charge un modèle enregistrés et l'ensemble des infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('models/mlp_bank.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.34645644, -0.47123882,  0.8929289 ,  0.9067629 ,  0.60434574,\n",
       "         0.7759857 , -0.07645609,  0.77421653], dtype=float32),\n",
       " array([ 0.34645644, -0.47123882,  0.8929289 ,  0.9067629 ,  0.60434574,\n",
       "         0.7759857 , -0.07645609,  0.77421653], dtype=float32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()[1], mlp.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7f2010d6f160>,\n",
       " <function tensorflow.python.keras.losses.binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer, new_model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28038713],\n",
       "       [0.10865974],\n",
       "       [0.02079785],\n",
       "       ...,\n",
       "       [0.03017306],\n",
       "       [0.99993813],\n",
       "       [0.08172989]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(X_test_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 0s 490us/step - loss: 0.3467 - accuracy: 0.8550\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 490us/step - loss: 0.3429 - accuracy: 0.8555\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 499us/step - loss: 0.3403 - accuracy: 0.8555\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 514us/step - loss: 0.3386 - accuracy: 0.8570\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 511us/step - loss: 0.3370 - accuracy: 0.8575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f20659cebe0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(X_test_pp, y_test, batch_size=20, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.to_json()\n",
    "\n",
    "Si on a juste besoin de sauvegarder **la structure d'un réseau, sans ses paramètres d'apprentissage ni ses poids**, on peut utiliser les 2 fonctions suivantes (pour sauvegarder et charger)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 11], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 11], \"dtype\": \"float32\", \"units\": 8, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 6, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sauvegarde en json\n",
    "json = mlp.to_json()\n",
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# reconstruire un modèle depuis une sauvegarde json\n",
    "from keras.models import model_from_json\n",
    "new_model2 = model_from_json(json)\n",
    "new_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.52040637, -0.3050189 ,  0.08282894,  0.17991823,  0.22155589,\n",
       "         -0.06695005,  0.4384995 ,  0.16253531],\n",
       "        [-0.47187346, -0.2406449 , -0.48651233, -0.54381585, -0.31263995,\n",
       "         -0.3244583 , -0.25161973, -0.253461  ],\n",
       "        [ 0.34067196,  0.45398015, -0.17907548, -0.39995515,  0.01222539,\n",
       "         -0.3542397 ,  0.37009603, -0.32202202],\n",
       "        [ 0.3335271 ,  0.42721385, -0.5172829 ,  0.34970236, -0.29685715,\n",
       "          0.01476604, -0.3974011 ,  0.09121376],\n",
       "        [-0.19214278,  0.4879194 , -0.42028016,  0.5127557 , -0.5037113 ,\n",
       "          0.29289025,  0.31492138, -0.09360087],\n",
       "        [-0.32972264,  0.34573054, -0.0549314 , -0.10982567, -0.27349377,\n",
       "         -0.5513795 , -0.18502927, -0.2959757 ],\n",
       "        [ 0.15428561, -0.24632469,  0.08971852, -0.39248633,  0.17617148,\n",
       "          0.47651547, -0.38299844, -0.15080094],\n",
       "        [-0.33926398, -0.43584   ,  0.38706845, -0.12005034, -0.05034369,\n",
       "         -0.4796483 ,  0.4762196 , -0.12429816],\n",
       "        [-0.42964184,  0.15590167, -0.14659092,  0.14596564,  0.12662888,\n",
       "         -0.4716209 , -0.05484188, -0.4660034 ],\n",
       "        [-0.28259888, -0.48110518,  0.3617857 ,  0.40458673,  0.32640076,\n",
       "         -0.4632256 ,  0.45182163, -0.09006354],\n",
       "        [ 0.20860457, -0.11811554,  0.02395678,  0.02154273,  0.44244343,\n",
       "         -0.55568254,  0.35948324, -0.5380008 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.07067937, -0.13588482,  0.35875154, -0.2155618 ,  0.5931556 ,\n",
       "         -0.549499  ],\n",
       "        [ 0.20349604,  0.28710413, -0.07033783,  0.3057601 ,  0.21267879,\n",
       "          0.5357157 ],\n",
       "        [ 0.5527482 ,  0.19912219, -0.19990447, -0.03203464, -0.12561446,\n",
       "         -0.26219103],\n",
       "        [ 0.33179277,  0.49291062,  0.44418097, -0.6039162 ,  0.6046314 ,\n",
       "          0.6262959 ],\n",
       "        [-0.11406785,  0.18634081, -0.21358237,  0.531554  ,  0.1164155 ,\n",
       "          0.16682625],\n",
       "        [-0.11047035,  0.22935581, -0.4978697 ,  0.01053488, -0.22393417,\n",
       "          0.21730506],\n",
       "        [ 0.13068742, -0.0842703 , -0.43200436,  0.24880654,  0.39470887,\n",
       "         -0.17998019],\n",
       "        [ 0.37475467, -0.42620248, -0.35635832,  0.5062009 , -0.07766122,\n",
       "         -0.56751364]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.25356698],\n",
       "        [-0.11056036],\n",
       "        [ 0.68410194],\n",
       "        [ 0.12054944],\n",
       "        [ 0.50372374],\n",
       "        [ 0.6493553 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(new_model2.optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.save_weights()\n",
    "\n",
    "Si jamais, on veut uniquement les poids d'un modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save_weights('models/mes_poids.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_294 (Dense)            (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model3 = Sequential([\n",
    "    Dense(units=8, activation='relu', input_dim=11),\n",
    "    Dense(units=6, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "new_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 7.00197816e-02,  4.90804017e-01,  3.79372537e-01,\n",
       "          2.79043496e-01, -3.85254920e-01,  1.55641794e-01,\n",
       "          1.91921711e-01,  2.11430073e-01],\n",
       "        [-1.63061023e-01, -4.33523655e-01,  2.91498065e-01,\n",
       "         -3.33856046e-01, -3.93931717e-01,  5.18758297e-02,\n",
       "          2.32530177e-01, -5.11753559e-01],\n",
       "        [-3.30212325e-01,  5.30959666e-01,  3.85699868e-01,\n",
       "         -1.39323324e-01,  2.45693803e-01, -2.83923268e-01,\n",
       "         -2.77836323e-02, -3.34671706e-01],\n",
       "        [ 5.40331066e-01,  5.13698637e-01, -3.90781164e-02,\n",
       "         -3.82620752e-01, -3.13674539e-01,  1.12761259e-02,\n",
       "         -5.11056602e-01, -1.22807115e-01],\n",
       "        [ 4.87059176e-01,  3.86694014e-01, -3.38792503e-01,\n",
       "          9.54108238e-02, -2.31025159e-01,  3.58129144e-01,\n",
       "          4.60426509e-01,  1.87718868e-02],\n",
       "        [ 4.49438989e-01, -5.36754012e-01, -3.69453371e-01,\n",
       "         -2.76735127e-01,  4.35965002e-01, -2.19561458e-01,\n",
       "         -3.12392771e-01,  9.89705324e-03],\n",
       "        [-2.30683684e-02, -2.18175977e-01,  3.58883858e-01,\n",
       "         -1.12935483e-01,  1.19525969e-01, -2.22965091e-01,\n",
       "          2.32299149e-01,  2.47603536e-01],\n",
       "        [ 2.51505136e-01, -3.36526930e-01,  2.07152665e-01,\n",
       "          1.21930182e-01,  3.40445280e-01, -3.44265848e-01,\n",
       "         -3.93465728e-01,  3.16244364e-03],\n",
       "        [-8.03530216e-03, -3.33482742e-01, -2.46149600e-01,\n",
       "         -4.39722747e-01, -4.88797367e-01, -5.53499997e-01,\n",
       "         -7.97599852e-02,  2.43688405e-01],\n",
       "        [ 5.58593094e-01,  2.81621635e-01, -4.37266111e-01,\n",
       "          1.44219875e-01, -5.20651162e-01, -1.01943523e-01,\n",
       "         -3.58801186e-01,  5.11109829e-04],\n",
       "        [-2.91076720e-01, -1.21779442e-02,  5.59022009e-01,\n",
       "         -1.25493526e-01,  2.31022060e-01, -3.52440357e-01,\n",
       "         -3.41632217e-01, -3.01826715e-01]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.00338948,  0.21261919,  0.5354775 , -0.20262873,  0.16680562,\n",
       "         -0.46149194],\n",
       "        [-0.06943214, -0.44408852,  0.4602294 , -0.25246587,  0.5858203 ,\n",
       "         -0.14270729],\n",
       "        [ 0.27190286, -0.0745694 ,  0.12167186, -0.56647646,  0.01106244,\n",
       "          0.63093007],\n",
       "        [ 0.07923359, -0.49208218, -0.2420479 , -0.05483115, -0.55218625,\n",
       "         -0.60834   ],\n",
       "        [ 0.64353204,  0.6135013 , -0.3443647 ,  0.00772399,  0.22373736,\n",
       "          0.3101856 ],\n",
       "        [ 0.37737608, -0.14014333, -0.31893948, -0.03024864,  0.5495336 ,\n",
       "         -0.05569834],\n",
       "        [-0.20624873,  0.248326  ,  0.46719468,  0.20665264,  0.6519575 ,\n",
       "         -0.61013687],\n",
       "        [ 0.03010064,  0.2501899 , -0.30881962, -0.4817176 , -0.07283407,\n",
       "         -0.3663318 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.59505856],\n",
       "        [ 0.34723616],\n",
       "        [ 0.6937119 ],\n",
       "        [-0.20496774],\n",
       "        [ 0.7365259 ],\n",
       "        [-0.903591  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# poids initialisés par défaut\n",
    "new_model3.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.35279983, -0.09898072, -0.35673648, -0.37696922,  0.15654956,\n",
       "         -0.40474743, -0.10706872,  0.5751586 ],\n",
       "        [-0.17824087,  0.25431764, -0.3201446 ,  0.25174102, -0.04208521,\n",
       "          0.0892429 ,  0.1176251 ,  0.15652889],\n",
       "        [ 0.64293915,  0.03073284,  0.3868236 ,  0.22502741,  0.5902933 ,\n",
       "          0.24626827,  0.29282773, -0.0891014 ],\n",
       "        [-0.07049636, -0.09114827,  0.15407038, -0.14431678,  0.12019989,\n",
       "         -0.08182564,  0.00202464,  0.05481816],\n",
       "        [ 1.2913975 ,  0.96711874, -0.71557593,  0.2040962 , -0.54972696,\n",
       "         -0.82999104,  0.50486887, -0.2967492 ],\n",
       "        [-0.09309078,  0.06769991, -0.03001953,  0.34526855, -0.17652254,\n",
       "          0.10117461,  0.05768863,  0.15901603],\n",
       "        [-0.23917308, -0.32882273, -0.22434482, -0.91876376,  0.29185608,\n",
       "         -0.02823355, -0.10142676, -0.94900066],\n",
       "        [-1.0452311 ,  1.2898824 ,  0.05201077, -0.2109877 ,  0.9628995 ,\n",
       "         -0.05280477, -0.05078161, -0.25675577],\n",
       "        [-0.05371074,  0.04714881,  0.23594882, -0.19458967, -0.04547591,\n",
       "         -0.17298736,  0.10797948,  0.03994825],\n",
       "        [-0.36435658,  0.41914976, -0.52799296,  0.13960616,  0.08476041,\n",
       "         -0.41772002,  1.1101074 ,  0.46979958],\n",
       "        [ 0.10658796, -0.20681894, -0.09627207, -0.39359343,  0.16583025,\n",
       "         -0.11254062,  0.0051821 , -0.37957454]], dtype=float32),\n",
       " array([ 0.34645644, -0.47123882,  0.8929289 ,  0.9067629 ,  0.60434574,\n",
       "         0.7759857 , -0.07645609,  0.77421653], dtype=float32),\n",
       " array([[-0.577715  , -0.25311345, -0.22393727,  0.8468641 ,  0.5470601 ,\n",
       "          0.6075978 ],\n",
       "        [-1.2397622 ,  0.5102988 ,  1.270248  , -0.8875943 , -0.07641721,\n",
       "         -0.11089087],\n",
       "        [-0.21792783,  0.5171113 , -0.33017957, -0.2418885 ,  0.7279976 ,\n",
       "          0.65509504],\n",
       "        [ 0.2128265 , -0.9104609 ,  0.12993978,  0.41282296,  0.59415716,\n",
       "          1.0569968 ],\n",
       "        [ 0.56233394,  0.28850532,  0.16243717, -0.48735538, -0.3187929 ,\n",
       "          0.13593106],\n",
       "        [-0.4301796 ,  0.6363212 ,  0.11982207, -0.44336703,  0.3900016 ,\n",
       "          0.40796018],\n",
       "        [ 0.19677885, -0.5410229 , -0.8977121 , -0.6608273 ,  0.5091205 ,\n",
       "          0.41013354],\n",
       "        [ 0.23715612,  0.2632229 , -0.8329533 ,  0.8450443 , -0.19205694,\n",
       "          0.35646158]], dtype=float32),\n",
       " array([ 0.7690733 , -0.15710835,  0.18341964,  0.22021909,  0.14498015,\n",
       "         0.20767866], dtype=float32),\n",
       " array([[-1.4591478 ],\n",
       "        [ 0.43047878],\n",
       "        [ 0.94002885],\n",
       "        [ 1.3797978 ],\n",
       "        [-0.54958105],\n",
       "        [-0.46992314]], dtype=float32),\n",
       " array([0.07232458], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chargement des poids sauvegardés\n",
    "new_model3.load_weights('models/mes_poids.h5')\n",
    "new_model3.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complément sur l'overfitting\n",
    "\n",
    "Toujours sur les données de la banque, entrainer un réseau ayant une structure complexe avec beaucoup de neurones et de couches afin de générer une situation d'overfitting.  \n",
    "Comparer l'accuracy sur les échantillons train et test pour confirmer le cas de sur-apprentissage.\n",
    "\n",
    "Reprendre le même réseau en utilisant des layers `Dropout` pour réduire ce problème.  \n",
    "Comparer à nouveau l'accuracy pour voir l'effet des `Dropout` sur l'overfitting.\n",
    "\n",
    "Une autre méthode pour limiter le sur-apprentissage est la régularisation. Est-il possible d'en faire avec un réseau de neurones ? Si oui, allez-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_303 (Dense)            (None, 128)               1536      \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 12,473\n",
      "Trainable params: 12,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_overfit = Sequential([\n",
    "    Dense(units=128, activation='relu', input_dim=11),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=4, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "mlp_overfit.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "mlp_overfit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 664us/step - loss: 0.4119 - accuracy: 0.8229\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.3703 - accuracy: 0.8565\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.3608 - accuracy: 0.8601\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 1s 679us/step - loss: 0.3528 - accuracy: 0.8609\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 1s 663us/step - loss: 0.3475 - accuracy: 0.8612\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 659us/step - loss: 0.3411 - accuracy: 0.8643\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 1s 668us/step - loss: 0.3370 - accuracy: 0.8656\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 1s 655us/step - loss: 0.3319 - accuracy: 0.8640\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 671us/step - loss: 0.3276 - accuracy: 0.8677\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 1s 680us/step - loss: 0.3220 - accuracy: 0.8680\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 1s 722us/step - loss: 0.3207 - accuracy: 0.8730\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 684us/step - loss: 0.3127 - accuracy: 0.8731\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 689us/step - loss: 0.3088 - accuracy: 0.8763\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 692us/step - loss: 0.3041 - accuracy: 0.8766\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 685us/step - loss: 0.3006 - accuracy: 0.8770\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 688us/step - loss: 0.2951 - accuracy: 0.8823\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 710us/step - loss: 0.2902 - accuracy: 0.8806\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 669us/step - loss: 0.2841 - accuracy: 0.8871\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 747us/step - loss: 0.2784 - accuracy: 0.8894\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 1s 653us/step - loss: 0.2742 - accuracy: 0.8880\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 672us/step - loss: 0.2657 - accuracy: 0.8914\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 675us/step - loss: 0.2623 - accuracy: 0.8930\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 659us/step - loss: 0.2554 - accuracy: 0.8960\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 664us/step - loss: 0.2506 - accuracy: 0.8963\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 697us/step - loss: 0.2453 - accuracy: 0.9009\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 664us/step - loss: 0.2366 - accuracy: 0.9055\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 660us/step - loss: 0.2315 - accuracy: 0.9036\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 1s 665us/step - loss: 0.2239 - accuracy: 0.9087\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 731us/step - loss: 0.2200 - accuracy: 0.9095\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 1s 718us/step - loss: 0.2157 - accuracy: 0.9107\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 719us/step - loss: 0.2092 - accuracy: 0.9146\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 677us/step - loss: 0.2064 - accuracy: 0.9151\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 662us/step - loss: 0.1962 - accuracy: 0.9196\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 656us/step - loss: 0.2013 - accuracy: 0.9185\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 672us/step - loss: 0.1923 - accuracy: 0.9209\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 674us/step - loss: 0.1896 - accuracy: 0.9215\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 665us/step - loss: 0.1870 - accuracy: 0.9246\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 659us/step - loss: 0.1794 - accuracy: 0.9275\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 717us/step - loss: 0.1753 - accuracy: 0.9269\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 658us/step - loss: 0.1636 - accuracy: 0.9345\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 668us/step - loss: 0.1681 - accuracy: 0.9317\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 677us/step - loss: 0.1568 - accuracy: 0.9362\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 658us/step - loss: 0.1616 - accuracy: 0.9359\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 655us/step - loss: 0.1577 - accuracy: 0.9369\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 653us/step - loss: 0.1520 - accuracy: 0.9380\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 685us/step - loss: 0.1517 - accuracy: 0.9381\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 676us/step - loss: 0.1494 - accuracy: 0.9417\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 682us/step - loss: 0.1374 - accuracy: 0.9459\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 736us/step - loss: 0.1401 - accuracy: 0.9457\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 1s 757us/step - loss: 0.1460 - accuracy: 0.9416\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 1s 687us/step - loss: 0.1313 - accuracy: 0.9488\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.1283 - accuracy: 0.9510\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 663us/step - loss: 0.1350 - accuracy: 0.9475\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 1s 662us/step - loss: 0.1181 - accuracy: 0.9539\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 1s 675us/step - loss: 0.1236 - accuracy: 0.9535\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 1s 706us/step - loss: 0.1205 - accuracy: 0.9528\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 1s 709us/step - loss: 0.1233 - accuracy: 0.9526\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 1s 689us/step - loss: 0.1194 - accuracy: 0.9554\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 666us/step - loss: 0.1119 - accuracy: 0.9575\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 1s 661us/step - loss: 0.1096 - accuracy: 0.9589\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 1s 650us/step - loss: 0.1157 - accuracy: 0.9565\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 1s 675us/step - loss: 0.1191 - accuracy: 0.9539\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 1s 682us/step - loss: 0.1094 - accuracy: 0.9578\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 1s 673us/step - loss: 0.0996 - accuracy: 0.9630\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 1s 654us/step - loss: 0.1018 - accuracy: 0.9614\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 1s 711us/step - loss: 0.1033 - accuracy: 0.9607\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 1s 716us/step - loss: 0.1060 - accuracy: 0.9582\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 648us/step - loss: 0.0979 - accuracy: 0.9620\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 1s 654us/step - loss: 0.0926 - accuracy: 0.9649\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 1s 652us/step - loss: 0.0978 - accuracy: 0.9644\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 1s 673us/step - loss: 0.0969 - accuracy: 0.9639\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 1s 663us/step - loss: 0.0971 - accuracy: 0.9628\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 651us/step - loss: 0.0889 - accuracy: 0.9650\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 1s 722us/step - loss: 0.0890 - accuracy: 0.9679\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 1s 653us/step - loss: 0.0970 - accuracy: 0.9640\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 1s 663us/step - loss: 0.0921 - accuracy: 0.9657\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 1s 666us/step - loss: 0.0904 - accuracy: 0.9651\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.0879 - accuracy: 0.9696\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 1s 650us/step - loss: 0.0888 - accuracy: 0.9672\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 1s 668us/step - loss: 0.0924 - accuracy: 0.9668\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 1s 676us/step - loss: 0.0769 - accuracy: 0.9721\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 717us/step - loss: 0.0829 - accuracy: 0.9701\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 1s 678us/step - loss: 0.0809 - accuracy: 0.9703\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 1s 661us/step - loss: 0.0873 - accuracy: 0.9681\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 1s 655us/step - loss: 0.0915 - accuracy: 0.9663\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 719us/step - loss: 0.0826 - accuracy: 0.9693\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 1s 684us/step - loss: 0.0767 - accuracy: 0.9745\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 1s 732us/step - loss: 0.0696 - accuracy: 0.9759\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 1s 704us/step - loss: 0.0931 - accuracy: 0.9668\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 1s 661us/step - loss: 0.0803 - accuracy: 0.9711\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 1s 687us/step - loss: 0.0764 - accuracy: 0.9720\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 1s 697us/step - loss: 0.0772 - accuracy: 0.9730\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 1s 666us/step - loss: 0.0753 - accuracy: 0.9716\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 1s 644us/step - loss: 0.0744 - accuracy: 0.9720\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 1s 679us/step - loss: 0.0667 - accuracy: 0.9737\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 1s 655us/step - loss: 0.0781 - accuracy: 0.9715\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 1s 699us/step - loss: 0.0770 - accuracy: 0.9719\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 1s 679us/step - loss: 0.0684 - accuracy: 0.9762\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 1s 676us/step - loss: 0.0707 - accuracy: 0.9749\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.0694 - accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f206456a0d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_overfit.fit(X_train_pp, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 530us/step - loss: 0.0548 - accuracy: 0.9809\n",
      "63/63 [==============================] - 0s 832us/step - loss: 1.2791 - accuracy: 0.8025\n",
      "[0.054787665605545044, 0.9808750152587891] [1.2790740728378296, 0.8025000095367432]\n"
     ]
    }
   ],
   "source": [
    "print(mlp_overfit.evaluate(X_train_pp, y_train), mlp_overfit.evaluate(X_test_pp, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_309 (Dense)            (None, 128)               1536      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 12,473\n",
      "Trainable params: 12,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ANN - avec DropOut\n",
    "from keras.layers import Dropout\n",
    "\n",
    "mlp_overfit_dropout = Sequential([\n",
    "    Dense(units=128, activation='relu', input_dim=11),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=4, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "mlp_overfit_dropout.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "mlp_overfit_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 728us/step - loss: 0.5286 - accuracy: 0.7850\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 715us/step - loss: 0.4679 - accuracy: 0.8055\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 718us/step - loss: 0.4293 - accuracy: 0.8295\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 1s 723us/step - loss: 0.4093 - accuracy: 0.8376\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 1s 714us/step - loss: 0.3986 - accuracy: 0.8359\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 737us/step - loss: 0.3889 - accuracy: 0.8426\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 1s 781us/step - loss: 0.3904 - accuracy: 0.8394\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 1s 758us/step - loss: 0.3786 - accuracy: 0.8440\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 690us/step - loss: 0.3774 - accuracy: 0.8449\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 1s 737us/step - loss: 0.3818 - accuracy: 0.8432\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 1s 752us/step - loss: 0.3745 - accuracy: 0.8453\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 710us/step - loss: 0.3707 - accuracy: 0.8478\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 769us/step - loss: 0.3710 - accuracy: 0.8480\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 733us/step - loss: 0.3752 - accuracy: 0.8484\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 692us/step - loss: 0.3681 - accuracy: 0.8471\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 716us/step - loss: 0.3705 - accuracy: 0.8484\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 699us/step - loss: 0.3721 - accuracy: 0.8495\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 713us/step - loss: 0.3643 - accuracy: 0.8509\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 734us/step - loss: 0.3649 - accuracy: 0.8515\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 1s 687us/step - loss: 0.3605 - accuracy: 0.8476\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 715us/step - loss: 0.3647 - accuracy: 0.8524\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 692us/step - loss: 0.3597 - accuracy: 0.8528\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 732us/step - loss: 0.3654 - accuracy: 0.8525\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 703us/step - loss: 0.3620 - accuracy: 0.8506\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 728us/step - loss: 0.3612 - accuracy: 0.8536\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 715us/step - loss: 0.3617 - accuracy: 0.8534\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 704us/step - loss: 0.3617 - accuracy: 0.8520\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 1s 800us/step - loss: 0.3611 - accuracy: 0.8550\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 775us/step - loss: 0.3595 - accuracy: 0.8546\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 1s 739us/step - loss: 0.3599 - accuracy: 0.8549\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 714us/step - loss: 0.3594 - accuracy: 0.8505\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 715us/step - loss: 0.3603 - accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 708us/step - loss: 0.3589 - accuracy: 0.8536\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 718us/step - loss: 0.3591 - accuracy: 0.8524\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 700us/step - loss: 0.3564 - accuracy: 0.8540\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 744us/step - loss: 0.3543 - accuracy: 0.8561\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 747us/step - loss: 0.3548 - accuracy: 0.8556\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 712us/step - loss: 0.3537 - accuracy: 0.8524\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 724us/step - loss: 0.3543 - accuracy: 0.8537\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 735us/step - loss: 0.3510 - accuracy: 0.8547\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 712us/step - loss: 0.3537 - accuracy: 0.8589\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 697us/step - loss: 0.3536 - accuracy: 0.8575\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 739us/step - loss: 0.3486 - accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 700us/step - loss: 0.3477 - accuracy: 0.8586\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 699us/step - loss: 0.3489 - accuracy: 0.8576\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 705us/step - loss: 0.3510 - accuracy: 0.8550\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 687us/step - loss: 0.3462 - accuracy: 0.8616\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 682us/step - loss: 0.3545 - accuracy: 0.8530\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 708us/step - loss: 0.3491 - accuracy: 0.8560\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 1s 699us/step - loss: 0.3472 - accuracy: 0.8570\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 1s 727us/step - loss: 0.3517 - accuracy: 0.8590\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 1s 736us/step - loss: 0.3482 - accuracy: 0.8589\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 702us/step - loss: 0.3464 - accuracy: 0.8615\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 1s 708us/step - loss: 0.3450 - accuracy: 0.8586\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 1s 716us/step - loss: 0.3464 - accuracy: 0.8593\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 1s 713us/step - loss: 0.3471 - accuracy: 0.8602\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 1s 767us/step - loss: 0.3490 - accuracy: 0.8560\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 1s 716us/step - loss: 0.3480 - accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 704us/step - loss: 0.3431 - accuracy: 0.8608\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 1s 711us/step - loss: 0.3427 - accuracy: 0.8591\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 1s 744us/step - loss: 0.3443 - accuracy: 0.8589\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 1s 734us/step - loss: 0.3448 - accuracy: 0.8619\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 1s 683us/step - loss: 0.3409 - accuracy: 0.8627\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 1s 689us/step - loss: 0.3389 - accuracy: 0.8605\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 1s 693us/step - loss: 0.3439 - accuracy: 0.8608\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 1s 785us/step - loss: 0.3424 - accuracy: 0.8585\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 1s 738us/step - loss: 0.3394 - accuracy: 0.8622\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 698us/step - loss: 0.3466 - accuracy: 0.8594\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 1s 711us/step - loss: 0.3460 - accuracy: 0.8605\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 1s 702us/step - loss: 0.3407 - accuracy: 0.8595\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 1s 694us/step - loss: 0.3359 - accuracy: 0.8650\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 1s 717us/step - loss: 0.3414 - accuracy: 0.8597\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 725us/step - loss: 0.3369 - accuracy: 0.8636\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 1s 721us/step - loss: 0.3374 - accuracy: 0.8618\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 1s 715us/step - loss: 0.3463 - accuracy: 0.8576\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 1s 777us/step - loss: 0.3402 - accuracy: 0.8581\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 1s 780us/step - loss: 0.3367 - accuracy: 0.8625\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 1s 743us/step - loss: 0.3395 - accuracy: 0.8614\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 1s 721us/step - loss: 0.3370 - accuracy: 0.8608\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 1s 753us/step - loss: 0.3364 - accuracy: 0.8634\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 1s 769us/step - loss: 0.3405 - accuracy: 0.8629\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 736us/step - loss: 0.3331 - accuracy: 0.8636\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 1s 833us/step - loss: 0.3372 - accuracy: 0.8658\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 1s 788us/step - loss: 0.3353 - accuracy: 0.8619\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 1s 780us/step - loss: 0.3307 - accuracy: 0.8662\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 849us/step - loss: 0.3396 - accuracy: 0.8660\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 1s 831us/step - loss: 0.3358 - accuracy: 0.8643\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 1s 765us/step - loss: 0.3367 - accuracy: 0.8635\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 1s 731us/step - loss: 0.3353 - accuracy: 0.8633\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 1s 726us/step - loss: 0.3367 - accuracy: 0.8614\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 1s 802us/step - loss: 0.3408 - accuracy: 0.8605\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 1s 765us/step - loss: 0.3346 - accuracy: 0.8668\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 1s 756us/step - loss: 0.3365 - accuracy: 0.8639\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 1s 774us/step - loss: 0.3370 - accuracy: 0.8639\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 1s 734us/step - loss: 0.3343 - accuracy: 0.8650\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 1s 736us/step - loss: 0.3360 - accuracy: 0.8641\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 1s 728us/step - loss: 0.3350 - accuracy: 0.8616\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 1s 729us/step - loss: 0.3307 - accuracy: 0.8643\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 1s 773us/step - loss: 0.3360 - accuracy: 0.8566\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 1s 746us/step - loss: 0.3344 - accuracy: 0.8605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1fac20a520>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_overfit_dropout.fit(X_train_pp, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 539us/step - loss: 0.2788 - accuracy: 0.8834\n",
      "63/63 [==============================] - 0s 815us/step - loss: 0.3578 - accuracy: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35784780979156494, 0.859000027179718]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_overfit_dropout.evaluate(X_train_pp, y_train)\n",
    "mlp_overfit_dropout.evaluate(X_test_pp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_327 (Dense)            (None, 128)               1536      \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_330 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 12,473\n",
      "Trainable params: 12,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ANN - avec régularisation l2\n",
    "from keras import regularizers\n",
    "\n",
    "mlp_overfit_regul = Sequential([\n",
    "    Dense(units=128, activation='relu', input_dim=11),\n",
    "    Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),#ou kernel_regularizer='l2'\n",
    "    Dense(units=32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(units=16, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(units=4, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "mlp_overfit_regul.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "mlp_overfit_regul.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 684us/step - loss: 0.6543 - accuracy: 0.7962\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 725us/step - loss: 0.4359 - accuracy: 0.8303\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 781us/step - loss: 0.4178 - accuracy: 0.8484\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 1s 888us/step - loss: 0.4109 - accuracy: 0.8510\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 1s 865us/step - loss: 0.4045 - accuracy: 0.8526\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 717us/step - loss: 0.3997 - accuracy: 0.8560\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 1s 676us/step - loss: 0.3948 - accuracy: 0.8579\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 1s 709us/step - loss: 0.3918 - accuracy: 0.8559\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 678us/step - loss: 0.3895 - accuracy: 0.8589\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 1s 703us/step - loss: 0.3845 - accuracy: 0.8596\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 1s 729us/step - loss: 0.3820 - accuracy: 0.8583\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 722us/step - loss: 0.3817 - accuracy: 0.8585\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 672us/step - loss: 0.3770 - accuracy: 0.8634\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 706us/step - loss: 0.3747 - accuracy: 0.8651\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 669us/step - loss: 0.3742 - accuracy: 0.8620\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 659us/step - loss: 0.3723 - accuracy: 0.8618\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 717us/step - loss: 0.3715 - accuracy: 0.8627\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 693us/step - loss: 0.3706 - accuracy: 0.8604\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 698us/step - loss: 0.3692 - accuracy: 0.8643\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 1s 680us/step - loss: 0.3687 - accuracy: 0.8625\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 683us/step - loss: 0.3678 - accuracy: 0.8624\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 675us/step - loss: 0.3654 - accuracy: 0.8634\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 731us/step - loss: 0.3638 - accuracy: 0.8627\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 722us/step - loss: 0.3643 - accuracy: 0.8629\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 700us/step - loss: 0.3654 - accuracy: 0.8634\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 787us/step - loss: 0.3614 - accuracy: 0.8645\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 672us/step - loss: 0.3624 - accuracy: 0.8625\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 1s 685us/step - loss: 0.3601 - accuracy: 0.8644\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 683us/step - loss: 0.3604 - accuracy: 0.8637\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 1s 677us/step - loss: 0.3581 - accuracy: 0.8668\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 681us/step - loss: 0.3588 - accuracy: 0.8641\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 705us/step - loss: 0.3571 - accuracy: 0.8646\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 729us/step - loss: 0.3579 - accuracy: 0.8627\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 856us/step - loss: 0.3564 - accuracy: 0.8641\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 673us/step - loss: 0.3570 - accuracy: 0.8640\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 689us/step - loss: 0.3555 - accuracy: 0.8662\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 678us/step - loss: 0.3530 - accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 671us/step - loss: 0.3555 - accuracy: 0.8650\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 675us/step - loss: 0.3544 - accuracy: 0.8633\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 678us/step - loss: 0.3540 - accuracy: 0.8654\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 680us/step - loss: 0.3537 - accuracy: 0.8659\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 665us/step - loss: 0.3535 - accuracy: 0.8648\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 673us/step - loss: 0.3524 - accuracy: 0.8648\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 699us/step - loss: 0.3522 - accuracy: 0.8659\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 676us/step - loss: 0.3524 - accuracy: 0.8652\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 671us/step - loss: 0.3528 - accuracy: 0.8655\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 661us/step - loss: 0.3522 - accuracy: 0.8662\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 676us/step - loss: 0.3518 - accuracy: 0.8660\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 668us/step - loss: 0.3512 - accuracy: 0.8676\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 1s 696us/step - loss: 0.3497 - accuracy: 0.8683\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 1s 735us/step - loss: 0.3494 - accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 1s 682us/step - loss: 0.3505 - accuracy: 0.8673\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 681us/step - loss: 0.3491 - accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 1s 684us/step - loss: 0.3481 - accuracy: 0.8669\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 1s 703us/step - loss: 0.3473 - accuracy: 0.8680\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 1s 680us/step - loss: 0.3493 - accuracy: 0.8652\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 1s 683us/step - loss: 0.3474 - accuracy: 0.8716\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 1s 707us/step - loss: 0.3478 - accuracy: 0.8669\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 672us/step - loss: 0.3480 - accuracy: 0.8670\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 1s 708us/step - loss: 0.3477 - accuracy: 0.8655\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 1s 684us/step - loss: 0.3458 - accuracy: 0.8681\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.3455 - accuracy: 0.8686\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 1s 693us/step - loss: 0.3461 - accuracy: 0.8680\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 1s 681us/step - loss: 0.3466 - accuracy: 0.8660\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 1s 665us/step - loss: 0.3460 - accuracy: 0.8666\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 1s 656us/step - loss: 0.3440 - accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.3446 - accuracy: 0.8670\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 685us/step - loss: 0.3453 - accuracy: 0.8684\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 1s 707us/step - loss: 0.3434 - accuracy: 0.8671\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 1s 683us/step - loss: 0.3444 - accuracy: 0.8674\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 1s 664us/step - loss: 0.3432 - accuracy: 0.8681\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 1s 668us/step - loss: 0.3425 - accuracy: 0.8699\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 727us/step - loss: 0.3440 - accuracy: 0.8677\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 1s 764us/step - loss: 0.3424 - accuracy: 0.8687\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 1s 812us/step - loss: 0.3430 - accuracy: 0.8681\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 1s 688us/step - loss: 0.3415 - accuracy: 0.8685\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 1s 671us/step - loss: 0.3415 - accuracy: 0.8690\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 1s 755us/step - loss: 0.3422 - accuracy: 0.8674\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 1s 703us/step - loss: 0.3403 - accuracy: 0.8695\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 1s 700us/step - loss: 0.3425 - accuracy: 0.8695\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 1s 700us/step - loss: 0.3394 - accuracy: 0.8683\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 720us/step - loss: 0.3404 - accuracy: 0.8684\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 1s 696us/step - loss: 0.3398 - accuracy: 0.8684\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 1s 702us/step - loss: 0.3399 - accuracy: 0.8675\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 1s 682us/step - loss: 0.3407 - accuracy: 0.8676\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 747us/step - loss: 0.3393 - accuracy: 0.8701\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 1s 737us/step - loss: 0.3390 - accuracy: 0.8687\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 1s 711us/step - loss: 0.3393 - accuracy: 0.8666\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 1s 728us/step - loss: 0.3388 - accuracy: 0.8696\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 1s 694us/step - loss: 0.3386 - accuracy: 0.8715\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 1s 680us/step - loss: 0.3400 - accuracy: 0.8681\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 1s 722us/step - loss: 0.3386 - accuracy: 0.8692\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 1s 720us/step - loss: 0.3372 - accuracy: 0.8700\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 1s 729us/step - loss: 0.3366 - accuracy: 0.8694\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 1s 709us/step - loss: 0.3385 - accuracy: 0.8686\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 1s 677us/step - loss: 0.3379 - accuracy: 0.8679\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 1s 675us/step - loss: 0.3377 - accuracy: 0.8699\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 1s 683us/step - loss: 0.3365 - accuracy: 0.8694\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 1s 676us/step - loss: 0.3357 - accuracy: 0.8709\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 1s 690us/step - loss: 0.3366 - accuracy: 0.8708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1f5cff00d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_overfit_regul.fit(X_train_pp, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 554us/step - loss: 0.3305 - accuracy: 0.8717\n",
      "63/63 [==============================] - 0s 807us/step - loss: 0.3794 - accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37937313318252563, 0.8500000238418579]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_overfit_regul.evaluate(X_train_pp, y_train)\n",
    "mlp_overfit_regul.evaluate(X_test_pp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
